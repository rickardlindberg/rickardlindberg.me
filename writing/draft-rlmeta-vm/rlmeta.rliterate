{
"root_page":{
"children":[
{
"children":[
{
"children":[],
"id":"49ca0a2fa665466cb90c8c128d5cc835",
"paragraphs":[
{
"chunkpath":[
"vm",
"cases"
],
"filepath":[
"support.py"
],
"fragments":[
{
"text":"if name == \"PUSH_SCOPE\":\n    envs.append({})\n    pc += 1\n    continue\n",
"type":"code"
}
],
"id":"2c1a5595c42d499bbb325bae3bd2f874",
"type":"code"
}
],
"title":"PUSH_SCOPE"
},
{
"children":[],
"id":"542906286e124874b2975d0ae23f034f",
"paragraphs":[
{
"chunkpath":[
"vm",
"cases"
],
"filepath":[
"support.py"
],
"fragments":[
{
"text":"elif name == \"BACKTRACK\":\n    stack.append((labels[arg1], pos, len(stream_stack), len(envs)))\n    pc += 1\n    continue\n",
"type":"code"
}
],
"id":"d29ae793a57c42b5bb6e02f16abaf717",
"type":"code"
}
],
"title":"BACKTRACK"
},
{
"children":[],
"id":"8e19cbb2e71c412f95c7e241a69f0901",
"paragraphs":[
{
"chunkpath":[
"vm",
"cases"
],
"filepath":[
"support.py"
],
"fragments":[
{
"text":"elif name == \"CALL\":\n    key = (arg1, tuple([x[1] for x in stream_stack]+[pos]))\n    if key in memo:\n        last_action, stream_stack = memo[key]\n        stream_stack = stream_stack[:]\n        stream, pos = stream_stack.pop()\n        pc += 1\n    else:\n        stack.append((pc+1, key))\n        pc = labels[arg1]\n    continue\n",
"type":"code"
}
],
"id":"a0bfc0043b73482885ddcd87f913ce76",
"type":"code"
}
],
"title":"CALL"
},
{
"children":[],
"id":"df5dc1b5e5054e548d5c3606daba0d55",
"paragraphs":[
{
"chunkpath":[
"vm",
"cases"
],
"filepath":[
"support.py"
],
"fragments":[
{
"text":"elif name == \"MATCH_CHARSEQ\":\n    for char in arg1:\n        if pos >= len(stream) or stream[pos] != char:\n            fail_message = \"match charseq\"\n            break\n        pos += 1\n    else:\n        last_action = _ConstantSemanticAction(arg1)\n        pc += 1\n        continue\n",
"type":"code"
}
],
"id":"faee63d4203f433fb4665fd4cb5abf1f",
"type":"code"
}
],
"title":"MATCH_CHARSEQ"
},
{
"children":[],
"id":"5b99ed36fbde45989829fde6e17d4821",
"paragraphs":[
{
"chunkpath":[
"vm",
"cases"
],
"filepath":[
"support.py"
],
"fragments":[
{
"text":"elif name == \"COMMIT\":\n    stack.pop()\n    pc = labels[arg1]\n    continue\n",
"type":"code"
}
],
"id":"8222233eb6b140a495fb9884f4c637df",
"type":"code"
}
],
"title":"COMMIT"
},
{
"children":[],
"id":"b2510846e20d4cd08f9b0cd2dfb5c01d",
"paragraphs":[
{
"chunkpath":[
"vm",
"cases"
],
"filepath":[
"support.py"
],
"fragments":[
{
"text":"elif name == \"POP_SCOPE\":\n    envs.pop()\n    pc += 1\n    continue\n",
"type":"code"
}
],
"id":"4d43ad60b62549fe9a4d837858a1e6b6",
"type":"code"
}
],
"title":"POP_SCOPE"
},
{
"children":[],
"id":"d104aa6d6b8e43818f662498f6566e38",
"paragraphs":[
{
"chunkpath":[
"vm",
"cases"
],
"filepath":[
"support.py"
],
"fragments":[
{
"text":"elif name == \"RETURN\":\n    if len(stack) == 0:\n        result = last_action.eval()\n        if isinstance(result, _Builder):\n            return result.build_string()\n        else:\n            return result\n    pc, key = stack.pop()\n    memo[key] = (last_action, stream_stack[:]+[(stream, pos)])\n    continue\n",
"type":"code"
}
],
"id":"7afc540dab7b454a9805ec62225de4dc",
"type":"code"
}
],
"title":"RETURN"
},
{
"children":[],
"id":"b4aacd38dec8406c9db784e0823c3554",
"paragraphs":[
{
"chunkpath":[
"vm",
"cases"
],
"filepath":[
"support.py"
],
"fragments":[
{
"text":"elif name == \"LIST_APPEND\":\n    envs[-1].append(last_action)\n    pc += 1\n    continue\n",
"type":"code"
}
],
"id":"356f537a114549d590cbcec132d12154",
"type":"code"
}
],
"title":"LIST_APPEND"
},
{
"children":[],
"id":"1315305641224e4aa99dd00ec5b524b1",
"paragraphs":[
{
"chunkpath":[
"vm",
"cases"
],
"filepath":[
"support.py"
],
"fragments":[
{
"text":"elif name == \"BIND\":\n    envs[-1][arg1] = last_action\n    pc += 1\n    continue\n",
"type":"code"
}
],
"id":"fa7420fc6e714750afb1d9a559ba60a3",
"type":"code"
}
],
"title":"BIND"
},
{
"children":[],
"id":"738356fde86e4c7290b0f99850917ba8",
"paragraphs":[
{
"chunkpath":[
"vm",
"cases"
],
"filepath":[
"support.py"
],
"fragments":[
{
"text":"elif name == \"ACTION\":\n    last_action = _SemanticAction(arg1, envs[-1])\n    pc += 1\n    continue\n",
"type":"code"
}
],
"id":"ca202e729537441f88100eb2b1fb8936",
"type":"code"
}
],
"title":"ACTION"
},
{
"children":[],
"id":"d8dcb57d5da141908f28f8c52983d1a6",
"paragraphs":[
{
"chunkpath":[
"vm",
"cases"
],
"filepath":[
"support.py"
],
"fragments":[
{
"text":"elif name == \"MATCH_RANGE\":\n    if pos >= len(stream) or not (arg1 <= stream[pos] <= arg2):\n        fail_message = \"match range\"\n    else:\n        last_action = _ConstantSemanticAction(stream[pos])\n        pos += 1\n        pc += 1\n        continue\n",
"type":"code"
}
],
"id":"500a0c29c73e42448e1c4c8ea67c13cf",
"type":"code"
}
],
"title":"MATCH_RANGE"
},
{
"children":[],
"id":"b3562467300348028f04ae5034db0f34",
"paragraphs":[
{
"chunkpath":[
"vm",
"cases"
],
"filepath":[
"support.py"
],
"fragments":[
{
"text":"elif name == \"LIST_START\":\n    envs.append([])\n    pc += 1\n    continue\n",
"type":"code"
}
],
"id":"089a8080f82b404cbbb99de6dd80090a",
"type":"code"
}
],
"title":"LIST_START"
},
{
"children":[],
"id":"9940cd44d7fe4777b1c12e335bac33ae",
"paragraphs":[
{
"chunkpath":[
"vm",
"cases"
],
"filepath":[
"support.py"
],
"fragments":[
{
"text":"elif name == \"LIST_END\":\n    last_action = _SemanticAction(lambda xs: [x.eval() for x in xs], envs.pop())\n    pc += 1\n    continue\n",
"type":"code"
}
],
"id":"7562783a1dc34c42beb05e22ee0ae2f4",
"type":"code"
}
],
"title":"LIST_END"
},
{
"children":[],
"id":"8f0fffeab7084a1d9b01d928be4878a8",
"paragraphs":[
{
"chunkpath":[
"vm",
"cases"
],
"filepath":[
"support.py"
],
"fragments":[
{
"text":"elif name == \"MATCH_ANY\":\n    if pos >= len(stream):\n        fail_message = \"match any\"\n    else:\n        last_action = _ConstantSemanticAction(stream[pos])\n        pos += 1\n        pc += 1\n        continue\n",
"type":"code"
}
],
"id":"97063c2aa95a48b1886545a984494caf",
"type":"code"
}
],
"title":"MATCH_ANY"
},
{
"children":[],
"id":"fee2dcf573f04ac3a9e7cfd92adbe0c8",
"paragraphs":[
{
"chunkpath":[
"vm",
"cases"
],
"filepath":[
"support.py"
],
"fragments":[
{
"text":"elif name == \"PUSH_INPUT\":\n    if pos >= len(stream) or not isinstance(stream[pos], list):\n        fail_message = \"push input\"\n    else:\n        stream_stack.append((stream, pos+1))\n        stream = stream[pos]\n        pos = 0\n        pc += 1\n        continue\n",
"type":"code"
}
],
"id":"c5ae99acbb584d718d09917f827884f4",
"type":"code"
}
],
"title":"PUSH_INPUT"
},
{
"children":[],
"id":"87a1eee2cfb94e1a9463a6561c226012",
"paragraphs":[
{
"chunkpath":[
"vm",
"cases"
],
"filepath":[
"support.py"
],
"fragments":[
{
"text":"elif name == \"POP_INPUT\":\n    if pos < len(stream):\n        fail_message = \"pop input\"\n    else:\n        stream, pos = stream_stack.pop()\n        pc += 1\n        continue\n",
"type":"code"
}
],
"id":"5f242526e0af408ebd0038e2ec2c4797",
"type":"code"
}
],
"title":"POP_INPUT"
},
{
"children":[],
"id":"d42df29209bf475280ac510d9ae31182",
"paragraphs":[
{
"chunkpath":[
"vm",
"cases"
],
"filepath":[
"support.py"
],
"fragments":[
{
"text":"elif name == \"MATCH_CALL_RULE\":\n    if pos >= len(stream):\n        fail_message = \"match call rule\"\n    else:\n        fn_name = stream[pos]\n        key = (fn_name, tuple([x[1] for x in stream_stack]+[pos]))\n        if key in memo:\n            last_action, stream_stack = memo[key]\n            stream_stack = stream_stack[:]\n            stream, pos = stream_stack.pop()\n            pc += 1\n        else:\n            stack.append((pc+1, key))\n            pc = labels[fn_name]\n            pos += 1\n        continue\n",
"type":"code"
}
],
"id":"05a80103eda14253a19d5770172c51b1",
"type":"code"
}
],
"title":"MATCH_CALL_RULE"
},
{
"children":[],
"id":"34915cae29994179abbe19f2f7e4c267",
"paragraphs":[
{
"chunkpath":[
"vm",
"cases"
],
"filepath":[
"support.py"
],
"fragments":[
{
"text":"elif name == \"FAIL\":\n    fail_message = \"fail\"\n",
"type":"code"
}
],
"id":"455aa8f0eafd4641a124090a5b7bdb25",
"type":"code"
},
{
"chunkpath":[
"vm",
"fail case"
],
"filepath":[
"support.py"
],
"fragments":[
{
"text":"while stack and len(stack[-1]) == 2:\n    stack.pop()\nif not stack:\n    raise Exception(\"totally failed: {}\".format(fail_message))\n(pc, pos, stream_stack_len, envs_len) = stack.pop()\nif len(stream_stack) > stream_stack_len:\n    stream = stream_stack[stream_stack_len][0]\nstream_stack = stream_stack[:stream_stack_len]\nenvs = envs[:envs_len]\n",
"type":"code"
}
],
"id":"3aeef8c3298b44c0acb4a2ce8079d334",
"type":"code"
}
],
"title":"FAIL"
},
{
"children":[],
"id":"d7d285d9586b437ca7d7f51b5deb6193",
"paragraphs":[
{
"chunkpath":[
"vm",
"cases"
],
"filepath":[
"support.py"
],
"fragments":[
{
"text":"elif name == \"LABEL\":\n    last_action = _ConstantSemanticAction(label_counter)\n    label_counter += 1\n    pc += 1\n    continue\n",
"type":"code"
}
],
"id":"690d125013b74bdfa88a28e52dc4c184",
"type":"code"
}
],
"title":"LABEL"
},
{
"children":[],
"id":"a8160d30b886418882ada3a2a884e580",
"paragraphs":[
{
"chunkpath":[
"vm",
"cases"
],
"filepath":[
"support.py"
],
"fragments":[
{
"text":"elif name == \"MATCH_STRING\":\n    if pos >= len(stream) or stream[pos] != arg1:\n        fail_message = \"match string {}\".format(arg1)\n    else:\n        last_action = _ConstantSemanticAction(arg1)\n        pos += 1\n        pc += 1\n        continue\n",
"type":"code"
}
],
"id":"2d8eef6d882b434abbb5f835f666c498",
"type":"code"
}
],
"title":"MATCH_STRING"
}
],
"id":"e66f8cec6206420abe4736ae32849c53",
"paragraphs":[
{
"chunkpath":[
"vm"
],
"filepath":[
"support.py"
],
"fragments":[
{
"text":"def rlmeta_vm(instructions, labels, start_rule, stream):\n    label_counter = 0\n    envs = []\n    stack = []\n    last_action = _ConstantSemanticAction(None)\n    pc = labels[start_rule]\n    memo = {}\n    pos = 0\n    stream_stack = []\n    fail_message = \"\"\n    while True:\n        name, arg1, arg2 = instructions[pc]\n",
"type":"code"
},
{
"blank_lines_before":0,
"path":[
"cases"
],
"prefix":"        ",
"type":"chunk"
},
{
"text":"        else:\n            raise Exception(\"unknown command {}\".format(name))\n",
"type":"code"
},
{
"blank_lines_before":0,
"path":[
"fail case"
],
"prefix":"        ",
"type":"chunk"
}
],
"id":"f00b388c4529474b9925b3aa4149b0e3",
"type":"code"
}
],
"title":"VM"
},
{
"children":[],
"id":"18d541f39625425c82e285cdae8d7523",
"paragraphs":[
{
"chunkpath":[],
"filepath":[
"support.py"
],
"fragments":[
{
"text":"try:\n    from cStringIO import StringIO\nexcept:\n    from StringIO import StringIO\n\n",
"type":"code"
},
{
"blank_lines_before":0,
"path":[
"vm"
],
"prefix":"",
"type":"chunk"
},
{
"text":"\nclass _Grammar(object):\n\n    def run(self, rule_name, input_object):\n        if isinstance(input_object, basestring):\n            stream = input_object\n        else:\n            stream = [input_object]\n        return rlmeta_vm(self._instructions, self._labels, rule_name, stream)\n\nclass _SemanticAction(object):\n\n    def __init__(self, fn, env):\n        self.fn = fn\n        self.env = env\n\n    def eval(self):\n        return self.fn(self.env)\n\nclass _ConstantSemanticAction(object):\n\n    def __init__(self, value):\n        self.value = value\n\n    def eval(self):\n        return self.value\n\nclass _Builder(object):\n\n    def build_string(self):\n        output = _Output()\n        self.write(output)\n        return output.value\n\n    @classmethod\n    def create(self, item):\n        if isinstance(item, _Builder):\n            return item\n        elif isinstance(item, list):\n            return _ListBuilder([_Builder.create(x) for x in item])\n        else:\n            return _AtomBuilder(item)\n\nclass _Output(object):\n\n    def __init__(self):\n        self.buffer = StringIO()\n        self.indentation = 0\n        self.on_newline = True\n\n    @property\n    def value(self):\n        return self.buffer.getvalue()\n\n    def write(self, value):\n        for ch in value:\n            is_linebreak = ch == \"\\n\"\n            if self.indentation and self.on_newline and not is_linebreak:\n                self.buffer.write(\"    \"*self.indentation)\n            self.buffer.write(ch)\n            self.on_newline = is_linebreak\n\nclass _ListBuilder(_Builder):\n\n    def __init__(self, builders):\n        self.builders = builders\n\n    def write(self, output):\n        for builder in self.builders:\n            builder.write(output)\n\nclass _AtomBuilder(_Builder):\n\n    def __init__(self, atom):\n        self.atom = atom\n\n    def write(self, output):\n        output.write(str(self.atom))\n\nclass _IndentBuilder(_Builder):\n\n    def write(self, output):\n        output.indentation += 1\n\nclass _DedentBuilder(_Builder):\n\n    def write(self, output):\n        output.indentation -= 1\n",
"type":"code"
}
],
"id":"4d06e64ddc8941928ee419ac82f56c4d",
"type":"code"
}
],
"title":"Rest of support library"
},
{
"children":[],
"id":"5cca99df2e2c4c78ab4bfe4cb946d89a",
"paragraphs":[
{
"fragments":[
{
"text":"This builds upon the ",
"type":"text"
},
{
"text":"optimized version of RLMeta",
"type":"link",
"url":"/writing/optimizing-rlmeta/index.html"
},
{
"text":".",
"type":"text"
}
],
"id":"79ae9067afde497085d5b885fe4fb8a4",
"type":"text"
},
{
"fragments":[
{
"text":"This is inspired by ",
"type":"text"
},
{
"text":"Regular Expression Matching: the Virtual Machine Approach",
"type":"link",
"url":"https://swtch.com/~rsc/regexp/regexp2.html"
},
{
"text":" and ",
"type":"text"
},
{
"text":"A Text Pattern-Matching Tool based on Parsing Expression Grammars",
"type":"link",
"url":"http://www.inf.puc-rio.br/%7Eroberto/docs/peg.pdf"
},
{
"text":".",
"type":"text"
}
],
"id":"d21cbbff552e4c8dafd419861250c3c4",
"type":"text"
},
{
"fragments":[
{
"text":"Not using ",
"type":"text"
},
{
"text":"self",
"type":"code"
},
{
"text":" seems to improve performance. Is self always compiled to dictionary lookup, but local variable lookup to indexing in call stack?",
"type":"text"
}
],
"id":"3a5fbbadfd654c42bc1cd57075467383",
"type":"text"
},
{
"fragments":[
{
"text":"Instruction frequency analysis to optimize order of while loop.",
"type":"text"
}
],
"id":"68e3bcae66ca4daf9fd359a53559b019",
"type":"text"
},
{
"fragments":[
{
"text":"Why did labels change when making first vm based metacompiler? Investigate in branch.",
"type":"text"
}
],
"id":"4230d0b352b74f578d1e820477d4f0bb",
"type":"text"
},
{
"fragments":[
{
"text":"Add failure messages again. And make sure python template exception handling is the same again.",
"type":"text"
}
],
"id":"b96e160d222e4d28a37b51ddba1a290b",
"type":"text"
},
{
"fragments":[
{
"text":"Back patch jump instructions instead of using labels?",
"type":"text"
}
],
"id":"0cafd15b18cc43aea7ff1e4336e11e02",
"type":"text"
}
],
"title":"Notes"
},
{
"children":[
{
"children":[],
"id":"53f0708b231b468d844291df3fe17cf2",
"paragraphs":[
{
"chunkpath":[],
"filepath":[
"parser.rlmeta"
],
"fragments":[
{
"text":"Parser {\n  grammar =\n    | name:x space '{' rule*:ys space '}'      -> [\"Grammar\" x ~ys]\n  rule =\n    | name:x space '=' choice:y                -> [\"Rule\" x y]\n  choice =\n    | (space '|')?\n      sequence:x (space '|' sequence)*:xs      -> [\"Or\" x ~xs]\n  sequence =\n    | expr:x expr*:xs                          -> [\"Scope\" [\"And\" x ~xs]]\n  expr =\n    | expr1:x space ':' name:y                 -> [\"Bind\" y x]\n    | expr1\n  expr1 =\n    | expr2:x space '*'                        -> [\"Star\" x]\n    | expr2:x space '?'                        -> [\"Or\" x [\"And\"]]\n    | space '!' expr2:x                        -> [\"Not\" x]\n    | space '%'                                -> [\"MatchCallRule\"]\n    | space '#'                                -> [\"Label\"]\n    | expr2\n  expr2 =\n    | space '->' hostExpr:x                    -> [\"SemanticAction\" x]\n    | name:x !(space '=')                      -> [\"MatchRule\" x]\n    | space char:x '-' char:y                  -> [\"MatchRange\" x y]\n    | space string:x                           -> [\"MatchString\" x]\n    | space charseq:x                          -> [\"MatchCharseq\" x]\n    | space '.'                                -> [\"MatchAny\"]\n    | space '(' choice:x space ')'             -> x\n    | space '[' expr*:xs space ']'             -> [\"MatchList\" [\"And\" ~xs]]\n  hostExpr =\n    | space string:x                           -> [\"String\" x]\n    | space '[' hostExprListItem*:xs space ']' -> [\"List\" ~xs]\n    | space '{' buildExpr*:xs space '}'        -> [\"Builder\" ~xs]\n    | name:x space '(' hostExpr*:ys space ')'  -> [\"FnCall\" x ~ys]\n    | name:x                                   -> [\"VarLookup\" x]\n  hostExprListItem =\n    | space '~' hostExpr:x                     -> [\"ListItemSplice\" x]\n    | hostExpr\n  buildExpr =\n    | space '>'                                -> [\"IndentBuilder\"]\n    | space '<'                                -> [\"DedentBuilder\"]\n    | hostExpr\n  string    = '\"'  (!'\"'  innerChar)*:xs '\"'   -> join(xs)\n  charseq   = '\\'' (!'\\'' innerChar)*:xs '\\''  -> join(xs)\n  char      = '\\''  !'\\'' innerChar  :x  '\\''  -> x\n  innerChar = '\\\\' escape | .\n  escape    = '\\\\' -> \"\\\\\" | '\\'' -> \"'\"\n            | '\"'  -> \"\\\"\" | 'n'  -> \"\\n\"\n  name      = space nameStart:x nameChar*:xs   -> join([x ~xs])\n  nameStart = 'a'-'z' | 'A'-'Z'\n  nameChar  = 'a'-'z' | 'A'-'Z' | '0'-'9'\n  space     = (' ' | '\\n')*\n}\n",
"type":"code"
}
],
"id":"0a3d1c1a8c4c49ab803ba2aabb11f6b1",
"language":"",
"type":"code"
}
],
"title":"parser.rlmeta"
},
{
"children":[],
"id":"74bf51f7e8d94bcba1747edb477137ef",
"paragraphs":[
{
"chunkpath":[],
"filepath":[
"codegenerator.rlmeta"
],
"fragments":[
{
"text":"CodeGenerator {\n  Grammar        = .:x ast*:ys     -> { \"class \" x \"(_Grammar):\\n\" >\n                                          \"def __init__(self):\\n\" >\n                                            \"instructions = []\\n\"\n                                            \"labels = {}\\n\"\n                                            \"def I(name, x=None, y=None):\\n\" >\n                                              \"instructions.append((name, x, y))\\n\"\n                                            <\n                                            \"def LABEL(name):\\n\" >\n                                              \"labels[name] = len(instructions)\\n\"\n                                            <\n                                            ys\n                                            \"self._instructions = instructions\\n\"\n                                            \"self._labels = labels\\n\"\n                                          <\n                                        <                                  }\n  Rule           = py:x ast:y      -> { \"LABEL(\" x \")\\n\"\n                                        y\n                                        \"I('RETURN')\\n\"                    }\n  Or             =\n    | ast:x !.                     -> x\n    | ast:x Or:y #:a #:b           -> { \"I('BACKTRACK', \" a \")\\n\"\n                                        x\n                                        \"I('COMMIT', \" b \")\\n\"\n                                        \"LABEL(\" a \")\\n\"\n                                        y\n                                        \"LABEL(\" b \")\\n\"                   }\n  Scope          = ast:x           -> { \"I('PUSH_SCOPE')\\n\"\n                                        x\n                                        \"I('POP_SCOPE')\\n\"                 }\n  And            = ast*\n  Bind           = py:x ast:y      -> { y\n                                        \"I('BIND', \" x \")\\n\"               }\n  Star           = ast:x #:a #:b   -> { \"I('LIST_START')\\n\"\n                                        \"LABEL(\" a \")\\n\"\n                                        \"I('BACKTRACK', \" b \")\\n\"\n                                        x\n                                        \"I('LIST_APPEND')\\n\"\n                                        \"I('COMMIT', \" a \")\\n\"\n                                        \"LABEL(\" b \")\\n\"\n                                        \"I('LIST_END')\\n\"                  }\n  Not            = ast:x #:a #:b   -> { \"I('BACKTRACK', \" b \")\\n\"\n                                        x\n                                        \"I('COMMIT', \" a \")\\n\"\n                                        \"LABEL(\" a \")\\n\"\n                                        \"I('FAIL')\\n\"\n                                        \"LABEL(\" b \")\\n\"                   }\n  MatchCallRule  =                 -> { \"I('MATCH_CALL_RULE')\\n\"           }\n  Label          =                 -> { \"I('LABEL')\\n\"                     }\n  SemanticAction = ast:x           -> { \"I('ACTION', lambda env: \" x \")\\n\" }\n  MatchRule      = py:x            -> { \"I('CALL', \" x \")\\n\"               }\n  MatchRange     = py:x py:y       -> { \"I('MATCH_RANGE', \" x \", \" y \")\\n\" }\n  MatchString    = py:x            -> { \"I('MATCH_STRING', \" x \")\\n\"       }\n  MatchCharseq   = py:x            -> { \"I('MATCH_CHARSEQ', \" x \")\\n\"      }\n  MatchAny       =                 -> { \"I('MATCH_ANY')\\n\"                 }\n  MatchList      = ast:x           -> { \"I('PUSH_INPUT')\\n\"\n                                        x\n                                        \"I('POP_INPUT')\\n\"                 }\n  String         = py\n  List           = astList:x       -> { x                                  }\n  Builder        = astItems:x      -> { \"_Builder.create([\" x \"])\"         }\n  IndentBuilder  =                 -> { \"_IndentBuilder()\"                 }\n  DedentBuilder  =                 -> { \"_DedentBuilder()\"                 }\n  FnCall         = .:x astItems:y  -> { x \"(\" y \")\"                        }\n  VarLookup      = py:x            -> { \"env[\" x \"].eval()\"                }\n  ast            = [%:x]           -> { x                                  }\n  astItems       =\n    | ast:x astItem*:xs            -> { x xs                               }\n    |                              -> {                                    }\n  astItem        = ast:x           -> { \", \" x                             }\n  astList        = astListItem*:xs -> { \"(\" xs \"[])\"                       }\n  astListItem    =\n    | [\"ListItemSplice\" ast:x]     -> {     x  \"+\"                         }\n    | ast:x                        -> { \"[\" x \"]+\"                         }\n  py             = .:x             -> repr(x)\n}\n",
"type":"code"
}
],
"id":"c4887eaa08da4799acaad6fdbde5d2f7",
"language":"",
"type":"code"
}
],
"title":"codegenerator.rlmeta"
},
{
"children":[],
"id":"60ff77cb85fa455589e3e45cdeac8160",
"paragraphs":[
{
"code_id":"4d06e64ddc8941928ee419ac82f56c4d",
"id":"36d97cd6364b4b7c92b9088f6542db59",
"type":"expanded_code"
}
],
"title":"support.py"
},
{
"children":[],
"id":"338ad257e61e4025b8859d610a475c6a",
"paragraphs":[
{
"chunkpath":[],
"filepath":[
"compile.sh"
],
"fragments":[
{
"text":"#!/bin/bash\n\nset -e\n\nrlmeta_compiler=\"$(pwd)/$1\"\n\ncd \"$(dirname \"$0\")\"\n\nto_python_string() {\n    python -c 'import sys; sys.stdout.write(repr(sys.stdin.read()))'\n}\n\nsupport_py_string=$(to_python_string < support.py)\nsupport_py=$(python \"$rlmeta_compiler\" --support)\nparser_py=$(python \"$rlmeta_compiler\" < parser.rlmeta)\ncodegenerator_py=$(python \"$rlmeta_compiler\" < codegenerator.rlmeta)\n\ncat <<EOF\nimport sys\n\nSUPPORT = $support_py_string\n\n$support_py\n\n$parser_py\n\n$codegenerator_py\n\njoin = \"\".join\n\ndef compile_grammar(grammar):\n    parser = Parser()\n    code_generator = CodeGenerator()\n    return code_generator.run(\"ast\", parser.run(\"grammar\", grammar))\n\nif __name__ == \"__main__\":\n    if \"--support\" in sys.argv:\n        sys.stdout.write(SUPPORT)\n    else:\n        sys.stdout.write(compile_grammar(sys.stdin.read()))\nEOF\n",
"type":"code"
}
],
"id":"5603502f765e4392be55f0ad5f8ec9ac",
"type":"code"
}
],
"title":"compile.sh"
},
{
"children":[],
"id":"272d17f2d55749b59d7e5ec7b9b8e0ec",
"paragraphs":[
{
"chunkpath":[],
"filepath":[
"meta_compile.sh"
],
"fragments":[
{
"text":"#!/bin/bash\n\nset -e\n\ncd \"$(dirname \"$0\")\"\n\n./compile.sh rlmeta.py > rlmeta1.py\n\n./compile.sh rlmeta1.py > rlmeta2.py\n\n./compile.sh rlmeta2.py > rlmeta3.py\n\n./compile.sh rlmeta3.py > rlmeta4.py\n\ndiff rlmeta3.py rlmeta4.py\n\ndiff support.py <(python rlmeta3.py --support)\n\nmv rlmeta4.py rlmeta3.py\n\nmv rlmeta3.py rlmeta2.py\n\nmv rlmeta2.py rlmeta1.py\n\nmv rlmeta1.py rlmeta.py\n\necho OK\n",
"type":"code"
}
],
"id":"59997b4d5c134c4183d2f5a1f8804543",
"type":"code"
}
],
"title":"meta_compile.sh"
}
],
"id":"7e7b4c5318ff4c849c6e98e9ddeaacf0",
"paragraphs":[],
"title":"Code listings for RLMeta"
}
],
"id":"3dffd837b9ec4ad88b4e7f4c4b3b5aae",
"paragraphs":[
{
"fragments":[
{
"text":"In this article we change how RLMeta is executed. Instead of compiling it to a Python class, we will instead compile it to a sequence of bytecode instructions for a virtual machine that we define.",
"type":"text"
}
],
"id":"ad1d041250524b98a193f9fd3fa627f5",
"type":"text"
}
],
"title":"RLMeta: a VM based approach"
},
"variables":{}
}