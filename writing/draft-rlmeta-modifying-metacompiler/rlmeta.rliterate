{
"root_page":{
"children":[
{
"children":[],
"id":"bf2e6a99e41f478f884dd15ea243c111",
"paragraphs":[
{
"fragments":[
{
"text":"The compile.sh scripts compiles the RLMeta compiler. The inputs are the RLMeta source files (parser.rlmeta, codegenerator.rlmeta, and support.py) and the output is the RLMeta compiler (rlmeta.py). The resulting rlmeta.py file looks like follows with the templates expanded:",
"type":"text"
}
],
"id":"ac4e4f2a863f48e4a82eddbc322b4d54",
"type":"text"
},
{
"chunkpath":[
"rlmeta template"
],
"filepath":[
"compile.sh"
],
"fragments":[
{
"text":"import sys\n\nSUPPORT = $support_py_string\n\n$support_py\n\n$parser_py\n\n$codegenerator_py\n\njoin = \"\".join\n\ndef compile_grammar(grammar):\n    parser = Parser()\n    code_generator = CodeGenerator()\n    return code_generator.run(\"ast\", parser.run(\"grammar\", grammar))\n\nif __name__ == \"__main__\":\n    if \"--support\" in sys.argv:\n        sys.stdout.write(SUPPORT)\n    else:\n        try:\n            sys.stdout.write(compile_grammar(sys.stdin.read()))\n        except _MatchError as e:\n            sys.stderr.write(e.describe())\n            sys.exit(1)\n",
"type":"code"
}
],
"id":"cab1f5d6d3c0412696419fd2f8c0ab88",
"language":"python",
"type":"code"
},
{
"chunkpath":[],
"filepath":[],
"fragments":[
{
"text":"$ diff <(./compile.sh rlmeta.py) rlmeta.py && echo EQUAL\nEQUAL\n",
"type":"code"
}
],
"id":"51c75af0347d416181ffec8cab1f0c51",
"type":"code"
}
],
"title":"How is RLMeta a metacompiler?"
},
{
"children":[],
"id":"93d9030e0e4849c5a8d8ca0fffdf7592",
"paragraphs":[],
"title":"Why is this a useful property?"
},
{
"children":[
{
"children":[],
"id":"bb30e8cebfc54d6999b9983378315598",
"paragraphs":[
{
"chunkpath":[],
"filepath":[
"parser.rlmeta"
],
"fragments":[
{
"text":"Parser {\n  grammar =\n    | name:x space '{' rule*:ys space '}'      -> [\"Grammar\" x ~ys]\n  rule =\n    | name:x space '=' choice:y                -> [\"Rule\" x y]\n  choice =\n    | (space '|')?\n      sequence:x (space '|' sequence)*:xs      -> [\"Or\" x ~xs]\n  sequence =\n    | expr:x expr*:xs                          -> [\"Scope\" [\"And\" x ~xs]]\n  expr =\n    | expr1:x space ':' name:y                 -> [\"Bind\" y x]\n    | expr1\n  expr1 =\n    | expr2:x space '*'                        -> [\"Star\" x]\n    | expr2:x space '?'                        -> [\"Or\" x [\"And\"]]\n    | space '!' expr2:x                        -> [\"Not\" x]\n    | expr2\n  expr2 =\n    | space '->' hostExpr:x                    -> [\"SemanticAction\" x]\n    | name:x !(space '=')                      -> [\"MatchRule\" x]\n    | space char:x '-' char:y                  -> [\"MatchRange\" x y]\n    | space string:x                           -> [\"MatchString\" x]\n    | space charseq:x                          -> [\"MatchCharseq\" x]\n    | space '.'                                -> [\"MatchAny\"]\n    | space '(' choice:x space ')'             -> x\n    | space '[' expr*:xs space ']'             -> [\"MatchList\" [\"And\" ~xs]]\n  hostExpr =\n    | space string:x                           -> [\"String\" x]\n    | space '[' hostExprListItem*:xs space ']' -> [\"List\" ~xs]\n    | space '{' buildExpr*:xs space '}'        -> [\"Builder\" ~xs]\n    | name:x space '(' hostExpr*:ys space ')'  -> [\"FnCall\" x ~ys]\n    | name:x                                   -> [\"VarLookup\" x]\n  hostExprListItem =\n    | space '~' hostExpr:x                     -> [\"ListItemSplice\" x]\n    | hostExpr\n  buildExpr =\n    | space '>'                                -> [\"IndentBuilder\"]\n    | space '<'                                -> [\"DedentBuilder\"]\n    | hostExpr\n  string    = '\"'  (!'\"'  innerChar)*:xs '\"'   -> join(xs)\n  charseq   = '\\'' (!'\\'' innerChar)*:xs '\\''  -> join(xs)\n  char      = '\\''  !'\\'' innerChar  :x  '\\''  -> x\n  innerChar = '\\\\' escape | .\n  escape    = '\\\\' -> \"\\\\\" | '\\'' -> \"'\"\n            | '\"'  -> \"\\\"\" | 'n'  -> \"\\n\"\n  name      = space nameStart:x nameChar*:xs   -> join([x ~xs])\n  nameStart = 'a'-'z' | 'A'-'Z'\n  nameChar  = 'a'-'z' | 'A'-'Z' | '0'-'9'\n  space     = (' ' | '\\n')*\n}\n",
"type":"code"
}
],
"id":"46060bbf922841829adb3d3566a31960",
"type":"code"
}
],
"title":"parser.rlmeta"
},
{
"children":[],
"id":"ad4cf425e325476bbe0fd6821dc13b5c",
"paragraphs":[
{
"chunkpath":[],
"filepath":[
"codegenerator.rlmeta"
],
"fragments":[
{
"text":"CodeGenerator {\n  ast =\n    | [\"Grammar\" .:x ast*:ys]   -> { \"class \" x \"(_Grammar):\\n\" > ys <                   }\n    | [\"Rule\" .:x ast:y]        -> { \"\\ndef _rule_\" x \"(self):\\n\" > \"return \" y \"()\\n\" < }\n    | [\"MatchAny\"]              -> { \"self._match_any\"                                   }\n    | [\"String\" .:x]            -> { repr(x)                                             }\n    | [\"List\" astList:x]        -> { x                                                   }\n    | [\"Builder\" astItems:x]    -> { \"_Builder.create([\" x \"])\"                          }\n    | [\"IndentBuilder\"]         -> { \"_IndentBuilder()\"                                  }\n    | [\"DedentBuilder\"]         -> { \"_DedentBuilder()\"                                  }\n    | [\"FnCall\" .:x astItems:y] -> { x \"(\" y \")\"                                         }\n    | [\"VarLookup\" .:x]         -> { \"_vars.lookup(\" repr(x) \").eval()\"                  }\n    | astFnBody:x               -> { \"(lambda:\\n\" > x < \"\\n)\" }\n  astFnBody =\n    | [\"Or\" astItems:x]         -> { \"self._or([\" x \"])\"                                 }\n    | [\"Scope\" ast:x]           -> { \"(lambda _vars:\\n\" > x < \"()\\n)(_Vars())\"           }\n    | [\"And\" astItems:x]        -> { \"self._and([\" x \"])\"                                }\n    | [\"Bind\" .:x ast:y]        -> { \"_vars.bind(\" repr(x) \", \" y \"())\"                  }\n    | [\"Star\" ast:x]            -> { \"self._star(\" x \")\"                                 }\n    | [\"Not\" ast:x]             -> { \"self._not(\" x \")\"                                  }\n    | [\"SemanticAction\" ast:x]  -> { \"_SemanticAction(lambda: \" x \")\"                    }\n    | [\"MatchRule\" .:x]         -> { \"self._match_rule(\" repr(x) \")\"                     }\n    | [\"MatchRange\" .:x .:y]    -> { \"self._match_range(\" repr(x) \", \" repr(y) \")\"       }\n    | [\"MatchString\" .:x]       -> { \"self._match_string(\" repr(x) \")\"                   }\n    | [\"MatchCharseq\" .:x]      -> { \"self._match_charseq(\" repr(x) \")\"                  }\n    | [\"MatchList\" ast:x]       -> { \"self._match_list(\" x \")\"                           }\n  astItems = astItem*:xs        -> { \"\\n\" > xs <                                         }\n  astItem  = ast:x              -> { x \",\\n\"                                             }\n  astList  = astListItem*:xs    -> { \"(\" xs \"[])\"                                        }\n  astListItem =\n    | [\"ListItemSplice\" ast:x]  -> {     x  \"+\"                                          }\n    | ast:x                     -> { \"[\" x \"]+\"                                          }\n}\n",
"type":"code"
}
],
"id":"0113afdf98334edd9dfcfb0e5aed69f3",
"type":"code"
}
],
"title":"codegenerator.rlmeta"
},
{
"children":[],
"id":"5a6f1b7a39774ed690f27824793b1552",
"paragraphs":[
{
"chunkpath":[],
"filepath":[
"support.py"
],
"fragments":[
{
"text":"class _Grammar(object):\n\n    def _or(self, matchers):\n        original_stream = self._stream\n        for matcher in matchers:\n            try:\n                return matcher()\n            except _MatchError:\n                self._stream = original_stream\n        original_stream.fail(\"no choice matched\")\n\n    def _and(self, matchers):\n        result = None\n        for matcher in matchers:\n            result = matcher()\n        return result\n\n    def _star(self, matcher):\n        result = []\n        while True:\n            original_stream = self._stream\n            try:\n                result.append(matcher())\n            except _MatchError:\n                self._stream = original_stream\n                return _SemanticAction(lambda: [x.eval() for x in result])\n\n    def _not(self, matcher):\n        original_stream = self._stream\n        try:\n            matcher()\n        except _MatchError:\n            return _SemanticAction(lambda: None)\n        else:\n            original_stream.fail(\"match found\")\n        finally:\n            self._stream = original_stream\n\n    def _match_rule(self, rule_name):\n        key = (rule_name, self._stream.position())\n        if key in self._memo:\n            result, _, self._stream = self._memo[key]\n        else:\n            start = self._stream\n            result = getattr(self, \"_rule_{}\".format(rule_name))()\n            end = self._stream\n            self._memo[key] = (result, start, end)\n        return result\n\n    def _match_range(self, start, end):\n        original_stream = self._stream\n        next_objext, self._stream = self._stream.next()\n        if next_objext >= start and next_objext <= end:\n            return _SemanticAction(lambda: next_objext)\n        else:\n            original_stream.fail(\n                \"expected range {!r}-{!r} but found {!r}\".format(start, end, next_objext)\n            )\n\n    def _match_string(self, string):\n        original_stream = self._stream\n        next_object, self._stream = self._stream.next()\n        if next_object == string:\n            return _SemanticAction(lambda: string)\n        else:\n            original_stream.fail(\n                \"expected {!r} but found {!r}\".format(string, next_object)\n            )\n\n    def _match_charseq(self, charseq):\n        for char in charseq:\n            original_stream = self._stream\n            next_object, self._stream = self._stream.next()\n            if next_object != char:\n                original_stream.fail(\n                    \"expected {!r} but found {!r}\".format(char, next_object)\n                )\n        return _SemanticAction(lambda: charseq)\n\n    def _match_any(self):\n        next_object, self._stream = self._stream.next()\n        return _SemanticAction(lambda: next_object)\n\n    def _match_list(self, matcher):\n        original_stream = self._stream\n        next_object, next_stream = self._stream.next()\n        if isinstance(next_object, list):\n            self._stream = self._stream.nested(next_object)\n            matcher()\n            if self._stream.is_at_end():\n                self._stream = next_stream\n                return _SemanticAction(lambda: next_object)\n        original_stream.fail(\"list match failed\")\n\n    def run(self, rule_name, input_object):\n        self._memo = _Memo()\n        self._stream = _Stream.from_object(self._memo, input_object)\n        result = self._match_rule(rule_name).eval()\n        if isinstance(result, _Builder):\n            return result.build_string()\n        else:\n            return result\n\nclass _Vars(dict):\n\n    def bind(self, name, value):\n        self[name] = value\n        return value\n\n    def lookup(self, name):\n        return self[name]\n\nclass _SemanticAction(object):\n\n    def __init__(self, fn):\n        self.fn = fn\n\n    def eval(self):\n        return self.fn()\n\nclass _Builder(object):\n\n    def build_string(self):\n        output = _Output()\n        self.write(output)\n        return output.value\n\n    @classmethod\n    def create(self, item):\n        if isinstance(item, _Builder):\n            return item\n        elif isinstance(item, list):\n            return _ListBuilder([_Builder.create(x) for x in item])\n        else:\n            return _AtomBuilder(item)\n\nclass _Output(object):\n\n    def __init__(self):\n        self.value = \"\"\n        self.indentation = 0\n\n    def write(self, value):\n        for ch in value:\n            if self.value and ch != \"\\n\" and self.value[-1] == \"\\n\":\n                self.value += \"    \"*self.indentation\n            self.value += ch\n\nclass _ListBuilder(_Builder):\n\n    def __init__(self, builders):\n        self.builders = builders\n\n    def write(self, output):\n        for builder in self.builders:\n            builder.write(output)\n\nclass _AtomBuilder(_Builder):\n\n    def __init__(self, atom):\n        self.atom = atom\n\n    def write(self, output):\n        output.write(str(self.atom))\n\nclass _IndentBuilder(_Builder):\n\n    def write(self, output):\n        output.indentation += 1\n\nclass _DedentBuilder(_Builder):\n\n    def write(self, output):\n        output.indentation -= 1\n\nclass _Memo(dict):\n\n    def __init__(self):\n        dict.__init__(self)\n        self._latest_stream = _ObjectStream(self, [], position=-1)\n        self._latest_message = \"\"\n\n    def describe(self):\n        items = []\n        for (rule_name, _), (_, start, end) in self.items():\n            if end > start:\n                items.append((rule_name, start, end))\n        items.sort(key=lambda item: (item[2].position(), item[1].position()))\n        message = []\n        for item in items:\n            message.append(\"matched {: <20} {} -> {}\\n\".format(*item))\n        message.append(\"\\n\")\n        message.append(\"ERROR: {}: {}\\n\".format(\n            self._latest_stream,\n            self._latest_message\n        ))\n        return \"\".join(message)\n\n    def fail(self, stream, message):\n        if stream.position() >= self._latest_stream.position():\n            self._latest_stream = stream\n            self._latest_message = message\n        raise _MatchError(self)\n\nclass _MatchError(Exception):\n\n    def __init__(self, memo):\n        Exception.__init__(self)\n        self._memo = memo\n\n    def describe(self):\n        return self._memo.describe()\n\nclass _Stream(object):\n\n    @classmethod\n    def from_object(cls, memo, input_object):\n        if isinstance(input_object, basestring):\n            return _CharStream(memo, list(input_object))\n        else:\n            return _ObjectStream(memo, [input_object])\n\n    def __init__(self, memo, objects):\n        self._memo = memo\n        self._objects = objects\n\n    def fail(self, message):\n        self._memo.fail(self, message)\n\n    def next(self):\n        if self.is_at_end():\n            self.fail(\"not eof\")\n        next_object = self._objects[0]\n        return (\n            next_object,\n            self._advance(next_object, self._objects[1:]),\n        )\n\n    def is_at_end(self):\n        return len(self._objects) == 0\n\nclass _CharStream(_Stream):\n\n    def __init__(self, memo, objects, line=1, column=1):\n        _Stream.__init__(self, memo, objects)\n        self._line = line\n        self._column = column\n\n    def position(self):\n        return (self._line, self._column)\n\n    def _advance(self, next_object, objects):\n        if next_object == \"\\n\":\n            return _CharStream(self._memo, objects, self._line+1, 1)\n        else:\n            return _CharStream(self._memo, objects, self._line, self._column+1)\n\n    def __str__(self):\n        return \"L{:03d}:C{:03d}\".format(self._line, self._column)\n\nclass _ObjectStream(_Stream):\n\n    def __init__(self, memo, objects, parent=(), position=0):\n        _Stream.__init__(self, memo, objects)\n        self._parent = parent\n        self._position = position\n\n    def position(self):\n        return self._parent + (self._position,)\n\n    def nested(self, input_object):\n        return _ObjectStream(self._memo, input_object, self._parent+(self._position,))\n\n    def _advance(self, next_object, objects):\n        return _ObjectStream(self._memo, objects, self._parent, self._position+1)\n\n    def __str__(self):\n        return \"[{}]\".format(\", \".join(str(x) for x in self.position()))\n",
"type":"code"
}
],
"id":"d1256933edc84b45b5d630115e83d454",
"type":"code"
}
],
"title":"support.py"
},
{
"children":[],
"id":"01dd3721287a4b3eb6671a0f3fd99128",
"paragraphs":[
{
"chunkpath":[],
"filepath":[
"compile.sh"
],
"fragments":[
{
"text":"#!/bin/bash\n\nset -e\n\nrlmeta_compiler=\"$(pwd)/$1\"\n\ncd \"$(dirname \"$0\")\"\n\nto_python_string() {\n    python -c 'import sys; sys.stdout.write(repr(sys.stdin.read()))'\n}\n\nsupport_py_string=$(to_python_string < support.py)\nsupport_py=$(python \"$rlmeta_compiler\" --support)\nparser_py=$(python \"$rlmeta_compiler\" < parser.rlmeta)\ncodegenerator_py=$(python \"$rlmeta_compiler\" < codegenerator.rlmeta)\n\ncat <<EOF\n",
"type":"code"
},
{
"blank_lines_before":0,
"path":[
"rlmeta template"
],
"prefix":"",
"type":"chunk"
},
{
"text":"EOF\n",
"type":"code"
}
],
"id":"ef234944361c48eeb16387d8014a4c9b",
"type":"code"
}
],
"title":"compile.sh"
},
{
"children":[],
"id":"d910746e68c1406c97a054c4f6e56573",
"paragraphs":[
{
"chunkpath":[],
"filepath":[
"meta_compile.sh"
],
"fragments":[
{
"text":"#!/bin/bash\n\nset -e\n\ncd \"$(dirname \"$0\")\"\n\n./compile.sh rlmeta.py > rlmeta1.py\n\n./compile.sh rlmeta1.py > rlmeta2.py\n\n./compile.sh rlmeta2.py > rlmeta3.py\n\ndiff rlmeta2.py rlmeta3.py\n\ndiff support.py <(python rlmeta3.py --support)\n\nmv rlmeta3.py rlmeta2.py\n\nmv rlmeta2.py rlmeta1.py\n\nmv rlmeta1.py rlmeta.py\n\necho OK\n",
"type":"code"
}
],
"id":"bd7e31bf3ea7456f975830d5bf2ef05c",
"type":"code"
}
],
"title":"meta_compile.sh"
}
],
"id":"d54bbeda3d9846bca027f2c2995775a5",
"paragraphs":[],
"title":"Code listings for RLMeta"
}
],
"id":"7b987f7cd685486da72bf77dcd0b3f29",
"paragraphs":[],
"title":"Modifying RLMeta"
},
"variables":{}
}