{
"root_page":{
"children":[
{
"children":[],
"id":"39efe623ff374daba9830984300fcde2",
"paragraphs":[
{
"fragments":[
{
"text":"A metacompiler is a compiler that can reproduce itself from a high-level description.",
"type":"text"
}
],
"id":"528a58686ce442d79e1b367408fe944c",
"type":"text"
},
{
"fragments":[
{
"text":"A generic compiler takes source as input and produces output:",
"type":"text"
}
],
"id":"e192774e5eeb495589a7021b6f8f4d88",
"type":"text"
},
{
"chunkpath":[],
"filepath":[],
"fragments":[
{
"text":"source -> compiler -> output\n",
"type":"code"
}
],
"id":"84b2d2ffe1b641c388d7f834af5e427b",
"type":"code"
},
{
"fragments":[
{
"text":"The output produced by a metacompiler is itself (given that the source is the source for the metacompiler):",
"type":"text"
}
],
"id":"05285271f1cc494ca90f7d3d9a1dcd91",
"type":"text"
},
{
"chunkpath":[],
"filepath":[],
"fragments":[
{
"text":"source -> metacompiler -----\n               ^           |\n               |           |\n               -------------\n",
"type":"code"
}
],
"id":"af656248fc3845cfab5327911291fb11",
"type":"code"
},
{
"fragments":[
{
"text":"A C compiler written in C is not a metacompiler because C is not a high-level description. ",
"type":"text"
}
],
"id":"68a70728549c41478d8110b0248c678c",
"type":"text"
}
],
"title":"What is a metacompiler?"
},
{
"children":[],
"id":"bf2e6a99e41f478f884dd15ea243c111",
"paragraphs":[
{
"fragments":[
{
"text":"RLMeta is a metacompiler because its source is written in a high-level language and it is able to reproduce itself.",
"type":"text"
}
],
"id":"d86dd49a17e94d2694bedd68c178a028",
"type":"text"
},
{
"fragments":[
{
"text":"The ",
"type":"text"
},
{
"text":"compile.sh",
"type":"code"
},
{
"text":" scripts compiles the RLMeta compiler. It compiles the sources (",
"type":"text"
},
{
"text":"parser.rlmeta",
"type":"code"
},
{
"text":" and ",
"type":"text"
},
{
"text":"codegenerator.rlmeta",
"type":"code"
},
{
"text":") and combines the output with the support library (",
"type":"text"
},
{
"text":"support.py",
"type":"code"
},
{
"text":") and code to invoke it all.",
"type":"text"
}
],
"id":"ac4e4f2a863f48e4a82eddbc322b4d54",
"type":"text"
},
{
"chunkpath":[],
"filepath":[],
"fragments":[
{
"text":"        compile.sh\n|--------------------------|\n| source -> metacompiler --|---\n|                ^         |  |\n|                |         |  |\n|                ----------|---\n|--------------------------|\n",
"type":"code"
}
],
"id":"6bba4e434dc44f8181caf4c5ccfee01e",
"type":"code"
},
{
"code_id":"ef234944361c48eeb16387d8014a4c9b",
"id":"e4c95da40c294c278c528f1c6fbb389d",
"type":"expanded_code"
},
{
"fragments":[
{
"text":"How can it be verified that RLMeta is a metacompiler? The following script does it by comparing the current compiler to the one generated by the ",
"type":"text"
},
{
"text":"compile.sh",
"type":"code"
},
{
"text":" script. If they are equal the compiler reproduced itself exactly, and is thus a metacompiler. Otherwise the two compilers differ.",
"type":"text"
}
],
"id":"734c020ee59a4446a84baeeab3e5c655",
"type":"text"
},
{
"chunkpath":[],
"filepath":[
"is_metacompiler.sh"
],
"fragments":[
{
"text":"if diff $1 <(./compile.sh $1); then\n    echo \"$1 is a metacompiler!\"\nelse\n    echo \"$1 is not a metacompiler. See diff above.\"\nfi\n",
"type":"code"
}
],
"id":"51c75af0347d416181ffec8cab1f0c51",
"type":"code"
},
{
"fragments":[
{
"text":"To prove:",
"type":"text"
}
],
"id":"52191a29ca4d4462860c0a2552160441",
"type":"text"
},
{
"chunkpath":[],
"filepath":[],
"fragments":[
{
"text":"$ ./is_metacompiler.sh rlmeta.py\nrlmeta.py is a metacompiler!\n",
"type":"code"
}
],
"id":"8e96b580ce5c4ed2bc67997925bc1117",
"type":"code"
}
],
"title":"Is RLMeta a metacompiler?"
},
{
"children":[],
"id":"93d9030e0e4849c5a8d8ca0fffdf7592",
"paragraphs":[
{
"fragments":[
{
"text":"Yes, WHYY?",
"type":"text"
}
],
"id":"fc4349d271d2479885e24591439782a2",
"type":"text"
},
{
"fragments":[
{
"text":"In order to modify rlmeta.py we need the source code and a compiler. If there is no way we can reproduce it, we can't modify it.",
"type":"text"
}
],
"id":"c7f676bd1b8e4759bb676cb020172a36",
"type":"text"
}
],
"title":"Why is this a useful property?"
},
{
"children":[],
"id":"5f6a1c91143146dbb3b865ac42562135",
"paragraphs":[
{
"chunkpath":[],
"filepath":[],
"fragments":[
{
"text":"    | astFnBody:x               -> { \"(lambda:\\n\" > x < \"\\n)\" }\n",
"type":"code"
}
],
"id":"75962a34bc124422840c608c5ce11574",
"language":"rlmeta",
"type":"code"
},
{
"chunkpath":[],
"filepath":[],
"fragments":[
{
"text":"    | astFnBody:x               -> { \"(lambda: \" x \")\" }\n",
"type":"code"
}
],
"id":"00aa8eafb77042e58c86e630149b9d27",
"language":"rlmeta",
"type":"code"
},
{
"chunkpath":[],
"filepath":[],
"fragments":[
{
"text":"$ git diff codegenerator.rlmeta\ndiff --git a/writing/draft-rlmeta-modifying-metacompiler/codegenerator.rlmeta b/writing/draft-rlmeta-modifying-metacompiler/codegenerator.rlmeta\nindex 293e013..657f59a 100644\n--- a/writing/draft-rlmeta-modifying-metacompiler/codegenerator.rlmeta\n+++ b/writing/draft-rlmeta-modifying-metacompiler/codegenerator.rlmeta\n@@ -10,7 +10,7 @@ CodeGenerator {\n     | [\"DedentBuilder\"]         -> { \"_DedentBuilder()\"                                  }\n     | [\"FnCall\" .:x astItems:y] -> { x \"(\" y \")\"                                         }\n     | [\"VarLookup\" .:x]         -> { \"_vars.lookup(\" repr(x) \").eval()\"                  }\n-    | astFnBody:x               -> { \"(lambda:\\n\" > x < \"\\n)\" }\n+    | astFnBody:x               -> { \"(lambda: \" x \")\" }\n   astFnBody =\n     | [\"Or\" astItems:x]         -> { \"self._or([\" x \"])\"                                 }\n     | [\"Scope\" ast:x]           -> { \"(lambda _vars:\\n\" > x < \"()\\n)(_Vars())\"           }\n",
"type":"code"
}
],
"id":"0bc5ae207dbd4ea3b41a00651d0d1873",
"language":"diff",
"type":"code"
},
{
"fragments":[
{
"text":"Is rlmeta.py a metacompiler? Le'ts check:",
"type":"text"
}
],
"id":"c16df5bc53fc422796deaf081c25ae8b",
"type":"text"
},
{
"chunkpath":[],
"filepath":[],
"fragments":[
{
"text":"$ diff rlmeta.py <(./compile.sh rlmeta.py)\n1685,1686c1685\n<                                         '(lambda:\\n',\n<                                         _IndentBuilder(),\n---\n>                                         '(lambda: ',\n1688,1689c1687\n<                                         _DedentBuilder(),\n<                                         '\\n)',\n---\n> \n",
"type":"code"
}
],
"id":"90cf5d9eca604cd8becd3e9feca345dc",
"language":"diff",
"type":"code"
},
{
"chunkpath":[],
"filepath":[],
"fragments":[
{
"text":"$ ./compile.sh rlmeta.py > rlmeta1.py\n",
"type":"code"
}
],
"id":"7a6b856affa54cc4bdb62fd5a0b4f137",
"type":"code"
},
{
"fragments":[
{
"text":"Is rlmeta1.py a metacompiler? Le'ts check:",
"type":"text"
}
],
"id":"4818c579d5da41caa796d973b28d6752",
"type":"text"
},
{
"chunkpath":[],
"filepath":[],
"fragments":[
{
"text":"$ ./is_metacompiler.sh rlmeta1.py\n287,325c287,299\n<         return (lambda:\n<             self._or([\n<                 (lambda:\n<                     (lambda _vars:\n<                         (lambda:\n<                             self._and([\n<                                 (lambda:\n<                                     _vars.bind('x', (lambda:\n<                                         self._match_rule('name')\n<                                     )())\n<                                 ),\n<                                 (lambda:\n<                                     self._match_rule('space')\n<                                 ),\n<                                 (lambda:\n<                                     self._match_charseq('{')\n<                                 ),\n<                                 (lambda:\n<                                     _vars.bind('ys', (lambda:\n<                                         self._star((lambda:\n<                                             self._match_rule('rule')\n<                                         ))\n<                                     )())\n<                                 ),\n<                                 (lambda:\n<                                     self._match_rule('space')\n<                                 ),\n<                                 (lambda:\n<                                     self._match_charseq('}')\n<                                 ),\n<                                 (lambda:\n<                                     _SemanticAction(lambda: (['Grammar']+[_vars.lookup('x').eval()]+_vars.lookup('ys').eval()+[]))\n<                                 ),\n<                             ])\n<                         )()\n<                     )(_Vars())\n<                 ),\n<             ])\n<         )()\n---\n>         return (lambda: self._or([\n>             (lambda: (lambda _vars:\n>                 (lambda: self._and([\n>                     (lambda: _vars.bind('x', (lambda: self._match_rule('name'))())),\n>                     (lambda: self._match_rule('space')),\n>                     (lambda: self._match_charseq('{')),\n>                     (lambda: _vars.bind('ys', (lambda: self._star((lambda: self._match_rule('rule'))))())),\n>                     (lambda: self._match_rule('space')),\n>                     (lambda: self._match_charseq('}')),\n>                     (lambda: _SemanticAction(lambda: (['Grammar']+[_vars.lookup('x').eval()]+_vars.lookup('ys').eval()+[]))),\n>                 ]))()\n>             )(_Vars())),\n>         ]))()\n...\nrlmeta1.py is not a metacompiler. See diff above.\n",
"type":"code"
}
],
"id":"27880ff33fae4aafa40bd977cc4cd0c4",
"language":"diff",
"type":"code"
},
{
"chunkpath":[],
"filepath":[],
"fragments":[
{
"text":"$ ./compile.sh rlmeta1.py > rlmeta2.py\n",
"type":"code"
}
],
"id":"220782c1b04d44718525cae19adfc70b",
"type":"code"
},
{
"chunkpath":[],
"filepath":[],
"fragments":[
{
"text":"$ ./is_metacompiler.sh rlmeta2.py\nrlmeta2.py is a metacompiler!\n",
"type":"code"
}
],
"id":"02c659d8ee7e4f9797fb9ca93a1fa1a4",
"type":"code"
},
{
"fragments":[
{
"text":"This means that rlmeta2.py is a metacompiler. The compiler that rlmeta2.py produces is exactly the same as itself.",
"type":"text"
}
],
"id":"6b890adad1964ae9b928a7531d2c1793",
"type":"text"
},
{
"chunkpath":[],
"filepath":[
"meta_compile.sh"
],
"fragments":[
{
"text":"#!/bin/bash\n\nset -e\n\ncd \"$(dirname \"$0\")\"\n\n./compile.sh rlmeta.py > rlmeta1.py\n\n./compile.sh rlmeta1.py > rlmeta2.py\n\n./compile.sh rlmeta2.py > rlmeta3.py\n\ndiff rlmeta2.py rlmeta3.py\n\ndiff support.py <(python rlmeta3.py --support)\n\nmv rlmeta3.py rlmeta2.py\n\nmv rlmeta2.py rlmeta1.py\n\nmv rlmeta1.py rlmeta.py\n\necho OK\n",
"type":"code"
}
],
"id":"bd7e31bf3ea7456f975830d5bf2ef05c",
"type":"code"
}
],
"title":"Making a change"
},
{
"children":[],
"id":"0130b76cb3d24f458bb47debb6fc2780",
"paragraphs":[
{
"fragments":[
{
"text":"Explain how bug was fixed.",
"type":"text"
}
],
"id":"a7b2bbcc13a9431da6c2fbb3c4c9ec41",
"type":"text"
},
{
"fragments":[
{
"text":"Generate support.py from compiler instead of from source.",
"type":"text"
}
],
"id":"0b7839572c9940dabc0e4afe5343ab9b",
"type":"text"
}
],
"title":"Changing support"
},
{
"children":[
{
"children":[],
"id":"bb30e8cebfc54d6999b9983378315598",
"paragraphs":[
{
"chunkpath":[],
"filepath":[
"parser.rlmeta"
],
"fragments":[
{
"text":"Parser {\n  grammar =\n    | name:x space '{' rule*:ys space '}'      -> [\"Grammar\" x ~ys]\n  rule =\n    | name:x space '=' choice:y                -> [\"Rule\" x y]\n  choice =\n    | (space '|')?\n      sequence:x (space '|' sequence)*:xs      -> [\"Or\" x ~xs]\n  sequence =\n    | expr:x expr*:xs                          -> [\"Scope\" [\"And\" x ~xs]]\n  expr =\n    | expr1:x space ':' name:y                 -> [\"Bind\" y x]\n    | expr1\n  expr1 =\n    | expr2:x space '*'                        -> [\"Star\" x]\n    | expr2:x space '?'                        -> [\"Or\" x [\"And\"]]\n    | space '!' expr2:x                        -> [\"Not\" x]\n    | expr2\n  expr2 =\n    | space '->' hostExpr:x                    -> [\"SemanticAction\" x]\n    | name:x !(space '=')                      -> [\"MatchRule\" x]\n    | space char:x '-' char:y                  -> [\"MatchRange\" x y]\n    | space string:x                           -> [\"MatchString\" x]\n    | space charseq:x                          -> [\"MatchCharseq\" x]\n    | space '.'                                -> [\"MatchAny\"]\n    | space '(' choice:x space ')'             -> x\n    | space '[' expr*:xs space ']'             -> [\"MatchList\" [\"And\" ~xs]]\n  hostExpr =\n    | space string:x                           -> [\"String\" x]\n    | space '[' hostExprListItem*:xs space ']' -> [\"List\" ~xs]\n    | space '{' buildExpr*:xs space '}'        -> [\"Builder\" ~xs]\n    | name:x space '(' hostExpr*:ys space ')'  -> [\"FnCall\" x ~ys]\n    | name:x                                   -> [\"VarLookup\" x]\n  hostExprListItem =\n    | space '~' hostExpr:x                     -> [\"ListItemSplice\" x]\n    | hostExpr\n  buildExpr =\n    | space '>'                                -> [\"IndentBuilder\"]\n    | space '<'                                -> [\"DedentBuilder\"]\n    | hostExpr\n  string    = '\"'  (!'\"'  innerChar)*:xs '\"'   -> join(xs)\n  charseq   = '\\'' (!'\\'' innerChar)*:xs '\\''  -> join(xs)\n  char      = '\\''  !'\\'' innerChar  :x  '\\''  -> x\n  innerChar = '\\\\' escape | .\n  escape    = '\\\\' -> \"\\\\\" | '\\'' -> \"'\"\n            | '\"'  -> \"\\\"\" | 'n'  -> \"\\n\"\n  name      = space nameStart:x nameChar*:xs   -> join([x ~xs])\n  nameStart = 'a'-'z' | 'A'-'Z'\n  nameChar  = 'a'-'z' | 'A'-'Z' | '0'-'9'\n  space     = (' ' | '\\n')*\n}\n",
"type":"code"
}
],
"id":"46060bbf922841829adb3d3566a31960",
"type":"code"
}
],
"title":"parser.rlmeta"
},
{
"children":[],
"id":"ad4cf425e325476bbe0fd6821dc13b5c",
"paragraphs":[
{
"chunkpath":[],
"filepath":[
"codegenerator.rlmeta"
],
"fragments":[
{
"text":"CodeGenerator {\n  ast =\n    | [\"Grammar\" .:x ast*:ys]   -> { \"class \" x \"(_Grammar):\\n\" > ys <                   }\n    | [\"Rule\" .:x ast:y]        -> { \"\\ndef _rule_\" x \"(self):\\n\" > \"return \" y \"()\\n\" < }\n    | [\"MatchAny\"]              -> { \"self._match_any\"                                   }\n    | [\"String\" .:x]            -> { repr(x)                                             }\n    | [\"List\" astList:x]        -> { x                                                   }\n    | [\"Builder\" astItems:x]    -> { \"_Builder.create([\" x \"])\"                          }\n    | [\"IndentBuilder\"]         -> { \"_IndentBuilder()\"                                  }\n    | [\"DedentBuilder\"]         -> { \"_DedentBuilder()\"                                  }\n    | [\"FnCall\" .:x astItems:y] -> { x \"(\" y \")\"                                         }\n    | [\"VarLookup\" .:x]         -> { \"_vars.lookup(\" repr(x) \").eval()\"                  }\n    | astFnBody:x               -> { \"(lambda:\\n\" > x < \"\\n)\" }\n  astFnBody =\n    | [\"Or\" astItems:x]         -> { \"self._or([\" x \"])\"                                 }\n    | [\"Scope\" ast:x]           -> { \"(lambda _vars:\\n\" > x < \"()\\n)(_Vars())\"           }\n    | [\"And\" astItems:x]        -> { \"self._and([\" x \"])\"                                }\n    | [\"Bind\" .:x ast:y]        -> { \"_vars.bind(\" repr(x) \", \" y \"())\"                  }\n    | [\"Star\" ast:x]            -> { \"self._star(\" x \")\"                                 }\n    | [\"Not\" ast:x]             -> { \"self._not(\" x \")\"                                  }\n    | [\"SemanticAction\" ast:x]  -> { \"_SemanticAction(lambda: \" x \")\"                    }\n    | [\"MatchRule\" .:x]         -> { \"self._match_rule(\" repr(x) \")\"                     }\n    | [\"MatchRange\" .:x .:y]    -> { \"self._match_range(\" repr(x) \", \" repr(y) \")\"       }\n    | [\"MatchString\" .:x]       -> { \"self._match_string(\" repr(x) \")\"                   }\n    | [\"MatchCharseq\" .:x]      -> { \"self._match_charseq(\" repr(x) \")\"                  }\n    | [\"MatchList\" ast:x]       -> { \"self._match_list(\" x \")\"                           }\n  astItems = astItem*:xs        -> { \"\\n\" > xs <                                         }\n  astItem  = ast:x              -> { x \",\\n\"                                             }\n  astList  = astListItem*:xs    -> { \"(\" xs \"[])\"                                        }\n  astListItem =\n    | [\"ListItemSplice\" ast:x]  -> {     x  \"+\"                                          }\n    | ast:x                     -> { \"[\" x \"]+\"                                          }\n}\n",
"type":"code"
}
],
"id":"0113afdf98334edd9dfcfb0e5aed69f3",
"type":"code"
}
],
"title":"codegenerator.rlmeta"
},
{
"children":[],
"id":"5a6f1b7a39774ed690f27824793b1552",
"paragraphs":[
{
"chunkpath":[],
"filepath":[
"support.py"
],
"fragments":[
{
"text":"class _Grammar(object):\n\n    def _or(self, matchers):\n        original_stream = self._stream\n        for matcher in matchers:\n            try:\n                return matcher()\n            except _MatchError:\n                self._stream = original_stream\n        original_stream.fail(\"no choice matched\")\n\n    def _and(self, matchers):\n        result = None\n        for matcher in matchers:\n            result = matcher()\n        return result\n\n    def _star(self, matcher):\n        result = []\n        while True:\n            original_stream = self._stream\n            try:\n                result.append(matcher())\n            except _MatchError:\n                self._stream = original_stream\n                return _SemanticAction(lambda: [x.eval() for x in result])\n\n    def _not(self, matcher):\n        original_stream = self._stream\n        try:\n            matcher()\n        except _MatchError:\n            return _SemanticAction(lambda: None)\n        else:\n            original_stream.fail(\"match found\")\n        finally:\n            self._stream = original_stream\n\n    def _match_rule(self, rule_name):\n        key = (rule_name, self._stream.position())\n        if key in self._memo:\n            result, _, self._stream = self._memo[key]\n        else:\n            start = self._stream\n            result = getattr(self, \"_rule_{}\".format(rule_name))()\n            end = self._stream\n            self._memo[key] = (result, start, end)\n        return result\n\n    def _match_range(self, start, end):\n        original_stream = self._stream\n        next_objext, self._stream = self._stream.next()\n        if next_objext >= start and next_objext <= end:\n            return _SemanticAction(lambda: next_objext)\n        else:\n            original_stream.fail(\n                \"expected range {!r}-{!r} but found {!r}\".format(start, end, next_objext)\n            )\n\n    def _match_string(self, string):\n        original_stream = self._stream\n        next_object, self._stream = self._stream.next()\n        if next_object == string:\n            return _SemanticAction(lambda: string)\n        else:\n            original_stream.fail(\n                \"expected {!r} but found {!r}\".format(string, next_object)\n            )\n\n    def _match_charseq(self, charseq):\n        for char in charseq:\n            original_stream = self._stream\n            next_object, self._stream = self._stream.next()\n            if next_object != char:\n                original_stream.fail(\n                    \"expected {!r} but found {!r}\".format(char, next_object)\n                )\n        return _SemanticAction(lambda: charseq)\n\n    def _match_any(self):\n        next_object, self._stream = self._stream.next()\n        return _SemanticAction(lambda: next_object)\n\n    def _match_list(self, matcher):\n        original_stream = self._stream\n        next_object, next_stream = self._stream.next()\n        if isinstance(next_object, list):\n            self._stream = self._stream.nested(next_object)\n            matcher()\n            if self._stream.is_at_end():\n                self._stream = next_stream\n                return _SemanticAction(lambda: next_object)\n        original_stream.fail(\"list match failed\")\n\n    def run(self, rule_name, input_object):\n        self._memo = _Memo()\n        self._stream = _Stream.from_object(self._memo, input_object)\n        result = self._match_rule(rule_name).eval()\n        if isinstance(result, _Builder):\n            return result.build_string()\n        else:\n            return result\n\nclass _Vars(dict):\n\n    def bind(self, name, value):\n        self[name] = value\n        return value\n\n    def lookup(self, name):\n        return self[name]\n\nclass _SemanticAction(object):\n\n    def __init__(self, fn):\n        self.fn = fn\n\n    def eval(self):\n        return self.fn()\n\nclass _Builder(object):\n\n    def build_string(self):\n        output = _Output()\n        self.write(output)\n        return output.value\n\n    @classmethod\n    def create(self, item):\n        if isinstance(item, _Builder):\n            return item\n        elif isinstance(item, list):\n            return _ListBuilder([_Builder.create(x) for x in item])\n        else:\n            return _AtomBuilder(item)\n\nclass _Output(object):\n\n    def __init__(self):\n        self.value = \"\"\n        self.indentation = 0\n\n    def write(self, value):\n        for ch in value:\n            if self.value and ch != \"\\n\" and self.value[-1] == \"\\n\":\n                self.value += \"    \"*self.indentation\n            self.value += ch\n\nclass _ListBuilder(_Builder):\n\n    def __init__(self, builders):\n        self.builders = builders\n\n    def write(self, output):\n        for builder in self.builders:\n            builder.write(output)\n\nclass _AtomBuilder(_Builder):\n\n    def __init__(self, atom):\n        self.atom = atom\n\n    def write(self, output):\n        output.write(str(self.atom))\n\nclass _IndentBuilder(_Builder):\n\n    def write(self, output):\n        output.indentation += 1\n\nclass _DedentBuilder(_Builder):\n\n    def write(self, output):\n        output.indentation -= 1\n\nclass _Memo(dict):\n\n    def __init__(self):\n        dict.__init__(self)\n        self._latest_stream = _ObjectStream(self, [], position=-1)\n        self._latest_message = \"\"\n\n    def describe(self):\n        items = []\n        for (rule_name, _), (_, start, end) in self.items():\n            if end > start:\n                items.append((rule_name, start, end))\n        items.sort(key=lambda item: (item[2].position(), item[1].position()))\n        message = []\n        for item in items:\n            message.append(\"matched {: <20} {} -> {}\\n\".format(*item))\n        message.append(\"\\n\")\n        message.append(\"ERROR: {}: {}\\n\".format(\n            self._latest_stream,\n            self._latest_message\n        ))\n        return \"\".join(message)\n\n    def fail(self, stream, message):\n        if stream.position() >= self._latest_stream.position():\n            self._latest_stream = stream\n            self._latest_message = message\n        raise _MatchError(self)\n\nclass _MatchError(Exception):\n\n    def __init__(self, memo):\n        Exception.__init__(self)\n        self._memo = memo\n\n    def describe(self):\n        return self._memo.describe()\n\nclass _Stream(object):\n\n    @classmethod\n    def from_object(cls, memo, input_object):\n        if isinstance(input_object, basestring):\n            return _CharStream(memo, list(input_object))\n        else:\n            return _ObjectStream(memo, [input_object])\n\n    def __init__(self, memo, objects):\n        self._memo = memo\n        self._objects = objects\n\n    def fail(self, message):\n        self._memo.fail(self, message)\n\n    def next(self):\n        if self.is_at_end():\n            self.fail(\"not eof\")\n        next_object = self._objects[0]\n        return (\n            next_object,\n            self._advance(next_object, self._objects[1:]),\n        )\n\n    def is_at_end(self):\n        return len(self._objects) == 0\n\nclass _CharStream(_Stream):\n\n    def __init__(self, memo, objects, line=1, column=1):\n        _Stream.__init__(self, memo, objects)\n        self._line = line\n        self._column = column\n\n    def position(self):\n        return (self._line, self._column)\n\n    def _advance(self, next_object, objects):\n        if next_object == \"\\n\":\n            return _CharStream(self._memo, objects, self._line+1, 1)\n        else:\n            return _CharStream(self._memo, objects, self._line, self._column+1)\n\n    def __str__(self):\n        return \"L{:03d}:C{:03d}\".format(self._line, self._column)\n\nclass _ObjectStream(_Stream):\n\n    def __init__(self, memo, objects, parent=(), position=0):\n        _Stream.__init__(self, memo, objects)\n        self._parent = parent\n        self._position = position\n\n    def position(self):\n        return self._parent + (self._position,)\n\n    def nested(self, input_object):\n        return _ObjectStream(self._memo, input_object, self._parent+(self._position,))\n\n    def _advance(self, next_object, objects):\n        return _ObjectStream(self._memo, objects, self._parent, self._position+1)\n\n    def __str__(self):\n        return \"[{}]\".format(\", \".join(str(x) for x in self.position()))\n",
"type":"code"
}
],
"id":"d1256933edc84b45b5d630115e83d454",
"type":"code"
}
],
"title":"support.py"
},
{
"children":[],
"id":"01dd3721287a4b3eb6671a0f3fd99128",
"paragraphs":[
{
"chunkpath":[],
"filepath":[
"compile.sh"
],
"fragments":[
{
"text":"#!/bin/bash\n\nset -e\n\nrlmeta_compiler=\"$(pwd)/$1\"\n\ncd \"$(dirname \"$0\")\"\n\nto_python_string() {\n    python -c 'import sys; sys.stdout.write(repr(sys.stdin.read()))'\n}\n\nsupport_py_string=$(to_python_string < support.py)\nsupport_py=$(python \"$rlmeta_compiler\" --support)\nparser_py=$(python \"$rlmeta_compiler\" < parser.rlmeta)\ncodegenerator_py=$(python \"$rlmeta_compiler\" < codegenerator.rlmeta)\n\ncat <<EOF\n",
"type":"code"
},
{
"blank_lines_before":0,
"path":[
"rlmeta template"
],
"prefix":"",
"type":"chunk"
},
{
"text":"EOF\n",
"type":"code"
}
],
"id":"ef234944361c48eeb16387d8014a4c9b",
"type":"code"
},
{
"chunkpath":[
"rlmeta template"
],
"filepath":[
"compile.sh"
],
"fragments":[
{
"text":"import sys\n\nSUPPORT = $support_py_string\n\n$support_py\n\n$parser_py\n\n$codegenerator_py\n\njoin = \"\".join\n\ndef compile_grammar(grammar):\n    parser = Parser()\n    code_generator = CodeGenerator()\n    return code_generator.run(\"ast\", parser.run(\"grammar\", grammar))\n\nif __name__ == \"__main__\":\n    if \"--support\" in sys.argv:\n        sys.stdout.write(SUPPORT)\n    else:\n        try:\n            sys.stdout.write(compile_grammar(sys.stdin.read()))\n        except _MatchError as e:\n            sys.stderr.write(e.describe())\n            sys.exit(1)\n",
"type":"code"
}
],
"id":"cab1f5d6d3c0412696419fd2f8c0ab88",
"language":"python",
"type":"code"
}
],
"title":"compile.sh"
},
{
"children":[],
"id":"d910746e68c1406c97a054c4f6e56573",
"paragraphs":[
{
"code_id":"bd7e31bf3ea7456f975830d5bf2ef05c",
"id":"289eb60da587474aaa127a14f68a6a95",
"type":"expanded_code"
}
],
"title":"meta_compile.sh"
}
],
"id":"d54bbeda3d9846bca027f2c2995775a5",
"paragraphs":[],
"title":"Code listings for RLMeta"
}
],
"id":"7b987f7cd685486da72bf77dcd0b3f29",
"paragraphs":[
{
"fragments":[
{
"text":"In this article I explain how to modify the RLMeta metacompiler and how modifying a metacompiler is different than modifying an ordinary compiler (or program).",
"type":"text"
}
],
"id":"4d967f1bcd054206b4731c141ff9822a",
"type":"text"
}
],
"title":"Modifying RLMeta"
},
"variables":{}
}