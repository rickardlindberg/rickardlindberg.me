A while ago I created a [poster](/writing/creating-rlmeta-poster/index.html) to
showcase RLMeta. The version of RLMeta on the poster is based on the version
from the [memoizing failures](/writing/rlmeta-memoize-failures/index.html)
article, but I made it smaller and more beautiful to better fit the poster. To
be able to finish the poster, I had to stop making changes and put the source
code on the poster. That was difficult because I felt the need for it to be
perfect. Eventually I did stop polishing, and left a few items unresolved.

Almost immediately after I finished the poster, I started working on a second
version. Initially, my plan was to make a second version of the poster. I
started to fix the unresolved items and I was making progress. But somehow
imperfections kept creeping in. It felt like a never ending game of chasing
perfection. That's when I decided that a second poster was probably not going
to be worth it. But I still liked the new version of RLMeta.

Instead, I decided to attempt to present the new version in the style of a code
walk through. In other words, another way to showcase RLMeta that is also a bit
more practical. Compared to the poster version, this version could also be more
easily improved because rendering the blog post is automatic whereas creating
the layout of a poster requires manual work every time the source code changes.
I also wanted to experiment with the walk through format because I thought it
could be something worth putting into the README of a project.

The rest of this blog post consists of the walk through of the new version of
RLMeta and a section on the most important changes from the poster version and
motivations for them.

## Code walk through

### Getting RLMeta

In order to follow along on this walk through, you need to download the
version of RLMeta from here: [rlmeta-poster-2.zip](rlmeta-poster-2.zip).

### File structure

The zip file consists of the source code for the RLMeta compiler, a make
script, and the compiler itself (`rlmeta.py`):

$:shell:rlmeta-poster-2:tree --dirsfirst

The size of the source code is quite small:

$:shell:rlmeta-poster-2:wc -l src/*

The compiler can be created from this source code only. We will see how later
in this walk through.

### Exploring RLMeta

Before we dive into how the RLMeta compiler is created, let's explore RLMeta by
writing a small, but real, program in it.

What types of programs can we write in RLMeta?

In RLMeta, we write grammars. Grammars have rules that specify how to match
objects from an input stream and specify what should happen when objects are
matched.

Let's write a grammar that counts the number of objects in an input stream and
produces a report:

$~shell~rlmeta-poster-2~echo -e 'ObjectCounter {\n    count = .*:xs -> { "number of objects = " len(xs) }\n}' > object_counter.rlmeta

$:shell:rlmeta-poster-2:cat object_counter.rlmeta:rlmeta

The main function of the RLMeta compiler is to transform grammars into Python
code. If invoked without arguments, the compiler reads a grammar from stdin
and writes Python code to stdout:

$:shell:rlmeta-poster-2:cat object_counter.rlmeta | python rlmeta.py:python

This is equivalent to using the `--compile` command with a value  of `-` which
stands for stdin:

$:shell:rlmeta-poster-2:cat object_counter.rlmeta | python rlmeta.py --compile - | head -n3:python

And, the file can also be specified directly like this:

$:shell:rlmeta-poster-2:python rlmeta.py --compile object_counter.rlmeta | head -n3:python

Don't worry about understanding the generated code. We will explore it more
later. Just note that the generated class inherits from a class called
`Grammar` and that it uses some constants like `PUSH_SCOPE` and `LIST_START`.
These things are defined in a support library which can be generated by the
RLMeta compiler with the `--support` command:

$:shell:rlmeta-poster-2:python rlmeta.py --support | grep '^\(class\|def\)':python

To create a complete program, we also have to write a main function that
instantiates the `ObjectCounter` grammar and invokes its `count` rule.

Here is an example that passes stdin as the input stream to the `count` rule
and prints the result to stdout:

$~shell~rlmeta-poster-2~echo -e 'if __name__ == "__main__":\n    import sys\n    sys.stdout.write(ObjectCounter().run("count", sys.stdin.read()))' > object_counter_main.py

$:shell:rlmeta-poster-2:cat object_counter_main.py:python

The `--copy` command of the RLMeta compiler can be used to copy this main file,
as is, to the output.

Combining these pieces into a single compile command, we get this:

$:shell:rlmeta-poster-2:python rlmeta.py --support --compile object_counter.rlmeta --copy object_counter_main.py > object_counter.py

It will perform all commands in the given order and write all generated code
concatenated into a single file.

Note that the support library comes before the grammar so that `Grammar` is
defined by the time `ObjectCounter` is evaluated.

The object counter source code has now been compiled into a standalone Python
program that can be run like this:

$:shell:rlmeta-poster-2:echo 'hello' | python object_counter.py

$:shell:rlmeta-poster-2:echo 'this is longer' | python object_counter.py

So programs in RLMeta are written mainly in grammar files with some support
functions written in Python. The RLMeta compiler can process all these files to
produce a single Python file which is the compiled program.

$~shell~rlmeta-poster-2~rm object_counter.rlmeta
$~shell~rlmeta-poster-2~rm object_counter_main.py
$~shell~rlmeta-poster-2~rm object_counter.py

### Compiling RLMeta itself

Now that we have an understanding of RLMeta, let's look at the command that
compiles the RLMeta compiler itself from the source code:

$:shell:rlmeta-poster-2:python rlmeta.py --embed SUPPORT src/support.py --support --compile src/parser.rlmeta --compile src/codegenerator.rlmeta --compile src/assembler.rlmeta --copy src/main.py > rlmeta-raw.py

The first command, `--embed SUPPORT src/support.py`, tells the compiler to
generate a Python variable named `SUPPORT` containing the contents of the file
`src/support.py`. The `--embed` command is the last command of the compiler that
we have not yet seen. (The RLMeta compiler needs the support library in a
variable so that it can generate it later with the `--support` command.)

Next, the `--support` command tells the compiler to generate the support
library that is embedded in it.

The `--compile ...` commands tell the compiler to compile the given grammar
files.

The last command, `--copy src/main.py`, tells the compiler to copy the main file
verbatim. Similar to what we did to the main file in the object counter.

The make script can be called with the `--compile` command to perform this
exact function:

$:shell:rlmeta-poster-2:./make.py --compile > rlmeta-compile.py

And all these files are exactly the same:

$:shell:rlmeta-poster-2:md5sum rlmeta.py rlmeta-compile.py rlmeta-raw.py

Thus, the RLMeta compiler reproduced itself exactly from the source code.

$~shell~rlmeta-poster-2~rm rlmeta-compile.py
$~shell~rlmeta-poster-2~rm rlmeta-raw.py

### A tour of the main function

Let's now look at how all commands of the RLMeta compiler are implemented. Here
is the main function:

$:code:rlmeta-poster-2/src/main.py

It contains command line parsing and handles processing of all commands.

The `--compile` command is the most complex of them all. It calls the
`compile_chain` function which runs the given grammars/rules in order (in this
case the input will first be parsed, then passed to the code generator, and
finally passed to the assembler) and prints a pretty error message to stderr
upon failure:

$:code:rlmeta-poster-2/src/support.py:^def compile_chain:^[^ ]

This function might be useful for other RLMeta programs as well. That is why
it's included in the support library and not only in the main file.

### Following a compilation

Let's now follow a compilation of an example grammar to learn more about how
a grammar file is turned into Python code. Here it is:

$~shell~rlmeta-poster-2~echo -e 'Example {\n    main = .\n}' > example.rlmeta

$:shell:rlmeta-poster-2:cat example.rlmeta:rlmeta

And this is what it compiles to:

$:shell:rlmeta-poster-2:python rlmeta.py --compile example.rlmeta:python

The transformations that the grammar goes through are defined in the main
function:

$:code:rlmeta-poster-2/src/main.py:Parser:^.

So first the grammar file is passed to the `file` rule of the parser:

$:code:rlmeta-poster-2/src/parser.rlmeta:^  file:^  [^ ]

It in turn calls the `grammar` rule to parse all grammars in the file:

$:code:rlmeta-poster-2/src/parser.rlmeta:^  grammar:^  [^ ]

This rule matches the name, the open curly brace, a set of rules, and the
closing curly brace. It will then return an AST that looks like this:

```python
[
    "Grammar",
    "Example",
    ...
]
```

All grammar AST nodes are handed off to the `asts` rule in the code generator:

$:code:rlmeta-poster-2/src/codegenerator.rlmeta:^  asts *=:.

It it turn calls the `ast` rule to process each AST node:

$:code:rlmeta-poster-2/src/codegenerator.rlmeta:^  ast *=:.

The `ast` rule treats the first argument in the AST as a rule name, and calls
that rule. In this case `Grammar`:

$:code:rlmeta-poster-2/src/codegenerator.rlmeta:^  Grammar:^  [^ ]

The code generator creates a new AST node representing a grammar. But this AST
node is slightly different and meant to be processed by the assembler. The
result is this:

```python
[
    "Grammar",
    "Example",
    ... ast nodes for consumption by assembler ...
]
```

This AST node and all the others that the code generator produces are passed to
the `asts` rule in the assembler:

$:code:rlmeta-poster-2/src/assembler.rlmeta:^  asts *=:.

It in turn calls the `ast` rule:

$:code:rlmeta-poster-2/src/assembler.rlmeta:^  ast *=:.

Which does the same trick again, now invoking the `Grammar` rule (in the
assembler) which looks like this:

$:code:rlmeta-poster-2/src/assembler.rlmeta:^  Grammar:^  [^ ]

This rule can be read as follows:

* Match the grammar name and all AST nodes
* Perform the following action
    * Define a variable called `rules` which is a list
    * Define a variable called `code` which is a list
    * Define a variable called `labels` which is a dictionary
    * Define a variable called `patches` which is a list
    * Evaluate the AST nodes (with possible side effects recorded in the above
      variables)
    * Treat the value of the `patches` variable as a list of AST nodes and
      process them with the `asts` rule of this grammar
    * Return a string which is generated Python code

The generated code from our example looks like this:

    class Example(Grammar):
        rules = {
            ...
        }
        code = [
            ...
        ]

To understand how the `rule` and `code` sections are generated, we just have to
follow a few more transformations.

Let's look at one more and see how the rule in our example grammar is
transformed.

First, the rule is parsed by the `rule` rule in the parser:

$:code:rlmeta-poster-2/src/parser.rlmeta:^  rule =:^  [^ ]

First the name is matched, then the equals sign, and then an expression
representing the body of the rule.

It our case, this rule produces this AST node:

```python
[
    "Rule",
    "main",
    ...
]
```

That node is going to be processed by the `Rule` rule in the code generator:

$:code:rlmeta-poster-2/src/codegenerator.rlmeta:^  Rule:^  [^ ]

Generating an AST node that looks like this:

```python
[
    ["Rule", "main"],
    ...,
    ["OpCode", "RETURN"]
]
```

Here we can see that the AST from the code generator looks a bit more like
assembly code than a representation of the syntax in the grammar.

The first child in this AST node is going to be handled the `Rule` rule in the
assembler:

$:code:rlmeta-poster-2/src/assembler.rlmeta:^  Rule:^  [^ ]

It does two things:

1. Adds a string value to the `rules` list
2. Adds an entry to the `labels` dictionary to map a label to an index in the
   `code` list

At this point, the variables have the following values.

```python
rules = [
    "'main': 0",
]
labels = {
    'main': 0,
}
```

The second child in the AST node is going to be handled by the `OpCode` rule in
the assembler:

$:code:rlmeta-poster-2/src/assembler.rlmeta:^  OpCode:^  [^ ]

It adds the given op code to the `code` list, giving it this value:

```python
code = [
    ...,
    "RETURN",
]
```

When the `rules` and `code` variables are expanded, the resulting class looks
like this:

    class Example(Grammar):
        rules = {
            'main': 0
        }
        code = [
            ...,
            RETURN
        ]

Hopefully you should now be comfortable to follow transformations yourself to
understand how a compilation is done.

$~shell~rlmeta-poster-2~rm example.rlmeta

### The purpose of the make script

When the make script is called without arguments, it performs a meta
compilation and runs a few tests:

$:shell:rlmeta-poster-2:./make.py

The meaning of a meta compilation is to create a new version of RLMeta that can
still reproduce it self from the source code.

In the output above, we can see that it compiled RLMeta and wrote the result to
`rlmeta1.py`. In this case, since it is exactly the same as `rlmeta.py`, the
compilation stopped there and a few more tests were run using this compiler.
But if we make changes to the source code, `rlmeta1.py` will most likely not be
exactly the same as `rlmeta.py`, and a few more compilations might be needed.
I've written about the details of meta compilation in a [previous blog
post](/writing/modifying-rlmeta/index.html#5f6a1c91143146dbb3b865ac42562135).

So the purpose of the make script is to ease meta compilations and also run a
test suit on the newly generated metacompiler before accepting it.

The make script can also be used to perform a single compilation of RLMeta with
the `--compile` argument as we saw earlier.

## Changes from the previous version

This section explains the most important changes in this version of RLMeta
compared to the original poster version.

First of all, I wanted to work on the unresolved items which were the
following:

* The label counter is incremented at match time, not at semantic action
  evaluation time.
* Compilation depends on Bash.
* Assembly code in code generator is hard to read.

In the poster article, I also had a few notes about
[future versions](/writing/creating-rlmeta-poster/index.html#b070abcd2f134cf894e33e63188a9fee):

> The smaller it is, the easier it is to understand and therefore extend. The
> more flexible it is to extend the better. If I make another poster version it
> would therefore focus on being smaller and more flexible. Since all
> successive version of RLMeta have been faster than the ones before,
> performance is also important. But small size, clarity, and flexibility come
> first.

I used these guidelines to decide if certain changes should go into the new
version or not.

One interesting thing to note is that the guidelines are sometimes
contradicting. Writing clear code might mean more lines of code which makes the
code base larger. Perhaps that's also why I got stuck chasing perfection. I
thought I made something easier to read, but it ended up costing 10 extra lines
of code.  Should I include it?

### Generate labels in semantic actions

One thing that I left in the poster version that still annoyed me was that
labels were generated at match time, not at semantic action evaluation time. It
would not produce incorrect results. At worst, some labels end up not being
used because the counter value captured was in a rule that later failed.  But
dealing with labels at match time does not make sense. It should really happen
at semantic action evaluation time.

Here is what the `Not` rule looks like in the poster version:

$:file:scratch.rlmeta
Not = ast:x #:a #:b -> { "I('BACKTRACK', " b ")\n"
                         x
                         "I('COMMIT', " a ")\n"
                         "LABEL(" a ")\n"
                         "I('FAIL', 'no match expected')\n"
                         "LABEL(" b ")\n"                   }
$:endfile
$:code:scratch.rlmeta
$~shell~.~rm scratch.rlmeta

Here is what the `Not` rule looks like after the change:

$:file:scratch.rlmeta
Not = ast:x -> label():a -> label():b
            -> { "I('BACKTRACK', " b ")\n"
                 x
                 "I('COMMIT', " a ")\n"
                 "LABEL(" a ")\n"
                 "I('FAIL', 'no match expected')\n"
                 "LABEL(" b ")\n"                   }
$:endfile
$:code:scratch.rlmeta
$~shell~.~rm scratch.rlmeta

This change puts label generation where it belongs, in semantic actions, and
thus makes the implementation **more clear**. The VM is no longer concerned
with labels. It is only concerned with matching. This change required a bit of
rework how semantic actions work. Previously only one expression was allowed:

    <match expression> -> <semantic action expression>

Now multiple expressions are allowed:

    <match expression> -> <semantic action expression>:x
                       -> <semantic action expression>
                       -> <semantic action expression>

The result of expressions can also be bound to names which subsequent
expressions can refer to. `label` is such a variable that is set internally to
a function that generates increasing integers starting at 0.

The implementation of this change also **increases the flexibility** of RLMeta.
For example, it is now possible to write a semantic action that generates code
in different sections like this:

$:file:rlmeta-poster-2/example_buffers.rlmeta
ExampleBuffers {
    program  = ast:x  -> []:header
                      -> { "# HEADER\n"
                           header
                           "# BODY\n"
                           x            }
    ast      = [%:x]  -> x
    Program  = ast*
    Function = .:name -> add(header { "def " name "\n" })
                      -> { name "()\n" }
}
$:endfile
$:code:rlmeta-poster-2/example_buffers.rlmeta

The expressions `[]:header` creates a list and assigns it to the variable
`header`. When `x` is evaluated in the next step, the semantic action for the
`Function` rule will be evaluated which can then access the `header` variable
defined earlier.  These variables are not lexically scoped, but dynamically
scoped. If at runtime, a variable is defined, it will be accessible. It also
means that the `Function` rule can not be run without `program` being run
first, or the `header` variable will not be defined.

Here is an example AST representing a program:

$:file:rlmeta-poster-2/ast.py
AST = [
    ['Program',
        ['Function', 'foo'],
        ['Function', 'bar']
    ]
]
$:endfile
$:code:rlmeta-poster-2/ast.py

$:file:rlmeta-poster-2/main.py
import sys
sys.stdout.write(ExampleBuffers().run("program", AST))
$:endfile

$~shell~rlmeta-poster-2~python rlmeta.py --support --compile example_buffers.rlmeta --copy ast.py --copy main.py > example_buffers.py

When the `program` rule is run on the example input, the following is output:

$:shell:rlmeta-poster-2:python example_buffers.py

This type of thing is useful for example when generating C functions where
definitions need to go in "header" and declarations in "body".

In summary, this change is as follows:

* Label syntax (`#`) in parser is removed
* Actions can have multiple expressions
* Expressions can be bound to names
* A default `label` function to generate labels
* Names in semantic actions refer to matches or results bound earlier

(The complete initial diff for this change can be found on
[GitHub](https://github.com/rickardlindberg/rickardlindberg.me/commit/5154583e9d98c123630fb41664aa6906d4801d05).)

The increased clarity and flexibility come with a price. The size increases and
the performance drops.

The parser and the code generator are mostly the same. The greatest addition is
in the support library. Which is expected when semantic action evaluation
becomes more complex. The drop in performance is likely due to more function
calls when evaluating semantic actions. Even though size and performance got
worse, I believe the clarity and flexibility gain is worth it.

$~shell~rlmeta-poster-2~rm example_buffers.rlmeta
$~shell~rlmeta-poster-2~rm main.py
$~shell~rlmeta-poster-2~rm ast.py
$~shell~rlmeta-poster-2~rm example_buffers.py
$~shell~rlmeta-poster-2~rm -rf __pycache__

### Remove dependency on Bash

To compile the previous version of RLMeta, you ran the following command:

    ./compile.sh rlmeta.py

In one way, the compiler could not compile itself, but relied on a Bash script
for gluing things together. It would call the `rlmeta.py` compiler for certain
tasks and use Bash and Python for other tasks.

As we have already seen, the new version of RLMeta compiles itself like this:

    python rlmeta.py \
        --embed SUPPORT src/support.py \
        --support \
        --compile src/parser.rlmeta \
        --compile src/codegenerator.rlmeta \
        --compile src/assembler.rlmeta \
        --copy src/main.py \
        > rlmeta.py

The `rlmeta.py` compiler now has support (via `--embed` and `--copy`) for doing
what the Bash script previously did.

This makes the compiler slightly larger, but it feels so much cleaner.

In addition, the extra features are useful when writing programs in RLMeta.
Those programs can now also be compiled with a single command, and there is no
need to concatenate different pieces together.

(The complete diff for this change can be found on
[GitHub](https://github.com/rickardlindberg/rickardlindberg.me/commit/935bb77e1d5b88e09de64112aa2fb2f46dbcb7d9).)

### Extract assembler

The third thing that I had a problem with in the poster version was the
readability of the code generator.  For example, the `Not` rule looked like
this:

$:file:scratch.rlmeta
Not = ast:x -> label():a -> label():b
            -> { "I('BACKTRACK', " b ")\n"
                 x
                 "I('COMMIT', " a ")\n"
                 "LABEL(" a ")\n"
                 "I('FAIL', 'no match expected')\n"
                 "LABEL(" b ")\n"                   }
$:endfile
$:code:scratch.rlmeta
$~shell~.~rm scratch.rlmeta

It generates a string which contains Python code that calls functions to create
"assembly" code. So part of the compilation is actually happening at runtime
here. It is mixed and messy.

The new `Not` rule looks like this:

$:file:scratch.rlmeta
Not = ast:x -> label():a -> label():b
            -> [["OpCode" "BACKTRACK"]
                ["Target" b]
                ~x
                ["OpCode" "COMMIT"]
                ["Target" a]
                ["Label" a]
                ["OpCode" "FAIL"]
                ["Value" "no match"]
                ["Label" b]]
$:endfile
$:code:scratch.rlmeta
$~shell~.~rm scratch.rlmeta

Instead of outputting Python code directly, it now generates abstract assembly
code. Then a new third pass, the assembler, turns those instructions into
Python code as well as resolves label positions. So no more compilation at
runtime.

This reads better because the purpose of the code generator is now a bit
narrower. It can focus on one thing and leave the rest to the assembler.

Adding another pass also opens up the possibility to do peep-hole optimizations
on the abstract assembly code before the assembler turns the instructions into
Python code.

### Clearer VM

In the poster version, the virtual machine was written as a single function
with one loop like this:


$:file:scratch.py
def vm(instructions, labels, start_rule, stream):
    ...
    while True:
        name, arg1, arg2 = instructions[pc]
        if name == "PUSH_SCOPE":
            scope_stack.append(scope)
            scope = {}
            pc += 1
            continue
        elif name == "BACKTRACK":
            ...
        ...
$:endfile
$:code:scratch.py
$~shell~.~rm scratch.py

It was written like that to be as fast as possible. It avoided function calls.
It avoided class variables lookup by avoiding classes. All variables used were
defined locally in the `vm` function. Because function calls could not be used,
some code was also duplicated.

I decided that I would not consider performance at all, and instead try to
write the VM as clear as I could. I ended up with a `VM` class to hold some
state and instruction functions that operate on an instance of a VM:

$:file:scratch.py
class VM:

    def __init__(self, code, rules):
        ...

    ...

def PUSH_SCOPE(vm):
    vm.scope_rest = (vm.scope, vm.scope_rest)
    vm.scope = {}

def BACKTRACK(vm):
    ...

...
$:endfile
$:code:scratch.py
$~shell~.~rm scratch.py

As I noted earlier, I'm not sure I am happy with this result. I'm not convinced
that it reads better. The biggest upside is that since function calls are
now allowed, part of the VM can be expressed more clearly without repetition.

Before I ended up with this VM, I experimented with a language for writing
virtual machines that compiled to Python code. You could define instructions
and the arguments they took and define macros for code re-use. It was basically
a small macro language on top of Python. It looked something like this:

$:file:scratch.py
def vm(code, rules, start_rule, stream):
    action = SemanticAction(None)
    pc = rules[start_rule]
    call_backtrack_stack = []
    stream, stream_rest = (stream, None)
    pos, pos_rest = (0, tuple())
    scope, scope_rest = (None, None)
    fail_message = None
    latest_fail_message, latest_fail_pos = (None, tuple())
    memo = {}

definstruction PUSH_SCOPE():
    scope_rest = (scope, scope_rest)
    scope = {}
$:endfile
$:code:scratch.py
$~shell~.~rm scratch.py

And here is how macros were used:

$:file:scratch.py
definstruction FAIL(arg_message):
    fail_message = (arg_message,)
    #FAIL

defmacro FAIL:
    ...
$:endfile
$:code:scratch.py
$~shell~.~rm scratch.py

When this was compiled, something similar to the `vm` function above was
generated. A single function that was intended to run as fast as possible. But
you could write the VM quite clearly anyway.

I liked the result of that, but it introduced yet another language and made
compilation and metacompilation more complicated. For that reason, I decided
against it.

Perhaps another approach would be to consider the VM a separate piece, not to
be included in compilations and metacompilations. But they are also strongly
connected. Say for example that an optimizer decides to output a new VM
instruction, then the VM has to change.

I am not entirely clear about the interface here between the VM and the rest of
the compiler.

### Ability to run a rule in semantic action

Another feature that was added in this version was the ability to call a
grammar rule recursively from a semantic action.

This was initially needed to to implement recursive macros in the VM language
mentioned in the previous section, but it made its way into RLMeta to support
the patching of assembly instructions.

When a `Target` instruction is encountered, the `patches` list is populated
with a command:

$:code:rlmeta-poster-2/src/assembler.rlmeta:^  Target:^  [^ ]

These commands are then evaluated by running the `asts` rule on the `patches`
list. This starts another parse on the given stream.

$:code:rlmeta-poster-2/src/assembler.rlmeta:^.*-> run.*patches:.

The new parse has access the all the runtime variables that the semantic action
that invokes it has. So that is why a `Patch` instruction can modify the `code`
array and insert the correct index there instead of the placeholder:

$:code:rlmeta-poster-2/src/assembler.rlmeta:^  Patch:^  [^ ]

### Misc

Many more small changes were made. Here are a few notes about them.

* Various renames to make intention more clear and reformats to improve
  readability.

* Various clean ups in the parser:

    * Only allow semantic actions at the very end of a rule.

    * Make sure the whole file is parsed so that junk after a grammar results
      in an error.

* Adapt to Python 3.

## The future

On the one hand, I'm quite happy with the improvements to RLMeta that I was
able to make. The code feels more clear and flexible. Definitely a better
version of RLMeta.

On the other hand, this article turned out to have the same problem as the
poster. It just kept growing and growing, and at some point I had to stop
working on in, leave some issues unresolved, and call the article finished. For
example, I am not happy with how the new VM looks. A mix between classes and
functions and helpers.

I decided to set up a [repo on
GitHub](https://github.com/rickardlindberg/rlmeta) for RLMeta where it can
continue to be improved.

I plan for it to contain the base version of RLMeta which is the minimal
version that is able to compile itself and maintain properties such as
flexible, easy to extend, and easy to understand. Then I want to include
examples as well to show how RLMeta can be used and how you can extend it in
various ways.

## Code listings for RLMeta

Here is all the source code and also the make script for this version of
RLMeta.

### src/parser.rlmeta

$:code:rlmeta-poster-2/src/parser.rlmeta

### src/codegenerator.rlmeta

$:code:rlmeta-poster-2/src/codegenerator.rlmeta

### src/assembler.rlmeta

$:code:rlmeta-poster-2/src/assembler.rlmeta

### src/support.py

$:code:rlmeta-poster-2/src/support.py

### src/main.py

$:code:rlmeta-poster-2/src/main.py

### make.py

$:code:rlmeta-poster-2/make.py
