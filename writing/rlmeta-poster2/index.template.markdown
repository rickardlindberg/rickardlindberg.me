A while ago I created a [poster](/writing/creating-rlmeta-poster/index.html) to
showcase RLMeta. The version of RLMeta on the poster is based on the version
from the [memoizing failures](/writing/rlmeta-memoize-failures/index.html)
article, but I made it smaller and more beautiful to better fit the poster. To
be able to finish the poster, I had to stop making changes and put the source
code on the poster. That was difficult because I felt the need for it to be
perfect. Eventually I did stop polishing, and left a few items unresolved.

Almost immediately after I finished the poster, I started working on a second
version. Initially, my plan was to make a second version of the poster. I
started to fix the unresolved items and I was making progress. But somehow
imperfections kept creeping in. It felt like a never ending game of chasing
perfection. That's when I decided that a second poster was probably not going
to be worth it. But I still liked the new version of RLMeta.

Instead, I decided to attempt to present the new version in the style of a code
walk through. In other words, another way to showcase RLMeta that is also a bit
more practical. Compared to the poster version, this version could also be more
easily improved because rendering the blog post is automatic whereas creating
the layout of a poster requires manual work every time the source code changes.
I also wanted to experiment with the walk through format because I thought it
could be something worth putting into the README of a project.

The rest of this blog post consists of the walk through of the new version of
RLMeta and a section on the most important changes from the poster version and
motivations for them.

## Code walk through

### Getting RLMeta

In order to follow along on this walk through, you need to download the
version of RLMeta from here: [rlmeta-poster-2.zip](rlmeta-poster-2.zip).

### File structure

The zip file consists of the source code for the RLMeta compiler, a make
script, and the compiler itself (`rlmeta.py`):

$:shell:rlmeta-poster-2:tree --dirsfirst

The size of the source code is quite small:

$:shell:rlmeta-poster-2:wc -l src/*

The compiler can be created from this source code only. We will see how later
in this walk through.

### Exploring RLMeta

Before we dive into how the RLMeta compiler is created, let's explore RLMeta by
writing a small, but real, program in it.

What types of programs can we write in RLMeta?

In RLMeta, we write grammars. Grammars have rules that specify how to match
objects from an input stream and specify what should happen when objects are
matched.

Let's write a grammar that counts the number of objects in an input stream and
produces a report:

$~shell~rlmeta-poster-2~echo -e 'ObjectCounter {\n    count = .*:xs -> { "number of objects = " len(xs) }\n}' > object_counter.rlmeta

$:shell:rlmeta-poster-2:cat object_counter.rlmeta:rlmeta

The main function of the RLMeta compiler is to transform grammars into Python
code. If invoked without arguments, the compiler reads a grammar from stdin
and writes Python code to stdout:

$:shell:rlmeta-poster-2:cat object_counter.rlmeta | python rlmeta.py:python

This is equivalent to using the `--compile` command with a value  of `-` which
stands for stdin:

$:shell:rlmeta-poster-2:cat object_counter.rlmeta | python rlmeta.py --compile - | head -n3:python

And, the file can also be specified directly like this:

$:shell:rlmeta-poster-2:python rlmeta.py --compile object_counter.rlmeta | head -n3:python

Don't worry about understanding the generated code. We will explore it more
later. Just note that the generated class inherits from a class called
`Grammar` and that it uses some constants like `PUSH_SCOPE` and `LIST_START`.
These things are defined in a support library which can be generated by the
RLMeta compiler with the `--support` command:

$:shell:rlmeta-poster-2:python rlmeta.py --support | grep '^\(class\|def\)':python

To create a complete program, we also have to write a main function that
instantiates the `ObjectCounter` grammar and invokes its `count` rule.

Here is an example that passes stdin as the input stream to the `count` rule
and prints the result to stdout:

$~shell~rlmeta-poster-2~echo -e 'if __name__ == "__main__":\n    import sys\n    sys.stdout.write(ObjectCounter().run("count", sys.stdin.read()))' > object_counter_main.py

$:shell:rlmeta-poster-2:cat object_counter_main.py:python

The `--copy` command of the RLMeta compiler can be used to copy this main file,
as is, to the output.

Combining these pieces into a single compile command, we get this:

$:shell:rlmeta-poster-2:python rlmeta.py --support --compile object_counter.rlmeta --copy object_counter_main.py > object_counter.py

It will perform all commands in the given order and write all generated code
concatenated into a single file.

Note that the support library comes before the grammar so that `Grammar` is
defined by the time `ObjectCounter` is evaluated.

The object counter source code has now been compiled into a standalone Python
program that can be run like this:

$:shell:rlmeta-poster-2:echo 'hello' | python object_counter.py

$:shell:rlmeta-poster-2:echo 'this is longer' | python object_counter.py

So programs in RLMeta are written mainly in grammar files with some support
functions written in Python. The RLMeta compiler can process all these files to
produce a single Python file which is the compiled program.

$~shell~rlmeta-poster-2~rm object_counter.rlmeta
$~shell~rlmeta-poster-2~rm object_counter_main.py
$~shell~rlmeta-poster-2~rm object_counter.py

### Compiling RLMeta itself

Now that we have an understanding of RLMeta, let's look at the command that
compiles the RLMeta compiler itself from the source code:

$:shell:rlmeta-poster-2:python rlmeta.py --embed SUPPORT src/support.py --support --compile src/parser.rlmeta --compile src/codegenerator.rlmeta --compile src/assembler.rlmeta --copy src/main.py > rlmeta-raw.py

The first command, `--embed SUPPORT src/support.py`, tells the compiler to
generate a Python variable named `SUPPORT` containing the contents of the file
`src/support.py`. The `--embed` command is the last command of the compiler that
we have not yet seen. (The RLMeta compiler needs the support library in a
variable so that it can generate it later with the `--support` command.)

Next, the `--support` command tells the compiler to generate the support
library that is embedded in it.

The `--compile ...` commands tell the compiler to compile the given grammar
files.

The last command, `--copy src/main.py`, tells the compiler to copy the main file
verbatim. Similar to what we did to the main file in the object counter.

The make script can be called with the `--compile` command to perform this
exact function:

$:shell:rlmeta-poster-2:./make.py --compile > rlmeta-compile.py

And all these files are exactly the same:

$:shell:rlmeta-poster-2:md5sum rlmeta.py rlmeta-compile.py rlmeta-raw.py

Thus, the RLMeta compiler reproduced itself exactly from the source code.

$~shell~rlmeta-poster-2~rm rlmeta-compile.py
$~shell~rlmeta-poster-2~rm rlmeta-raw.py

### A tour of the main function

Let's now look at how all commands of the RLMeta compiler are implemented. Here
is the main function:

$:code:rlmeta-poster-2/src/main.py

It contains command line parsing and handles the basic cases.

The `--compile` is the most complex of them all. It calls the `compile_chain`
method which runs the given grammars/rules in order (in this case the input
will first be parsed, then passed to the code generator, and finally passed to
the assembler) and prints a pretty error message to stderr upon failure:

$:code:rlmeta-poster-2/src/support.py:^def compile_chain:^[^ ]

This function might be useful for other grammars as well. That is why it's
included in the support library and not only in the main file.

### Following a compilation

Let's now follow a compilation of an example grammar to learn more about how
a grammar file is turned into Python code. Here it is:

$~shell~rlmeta-poster-2~echo -e 'Example {\n    main = .\n}' > example.rlmeta

$:shell:rlmeta-poster-2:cat example.rlmeta:rlmeta

And this is what it compiles to:

$:shell:rlmeta-poster-2:python rlmeta.py --compile example.rlmeta:python

The transformations that the grammar goes through are defined in the main
function:

$:code:rlmeta-poster-2/src/main.py:Parser:^.

So first the grammar file is passed to the `file` rule of the parser:

$:code:rlmeta-poster-2/src/parser.rlmeta:^  file:^  [^ ]

It it turn calls the `grammar` rule to parse all grammars in the file:

$:code:rlmeta-poster-2/src/parser.rlmeta:^  grammar:^  [^ ]

This rule matches the name, the open curly brace, a set of rules, and the
closing curly brace. It will then return an AST that looks like this:

```python
[
    "Grammar",
    "Example",
    ...
]
```

All grammar AST nodes are handed off to the `asts` rule in the code generator:

$:code:rlmeta-poster-2/src/codegenerator.rlmeta:^  asts *=:.

It it turn calls the `ast` rule to process all AST nodes:

$:code:rlmeta-poster-2/src/codegenerator.rlmeta:^  ast *=:.

The `ast` rule treats the first argument in the AST as a rule name, and calls
that rule. In this case `Grammar`:

$:code:rlmeta-poster-2/src/codegenerator.rlmeta:^  Grammar:^  [^ ]

The code generator creates a new AST node representing a grammar. But this AST
node is slightly different and meant to be processed by the assembler. The
result is this:

```python
[
    "Grammar",
    "Example",
    ... ast nodes for consumption by assembler ...
]
```

This AST node and all the others that the code generator produces are passed to
the `asts` rule in the assembler:

$:code:rlmeta-poster-2/src/assembler.rlmeta:^  asts *=:.

It in turn calls the `ast` rule:

$:code:rlmeta-poster-2/src/assembler.rlmeta:^  ast *=:.

Which does the same trick again, now invoking the `Grammar` rule (in the
assembler) which looks like this:

$:code:rlmeta-poster-2/src/assembler.rlmeta:^  Grammar:^  [^ ]

This rule can be read as follows:

* Match the grammar name and all AST nodes
* Perform the following action
    * Define a variable called `rules` which is a list
    * Define a variable called `code` which is a list
    * Define a variable called `labels` which is a dictionary
    * Define a variable called `patches` which is a list
    * Evaluate the AST nodes (with possible side effects recorded in the above
      variables)
    * Tread the contents of the `code` variable as a list of AST nodes and process
      them with the `asts` rule of this grammar
    * Return a string which is generated Python code

The generated code from our example looks like this:

    class Example(Grammar):
        rules = {
            ...
        }
        code = [
            ...
        ]

To understand how the `rule` and `code` sections are generated, we just have to
follow a few more transformations.

Let's look at one more and see how the rule in our example grammar is
transformed.

First, the rule is parsed by the `rule` rule in the parser:

$:code:rlmeta-poster-2/src/parser.rlmeta:^  rule =:^  [^ ]

First the name is matched, then the equals sign, and then an expression
representing the body of the rule.

It our case, this rule produces this AST node:

```python
[
    "Rule",
    "main",
    ...
]
```

That node is going to be processed by the `Rule` rule in the code generator:

$:code:rlmeta-poster-2/src/codegenerator.rlmeta:^  Rule:^  [^ ]

Generating an AST node that looks like this:

```python
[
    ["Rule", "main"],
    ...,
    ["OpCode", "RETURN"]
]
```

Here we can see that the AST from the code generator looks a bit more like
assembly code than a representation of the syntax in the grammar.

The first child in this AST node is going to be handled the `Rule` rule in the
assembler:

$:code:rlmeta-poster-2/src/assembler.rlmeta:^  Rule:^  [^ ]

It does two things:

1. Adds a string value to the `rules` list
2. Adds an entry to the `labels` dictionary to map a label to an index in the
   `code` list

At this point, the variables have the following values.

```python
rules = [
    "'main': 0",
]
labels = {
    'main': 0,
}
```

The second child in the AST node is going to be handled by the `OpCode` rule in
the assembler:

$:code:rlmeta-poster-2/src/assembler.rlmeta:^  OpCode:^  [^ ]

It adds the given op code to the `code` list, giving it this value:

```python
code = [
    ...,
    "RETURN",
]
```

When the `rules` and `code` variables are expanded, the resulting class looks
like this:

    class Example(Grammar):
        rules = {
            'main': 0
        }
        code = [
            ...,
            RETURN
        ]

Hopefully you should now be comfortable to follow transformations yourself to
understand how a compilation is done.

$~shell~rlmeta-poster-2~rm example.rlmeta

### The purpose of the make script

When the make script is called without arguments, it performs a meta
compilation and runs a few tests:

$:shell:rlmeta-poster-2:./make.py

The meaning of a meta compilation is to create a new version of RLMeta that can
still reproduce it self from the source code.

In the output above, we can see that it compiled RLMeta and wrote the result to
`rlmeta1.py`. In this case, since it is exactly the same as `rlmeta.py`, the
compilation stopped there and a few more tests were run using this compiler.
But if we make changes to the source code, `rlmeta1.py` will most likely not be
exactly the same as `rlmeta.py`, and a few more compilations might be needed.
I've written about the details of meta compilation in a [previous blog
post](/writing/modifying-rlmeta/index.html#5f6a1c91143146dbb3b865ac42562135).

So the purpose of the make script is the ease meta compilations and also run a
test suit on the newly generated metacompiler before accepting it.

## Changes from the previous version

This section explains the most important changes in this version of RLMeta
compared to the original poster version.

First of all, I wanted to work on the unresolved items which were the
following:

* The label counter is incremented at match time, not at semantic action
  evaluation time.
* Compilation depends on Bash.
* Assembly code in code generator is hard to read.

In the poster article, I also had a few notes about
[future versions](/writing/creating-rlmeta-poster/index.html#b070abcd2f134cf894e33e63188a9fee):

> The smaller it is, the easier it is to understand and therefore extend. The
> more flexible it is to extend the better. If I make another poster version it
> would therefore focus on being smaller and more flexible. Since all
> successive version of RLMeta have been faster than the ones before,
> performance is also important. But small size, clarity, and flexibility come
> first.

I used these guidelines to decide if certain changes should go into the new
version or not.

One interesting thing to note is that the guidelines are sometimes
contradicting. Writing clear code might mean more lines of code which makes the
code base larger. Perhaps that's also why I got stuck chasing perfection. I
thought I made something easier to read, but it ended up costing 10 extra lines
of code.  Should I include it?

### Generate labels in semantic actions

One thing that I left in the first version of the poster that still annoyed me
was that labels were generated at match time, not at semantic action evaluation
time. It would not produce incorrect results. At worst, some labels end up not
being used because the counter value captured was in a rule that later failed.
But dealing with labels at match time does not make sense. It should really
happen at semantic action evaluation time.

Here is what the `Not` rule looks like in the first version of the poster:

$:file:scratch.rlmeta
Not = ast:x #:a #:b -> { "I('BACKTRACK', " b ")\n"
                         x
                         "I('COMMIT', " a ")\n"
                         "LABEL(" a ")\n"
                         "I('FAIL', 'no match expected')\n"
                         "LABEL(" b ")\n"                   }
$:endfile
$:code:scratch.rlmeta
$~shell~.~rm scratch.rlmeta

Here is what the `Not` rule looks like after the change:

$:file:scratch.rlmeta
Not = ast:x -> label():a -> label():b
            -> { "I('BACKTRACK', " b ")\n"
                 x
                 "I('COMMIT', " a ")\n"
                 "LABEL(" a ")\n"
                 "I('FAIL', 'no match expected')\n"
                 "LABEL(" b ")\n"                   }
$:endfile
$:code:scratch.rlmeta
$~shell~.~rm scratch.rlmeta

This change puts label generation where it belongs, in semantic actions, and
thus makes the implementation **more clear**. The VM is no longer concerned
with labels. It is only concerned with matching. This change required a bit of
rework how semantic actions work. Previously only one expression was allowed:

    <match expression> -> <semantic action expression>

Now multiple expressions are allowed:

    <match expression> -> <semantic action expression>:x
                       -> <semantic action expression>
                       -> <semantic action expression>

The result of expressions can also be bound to names which subsequent
expressions can refer to. `label` is such a variable that is set internally to
a function that generates increasing integers starting at 0.

The implementation of this change also **increases the flexibility** of RLMeta.
For example, it is now possible to write a semantic action that generates code
in different sections like this:

$:file:rlmeta-poster-2/example_buffers.rlmeta
ExampleBuffers {
    program  = ast:x  -> []:header
                      -> { "# HEADER\n"
                           header
                           "# BODY\n"
                           x            }
    ast      = [%:x]  -> x
    Program  = ast*
    Function = .:name -> add(header { "def " name "\n" })
                      -> { name "()\n" }
}
$:endfile
$:code:rlmeta-poster-2/example_buffers.rlmeta

The expressions `[]:header` creates a list and assigns it to the variable
`header`. When `x` is evaluated, the semantic action for the `Function` rule
will be evaluated which can then access the `header` variable defined earlier.
These variables are not lexically scoped, but dynamically scoped. If at
runtime, a variable is defined, it will be accessible. It also means that the
`Function` rule can not be runt without `program` being run first, or the
`header` variable will not be defined.

Here is an example AST representing a program:

$:file:rlmeta-poster-2/ast.py
AST = [
    ['Program',
        ['Function', 'foo'],
        ['Function', 'bar']
    ]
]
$:endfile
$:code:rlmeta-poster-2/ast.py

$:file:rlmeta-poster-2/main.py
import sys
sys.stdout.write(ExampleBuffers().run("program", AST))
$:endfile

$~shell~rlmeta-poster-2~python rlmeta.py --support --compile example_buffers.rlmeta --copy ast.py --copy main.py > example_buffers.py

When the `program` rule is run on the example input, the following is output:

$:shell:rlmeta-poster-2:python example_buffers.py

This type of thing is useful for example when generating C functions where
definitions need to go in "header" and declarations in "body".

In summary, this change is as follows:

* Label syntax (`#`) in parser is removed
* Actions can have multiple expressions
* Expressions can be bound to names
* A default `label` function to generate labels
* Names in semantic actions refer to matches or results bound earlier

The complete initial diff for this change can be found on
[GitHub](https://github.com/rickardlindberg/rickardlindberg.me/commit/5154583e9d98c123630fb41664aa6906d4801d05).
Note that later changes have been made that make the `Not` rule not look like
above for example.

The increased clarity and flexibility come with a price. The size increases and
the performance drops.

The parser and the code generator are mostly the same. The greatest addition is
in the support library. Which is expected when semantic action evaluation
becomes more complex. The drop in performance is likely due to more function
calls when evaluating semantic actions. Even though size and performance got
worse, I believe the clarity and flexibility gain is worth it.

$~shell~rlmeta-poster-2~rm example_buffers.rlmeta
$~shell~rlmeta-poster-2~rm main.py
$~shell~rlmeta-poster-2~rm ast.py
$~shell~rlmeta-poster-2~rm example_buffers.py
$~shell~rlmeta-poster-2~rm -rf __pycache__

### Remove dependency on Bash

To compile the previous version of RLMeta, you ran the following command:

    ./compile.sh rlmeta.py

In one way, the compiler could not compile itself, but relied on a Bash script
for gluing things together. It would call the `rlmeta.py` compiler for certain
tasks and use Bash and Python for other tasks.

As we have already seen, the new version of RLMeta compiles itself like this:

    python rlmeta.py \
        --embed SUPPORT src/support.py \
        --support \
        --compile src/parser.rlmeta \
        --compile src/codegenerator.rlmeta \
        --compile src/assembler.rlmeta \
        --copy src/main.py \
        > rlmeta.py

The `rlmeta.py` compiler now has support (via `--embed` and `--copy`) for doing
what the Bash script previously did.

This makes the compiler slightly larger, but it feels so much cleaner.

In addition, the extra features are useful when writing programs in RLMeta.
Those programs can now also be compiled with a single command, and there is no
need to concatenate different pieces together.

The complete diff for this change can be found on
[GitHub](https://github.com/rickardlindberg/rickardlindberg.me/commit/935bb77e1d5b88e09de64112aa2fb2f46dbcb7d9).

### Extract assembler

The third thing I had a problem with was the readability of the code generator.
For example, the `Not` rule looked like this:

$:file:scratch.rlmeta
Not = ast:x -> label():a -> label():b
            -> { "I('BACKTRACK', " b ")\n"
                 x
                 "I('COMMIT', " a ")\n"
                 "LABEL(" a ")\n"
                 "I('FAIL', 'no match expected')\n"
                 "LABEL(" b ")\n"                   }
$:endfile
$:code:scratch.rlmeta
$~shell~.~rm scratch.rlmeta

It generates a string which outputs some Python code that calls some functions
to create "assembly" code. It is mixed and messy.

The new `Not` rule looks like this:

$:file:scratch.rlmeta
Not           = ast:x       -> label():a -> label():b
                            -> [["OpCode" "BACKTRACK"]
                                ["Target" b]
                                ~x
                                ["OpCode" "COMMIT"]
                                ["Target" a]
                                ["Label" a]
                                ["OpCode" "FAIL"]
                                ["Value" "no match"]
                                ["Label" b]]
$:endfile
$:code:scratch.rlmeta
$~shell~.~rm scratch.rlmeta

It now generates abstract assembly code. Much cleaner. And then an assembler
turns that into Python code.

This adds another pass to the compiler. It also makes it possible to do
optimizations on abstract assembly code.

[x] Move "assembly" out of support library. Grammar should generate
    labels/instructions.

[x] Split code generator into code generator and python assembler. That makes
    each phase more clear and allows for optimizations.

[x] Resolve labels in assembler.

[ ] Add one more pass in between parser and codegen that generates VM-instrucionts
    [ ] VM-instructions will be easier to read
    [ ] Possible for peephole optimizations before generating Python code

### Clearer VM

* Previously the VM was written for performance
* Now the VM is written to be clear
* Not sure size changed that much, but clarity did
* Still not happy with the VM

Before I ended up with the clear VM, I did another experiment with PyVM.

PyVM was a new language whose sole purpose was to express virtual machines that
compiled to a Python function. It was basically a small macro language on top
of Python.

    TODO: Example PyVM code

    TODO: Example of what it turned it into

I got this approach working, and the VM was expressed quite nicely, but it
introduced complexity to the whole project:

* There were grammars for PyVM
* The VM had to be generated before it could be included in the support library

I decided that the complexity was not worth it and decided to not care about
performance and instead write the VM as clean as I could in pure Python.

[x] Get rid of PyVM

    [x] Compilation was further complicated now when VM has to be generated and
        a combined support library created.

    [x] Clean up PyVM grammars

    [x] Write VM as clean as possible in Python. Then write a separate
        optimized VM?

### Ability to run a rule in semantic action

* Perhaps it originally came from PyVM?

* Support recursive macros?

    * Probably requires function to run grammar against an object.

    * Needed to get rid of duplicated call code.

### Misc

* Reformat to improve readability.

* Rename to make intention more clear.

* Join using support function
    * Smaller and faster
    * https://github.com/rickardlindberg/rickardlindberg.me/commit/c7cde4ef64db9c871ee25ea7ec39d26a1adb6d7d

* Disallow semantic actions in the middle
    * More clear
    * Before after
    * Test case
    * https://github.com/rickardlindberg/rickardlindberg.me/commit/4934b9105ec609de2d59fce955d41879ef57fcea

    $ echo "Grammar { rule = . ->[] . }" | python rlmeta.py
    class Grammar(Grammar):

        def assemble(self, I, LABEL):
            LABEL('rule')
            I('PUSH_SCOPE')
            I('MATCH_ANY')
            I('ACTION', lambda scope: concat([]))
            I('MATCH_ANY')
            I('POP_SCOPE')
            I('RETURN')

    $ echo "Grammar { rule = . ->[] . }" | python rlmeta.py
    ERROR: expected '}'
    POSITION: 24
    STREAM:
        Grammar { rule = . ->[] <ERROR POSITION>. }

* Allow indent prefix to be changed
    * More flexible
    * Better flexibility at marginal cost. A little slower, but fixed by
      optimizing indent a little.
    * https://github.com/rickardlindberg/rickardlindberg.me/commit/ac6126b7ea6a8d38967d7cb5bcfe6784332f587a

    def indent(text):
        return join(join(["    ", line]) for line in text.splitlines(True))

    def indent(text, prefix="    "):
        return "".join(prefix + line for line in text.splitlines(True))

* Runtime vars outside VM
    * More stuff moved out of VM

* Adapt to Python 3.

* Better error message than None if runtime/scope is not found.

    * Rename match -> matches in Scope
    * Immutable scope instead and fail if entry does not exist?

* Counter class is more clean

* No need to wrap parser output in list for codegenerator in RLMeta

* Put compile + error reporting function in support lib.

* You can put any crap at end of file, and parsers don't care. Fix it!

* VM should not know about runtime.

* No failure if VM-compilation fails? (Swap Instruction arguments.)

* Better AST for action expressions.

* Can "native" calls be removed by adding binding in runtime?

* Put object match expr tree in parser instead of in codegen?

    - This makes the VM more clean. There is only one instruction for matching
      and the matching is done with a Python lambda. The VM knows nothing about
      how to match a single object.

## The future

On the one hand, I'm quite happy with the improvements to RLMeta that I was
able to make. The code feels more clear and flexible. Definitely a better
version of RLMeta.

On the other hand, this article turned out to have the same problem as the
poster. It just kept growing and growing, and at some point I had to stop
working on in, leave some issues unresolved, and call the article finished. For
example, I am not happy with how the new VM looks. A mix between classes and
functions and helpers.

I decided to set up a repo for RLMeta where it can continue to be improved.

I plan for it to contain the base version which is the minimal version to be
able to compile itself and maintain properties such as flexible, easy to
extend, easy to understand.

Then to show examples how you can extend it in various ways and show examples
how RLMeta can be used.

## Code listings for RLMeta

Here is all the source code and also the make script for this version of
RLMeta.

### src/parser.rlmeta

$:code:rlmeta-poster-2/src/parser.rlmeta

### src/codegenerator.rlmeta

$:code:rlmeta-poster-2/src/codegenerator.rlmeta

### src/assembler.rlmeta

$:code:rlmeta-poster-2/src/assembler.rlmeta

### src/support.py

$:code:rlmeta-poster-2/src/support.py

### src/main.py

$:code:rlmeta-poster-2/src/main.py

### make.py

$:code:rlmeta-poster-2/make.py
