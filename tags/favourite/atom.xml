<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <title>Rickard's personal homepage: latest posts tagged favourite</title>
    <link href="http://rickardlindberg.me/tags/favourite/atom.xml" rel="self" />
    <link href="http://rickardlindberg.me" />
    <id>http://rickardlindberg.me/tags/favourite/atom.xml</id>
    <author>
        <name>Rickard Lindberg</name>
        <email>rickard@rickardlindberg.me</email>
    </author>
    <updated>2019-09-25T00:00:00Z</updated>
    <entry>
    <title>Alan Kay notes</title>
    <link href="http://rickardlindberg.me/writing/alan-kay-notes/" />
    <id>http://rickardlindberg.me/writing/alan-kay-notes/</id>
    <published>2019-09-25T00:00:00Z</published>
    <updated>2019-09-25T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1>Alan Kay notes</h1>

<p><em>Published on 25 September 2019.</em></p>

<p>Back in 2012 I watched a talk by Alan Kay called <a href="https://youtu.be/YyIQKBzIuBY">Programming and Scaling</a> in which he talks about how software today has gotten so complex that we can’t comprehend it. Ever since then I’ve been interested in his ideas. In this post I summarize notes and quotes that I’ve gathered while studying Kay and related topics. Fogus did a similar post to this called <a href="http://blog.fogus.me/2018/10/25/soup/">Soup</a>.</p>
<h2 id="how-to-tackle-complexity">How to tackle complexity?</h2>
<p>In the talk Kay hints at one way to tackle complexity which involves solving problems in higher level languages. After listening to his talk and also reading <a href="https://mitpress.mit.edu/sites/default/files/sicp/full-text/book/book.html">SICP</a> in university, I had the following though about how to tackle complexity in software:</p>
<p>Different coordinate systems are suited for different math problems. Choosing the right coordinate system makes the problem easier to solve. The same should be true for programming problems. Each problem probably has an ideal programming language in which it can be solved. The task for a programmer should be to find that language, implement it, and solve the problem in that language.</p>
<p>The ideal language is found if no accidental complexity is present when the problem is solved in that language. That will also make the problem be expressed in few lines of code. So a crude metric of well written software is its size.</p>
<h2 id="steps-project">STEPS project</h2>
<p>Then I found out about the STEPS project (from <a href="http://vpri.org/">VPRI</a>) initiated by Kay in which they try to significantly reduce the number of lines of code required to implement “personal computing”. They do it partly by inventing new languages suited to the problems at hand.</p>
<p>The best overview of the STEPS project I think is the NSF proposal and the progress reports:</p>
<ul>
<li><p><a href="http://www.vpri.org/pdf/rn2006002_nsfprop.pdf">Proposal to NSF – Granted on August 31st 2006</a> (<a href="rn2006002_nsfprop.pdf">mirror</a>)</p></li>
<li><p><a href="http://www.vpri.org/pdf/tr2007008_steps.pdf">STEPS Toward The Reinvention of Programming</a> (<a href="tr2007008_steps.pdf">mirror</a>) (First Year Progress Report, December 2007.)</p></li>
<li><p><a href="http://www.vpri.org/pdf/tr2008004_steps08.pdf">STEPS Toward The Reinvention of Programming, 2008 Progress Report Submitted to the National Science Foundation (NSF), October 2008</a> (<a href="tr2008004_steps08.pdf">mirror</a>)</p></li>
<li><p><a href="http://www.vpri.org/pdf/tr2009016_steps09.pdf">STEPS Toward The Reinvention of Programming, 2009 Progress Report Submitted to the National Science Foundation (NSF) October 2009</a> (<a href="tr2009016_steps09.pdf">mirror</a>)</p></li>
<li><p><a href="http://www.vpri.org/pdf/tr2010004_steps10.pdf">STEPS Toward Expressive Programming Systems, 2010 Progress Report Submitted to the National Science Foundation (NSF) October 2010</a> (<a href="tr2010004_steps10.pdf">mirror</a>)</p></li>
<li><p><a href="http://www.vpri.org/pdf/tr2011004_steps11.pdf">Steps Toward Expressive Programming Systems</a> (<a href="tr2011004_steps11.pdf">mirror</a>) (Annual report to the NSF)</p></li>
<li><p><a href="http://www.vpri.org/pdf/tr2012001_steps.pdf">STEPS Toward the Reinvention of Programming, 2012 Final Report Submitted to the National Science Foundation (NSF) October 2012</a> (<a href="tr2012001_steps.pdf">mirror</a>)</p></li>
</ul>
<p>All their writings can be found <a href="http://vpri.org/writings.php">here</a>. Some favorites of mine:</p>
<ul>
<li><a href="http://www.vpri.org/pdf/tr2008003_experimenting.pdf">Experimenting With Programming Languages</a> (<a href="tr2008003_experimenting.pdf">mirror</a>)</li>
<li><a href="http://www.vpri.org/pdf/rn2010001_programm.pdf">Programming and Programming Languages</a> (<a href="rn2010001_programm.pdf">mirror</a>)</li>
<li><a href="http://www.vpri.org/pdf/tr2006003a_objmod.pdf">Open Reusable Object Models</a> (<a href="tr2006003a_objmod.pdf">mirror</a>)</li>
<li><a href="http://www.vpri.org/pdf/tr2009002_active_essays.pdf">Active Essays on the Web</a> (<a href="tr2009002_active_essays.pdf">mirror</a>)</li>
<li><a href="http://www.vpri.org/pdf/m2009011_chns_mng.pdf">Chains of meaning in the STEPS system</a> (<a href="m2009011_chns_mng.pdf">mirror</a>)</li>
<li><a href="http://www.vpri.org/pdf/m2013003_ksapps.pdf">Making Applications in KSWorld</a> (<a href="m2013003_ksapps.pdf">mirror</a>)</li>
<li><a href="http://www.vpri.org/pdf/tr2013002_KSonward.pdf">KScript and KSworld: A Time-Aware and Mostly Declarative Language and Interactive GUI Framework</a> (<a href="tr2013002_KSonward.pdf">mirror</a>)</li>
</ul>
<p>The STEPS project has many components. One of them is OMeta (described in <em>Experimenting With Programming Languages</em>) which inspired me to implement <a href="/tags/rlmeta/index.html">RLMeta</a>.</p>
<p>A blog post series mentioning the STEPS project and related ideas:</p>
<ul>
<li><a href="https://www.moserware.com/2008/04/towards-moores-law-software-part-1-of-3.html">Towards Moore’s Law Software: Part 1 of 3</a></li>
<li><a href="https://www.moserware.com/2008/04/towards-moores-law-software-part-2-of-3.html">Towards Moore’s Law Software: Part 2 of 3</a></li>
<li><a href="https://www.moserware.com/2008/04/towards-moores-law-software-part-3-of-3.html">Towards Moore’s Law Software: Part 3 of 3</a></li>
</ul>
<h2 id="object-oriented-programming">Object oriented programming</h2>
<p>Kay invented the term object oriented. But I get the feeling that mainstream object oriented programming today is not what he meant it to be. I tried to figure out what he meant it to be. Here are some quotes that I found relevant:</p>
<p>From Kay from <a href="http://worrydream.com/EarlyHistoryOfSmalltalk/">The Early History Of Smalltalk - Bret Victor</a>:</p>
<blockquote>
<p>Somewhere in all of this, I realized that the bridge to an object-based system could be in terms of each object as a syntax directed interpreter of messages sent to it. In one fell swoop this would unify object-oriented semantics with the ideal of a completely extensible language. The mental image was one of separate computers sending requests to other computers that had to be accepted and understood by the receivers before anything could happen. In today’s terms every object would be a server offering services whose deployment and discretion depended entirely on the server’s notion of relationship with the servee.</p>
</blockquote>
<p>From Kay from <a href="http://worrydream.com/EarlyHistoryOfSmalltalk/">The Early History Of Smalltalk - Bret Victor</a>:</p>
<blockquote>
<p>Again, the whole point of OOP is not to have to worry about what is inside an object. Objects made on different machines and with different languages should be able to talk to each other—and will have to in the future. Late-binding here involves trapping incompatibilities into recompatibility methods—a good discussion of some of the issues is found in [Popek 1984].</p>
</blockquote>
<p>From Kay from <a href="http://lists.squeakfoundation.org/pipermail/squeak-dev/1998-October/017019.html">prototypes vs classes was: Re: Sun’s HotSpot</a>:</p>
<blockquote>
<p>Just a gentle reminder that I took some pains at the last OOPSLA to try to remind everyone that Smalltalk is not only NOT its syntax or the class library, it is not even about classes. I’m sorry that I long ago coined the term “objects” for this topic because it gets many people to focus on the lesser idea.</p>
<p>The big idea is “messaging” – that is what the kernal of Smalltalk/Squeak is all about (and it’s something that was never quite completed in our Xerox PARC phase).</p>
</blockquote>
<p>From Kay from <a href="http://www.purl.org/stefan_ram/pub/doc_kay_oop_en">Dr. Alan Kay on the Meaning of “Object-Oriented Programming”</a>:</p>
<blockquote>
<p>I thought of objects being like biological cells and/or individual computers on a network, only able to communicate with messages (so messaging came at the very beginning – it took a while to see how to do messaging in a programming language efficiently enough to be useful).</p>
</blockquote>
<p>From Kay from <a href="http://www.purl.org/stefan_ram/pub/doc_kay_oop_en">Dr. Alan Kay on the Meaning of “Object-Oriented Programming”</a>:</p>
<blockquote>
<p>I wanted to get rid of data. The B5000 almost did this via its almost unbelievable HW architecture. I realized that the cell/whole-computer metaphor would get rid of data, and that “&lt;-” would be just another message token (it took me quite a while to think this out because I really thought of all these symbols as names for functions and procedures.</p>
</blockquote>
<p>From Kay from <a href="http://www.purl.org/stefan_ram/pub/doc_kay_oop_en">Dr. Alan Kay on the Meaning of “Object-Oriented Programming”</a>:</p>
<blockquote>
<p>The original Smalltalk at Xerox PARC came out of the above. The subsequent Smalltalk’s are complained about in the end of the History chapter: they backslid towards Simula and did not replace the extension mechanisms with safer ones that were anywhere near as useful.</p>
</blockquote>
<p>From Kay from <a href="http://www.purl.org/stefan_ram/pub/doc_kay_oop_en">Dr. Alan Kay on the Meaning of “Object-Oriented Programming”</a>:</p>
<blockquote>
<p>OOP to me means only messaging, local retention and protection and hiding of state-process, and extreme late-binding of all things. It can be done in Smalltalk and in LISP. There are possibly other systems in which this is possible, but I’m not aware of them.</p>
</blockquote>
<p>From a user in the <a href="https://news.ycombinator.com/item?id=19415983">Hacker News thread</a> discussing the above article:</p>
<blockquote>
<p>Containers are a validation of Kay’s idea that sharing encapsulated objects is easier than sharing data.</p>
</blockquote>
<p>From a user in the <a href="https://news.ycombinator.com/item?id=19415983">Hacker News thread</a> discussing the above article:</p>
<blockquote>
<p>Because a lot of people (including me) have a Simula based view of “object oriented”, we tend to think of objects as data structures with functions attached to them. Alan Kay had a different view, as far as I can tell. He viewed objects as being a collection of abilities. You could invoke these abilities by sending the object a “message”. How you send that message is irrelevant. The important thing is that the object is not a collection of data, but rather the object contains the program state necessary to provide the ability (and nothing more). One of the things he talks about (I can’t remember if he does in this specific email exchange, though) is the idea that once the data is inside the object, you can’t actually access it any more. It becomes a detail that the programmer doesn’t have to worry about.</p>
</blockquote>
<p>From a user in the <a href="https://news.ycombinator.com/item?id=19415983">Hacker News thread</a> discussing the above article:</p>
<blockquote>
<p>Smalltalk had to cut corners with messaging due to the limited processing of the time, nevertheless it has fully reified messages; one can express the sending of messages between objects.</p>
<p>Smalltalk inspired Erlang, which is the fully-asynchronous messaging/independent threads of execution part of OO only.</p>
<p>Self did OO without inheritance (composition by prototypes).</p>
</blockquote>
<h2 id="late-binding">Late binding</h2>
<p>Late-binding is another idea that Kay talks about that I want to understand better.</p>
<p>From Kay from <a href="http://worrydream.com/EarlyHistoryOfSmalltalk/">The Early History Of Smalltalk - Bret Victor</a>:</p>
<blockquote>
<p>Staying with the metaphor of late-binding, what further late-binding schemes might we expect to see? One of the nicest late-binding schemes that is being experimented with is the metaobject protocol work at Xerox PARC [Kiczales 1991]. The notion is that the language designer’s choice for the internal representation of instances, variables, etc., may not cover what the implementer needs, so within a fixed semantics they allow the implementer to give the system strategies—for example, using a hashed lookup for slots in an instance instead of direct indexing. These are then efficiently compiled and extend the base implementation of the system.</p>
</blockquote>
<h2 id="direct-manipulation">Direct manipulation</h2>
<p>From Kay from <a href="https://www.quora.com/What-exactly-is-WYSIWYG/answer/Alan-Kay-11">What exactly is WYSIWYG?</a>:</p>
<blockquote>
<p>In programming, you don’t want to go through a edit in an editor, submit to a compiler, which submits to a loader, which requires your system to intiialize, and so forth. You just want to be able to deal directly and safely with what you are trying to achieve.</p>
</blockquote>
<p>A related idea about no modes is presented by Larry Tesler in <a href="http://worrydream.com/refs/Tesler%20-%20A%20Personal%20History%20of%20Modeless%20Text%20Editing%20and%20Cut-Copy-Paste.pdf">A Personal History of Modeless Text Editing and Cut/Copy-Paste</a>.</p>
<h2 id="random-topics">Random topics</h2>
<p>Other topics that I got from Kay:</p>
<ul>
<li>What vs. How Programming: State the problem, then let the computer solve the problem: what programming instead of how programming.</li>
<li>Living in the Future: University students need powerful machines so that they can code like they live in the future. So that they can code without caring about optimizations.</li>
<li>Most people can only see the future through the past.</li>
<li>Learning to See:
<ul>
<li>Drawing without “parsing” the object.</li>
<li>Turn it upside down and just draw it like you see it.</li>
<li>Measure instead of perceive.</li>
</ul></li>
<li>Engineering Vs. Science Vs. Tinkering.</li>
<li>T-shirt Programming.</li>
<li>Meta Language.</li>
<li>Computing History.</li>
<li>Inventing Future.</li>
</ul>
<h2 id="further-reading">Further reading</h2>
<ul>
<li><a href="https://news.ycombinator.com/item?id=11808551">Ask HN: Relationship between OO and functional programming?</a></li>
<li><a href="https://news.ycombinator.com/item?id=11939851">Alan Kay has agreed to do an AMA today</a></li>
<li><a href="http://www.chilton-computing.org.uk/inf/pdfs/kay.htm">The Reactive Engine</a></li>
<li><a href="https://www.youtube.com/results?search_query=alan+kay">Alan Kay search on Youtube</a></li>
<li><a href="https://github.com/d-cook/SomethingNew">SomethingNew</a></li>
</ul>
]]></summary>
</entry>
<entry>
    <title>A meta approach to implementing programming languages</title>
    <link href="http://rickardlindberg.me/writing/rlmeta/" />
    <id>http://rickardlindberg.me/writing/rlmeta/</id>
    <published>2018-12-02T00:00:00Z</published>
    <updated>2018-12-02T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1>A meta approach to implementing programming languages</h1>

<p><em>Published on  2 December 2018.</em></p>

<p><em>28 May 2019: Added link to next article in</em> <a href="#2c78e9d9104c4bddbdd1dfe6314506c9"><em>Putting it together</em></a>.</p>
<p>How does the computer know what to do with the following expression?</p>
<pre class="text"><code>1+2*3</code></pre>
<p>How does it know how to recognize the sequence of characters as an arithmetic expression? How does it know that <code>2*3</code> should be computed first? How does it translate it to instructions that execute on the CPU?</p>
<p>In this article I present a metalanguage that I've developed that can help answer those questions.</p>
<ul>
<li><a href="#3f00cf52d91a411d941312539a15cc32">Metalanguages</a></li>
<li><a href="#ee16dcaf86a7402e9ca78edc620caacb">Interpreting expressions</a></li>
<li><a href="#61e10d1de6624255a4406572fef4b413">Compiling expressions</a></li>
<li><a href="#f5f122c94d3d4fa0b3a7e64a7fa0a724">RLMeta implementation</a>
<ul>
<li><a href="#1e01a8bdd22d48f2a7e8533d552bc264">Parser</a>
<ul>
<li><a href="#a757df1ad1764cc996d9d3e0a0ce4d25">Grammar</a></li>
<li><a href="#e1799ddc14ce4a7f83c8f390f9bf8720">Rule</a></li>
<li><a href="#c2a43ebb9a7d477f8dd7126f94bd33de">Choice</a></li>
<li><a href="#08818eb200d0482f8feb9104e1ae2ea7">Sequence</a></li>
<li><a href="#5fca8ddb3f88457bbe5217fa1ebf4383">Expression</a></li>
<li><a href="#cdeac4c7bcb84261a3d194c1183c9dd7">Expression of level 1</a></li>
<li><a href="#4e76262e4c9841db8c0b79401ac7a8ff">Expression of level 2</a></li>
<li><a href="#768d143c206146ca8efba292c6e9169b">Host expression</a></li>
<li><a href="#2057abb618bf4209950acd87fa49da5d">Character related</a></li>
<li><a href="#19acecc9fbc44023a69cea9eadbe734d">Name</a></li>
<li><a href="#d729731e037a4a5aafa6da77d2b8bdb1">Space</a></li>
</ul></li>
<li><a href="#c3f29fa523f341a487ebc07209c471f9">Code generator</a>
<ul>
<li><a href="#b225bd1638614a808495e33a63797beb">Note on target language</a></li>
<li><a href="#69841ad3d1044db18591fe09cdf1caee">Parsing algorithm</a></li>
<li><a href="#0d8a472a5c844a729b866f2c2c64794b">Structure of code generator</a></li>
<li><a href="#ed6931f4eeca4d43aaee1e9f5485a295">Grammar</a></li>
<li><a href="#3c542ba5b0104273805b227aeab84c04">Rule</a></li>
<li><a href="#696631bc029c47949b2ad97ce78ea32c">Or</a></li>
<li><a href="#86438bda56d342bc9d1f2c62e632a72d">Scope</a></li>
<li><a href="#487e675a013c45e3aee8b6c068e226df">And</a></li>
<li><a href="#4309ca572367401bb6c4561f273b8c85">Bind</a></li>
<li><a href="#244f0754be514ae88e0f581f3ab58c59">Star</a></li>
<li><a href="#44d3b166c62d43e38d2a781fb9f06b6d">Not</a></li>
<li><a href="#07530ffd21784561bd8594c98fcd050a">Semantic action</a></li>
<li><a href="#c10aabed8057404e97ef8cd6ac1b113d">Match rule</a></li>
<li><a href="#3ba5893bb7094ece96e853f869df9456">Match range</a></li>
<li><a href="#82022cc15d944579825b52559b1ee469">Match string</a></li>
<li><a href="#3eff70b8911e4b4e9bd520a7d25624e7">Match character sequence</a></li>
<li><a href="#5edd25f746a94b8392834343dce57370">Match any</a></li>
<li><a href="#c3b58d2d7b024fa4a0e5ff0bcf06d154">Match list</a></li>
<li><a href="#74804e4e0ee643ac95210d7aa17ae7c6">String</a></li>
<li><a href="#03d7a70d44fe4470967acd15d51ad56a">List</a></li>
<li><a href="#166dffacb2ca4911908584d77f30b21f">Builder</a></li>
<li><a href="#f5372dab8e084ca386297eb9575052e8">Function call</a></li>
<li><a href="#d9f73bdeb5c447dbaf5b8fe0bf3b67ba">Variable lookup</a></li>
<li><a href="#4397d20868fa4c08ac289e463725f18e">Final support methods</a></li>
</ul></li>
<li><a href="#2c78e9d9104c4bddbdd1dfe6314506c9">Putting it together</a></li>
<li><a href="#313b147a2f574ea09d76d9c7371bdf18">Bootstrapping</a></li>
</ul></li>
<li><a href="#5f558623cfce441fb3e61033299d1419">Implementing programming languages</a></li>
<li><a href="#4c6af1a11ed440d2bf31a497032c9c0b">Resources</a></li>
<li><a href="#388bb1e8ccbd4d55b89b391c08452c33">Code listings for RLMeta</a>
<ul>
<li><a href="#a56c54f42c00473091d7c8295ff4e0f1">parser.rlmeta</a></li>
<li><a href="#d9ea64bbdad3465897667ebec9d5ace1">codegenerator.rlmeta</a></li>
<li><a href="#983e606587034a0a9c8e8b5c714e7ef8">support.py</a></li>
<li><a href="#193d8f0ff47f4edcb201139df8cd9520">compile.sh</a></li>
</ul></li>
</ul>
<h2 id="f00cf52d91a411d941312539a15cc32metalanguages">[]{#3f00cf52d91a411d941312539a15cc32}Metalanguages</h2>
<p>Metalanguages are used to reason about languages. In metalanguages you can make statements about statements in a different language.</p>
<p>The metalanguage I've developed is called RLMeta. It is inspired by a metalanguage from the sixties called <a href="https://en.wikipedia.org/wiki/META_II">META II</a>. I wanted to develop my own version of META II to understand it deeply. RLMeta is also inspired by <a href="https://en.wikipedia.org/wiki/OMeta">OMeta</a> (another META II derivative).</p>
<p>RLMeta is a programming language in which you write grammars. Grammars have rules that specify how to match objects from an input stream and specify what should happen when objects are matched. The RLMeta compiler translates grammars into programs that recognize the objects specified in the grammar and evaluates the semantic actions when the objects are matched.</p>
<p><img src="image1.png" /></p>
<!-- image text -->
<center>
Overview of RLMeta compiler.
</center>
<h2 id="interpreting-expressions"><span id="ee16dcaf86a7402e9ca78edc620caacb"></span>Interpreting expressions</h2>
<p>How can RLMeta be used to give meaning to arithmetic expressions of the kind presented in the introductory example? Here is a grammar:</p>
<pre><code>1.  calculator
2.  calculator.rlmeta</code></pre>
<pre><code>Calculator {
  expression =
    | additive
  additive =
    | multitive:x &#39;+&#39; additive:y -&gt; add(x y)
    | multitive
  multitive =
    | digit:x &#39;*&#39; multitive:y    -&gt; mul(x y)
    | digit
  digit =
    | &#39;0&#39;-&#39;9&#39;:x                  -&gt; int(x)
}</code></pre>
<p>This grammar is called <code>Calculator</code>. It has four rules. The first rule says that an expression is an additive. The second rule says that an additive is either a multitive followed by the character '+' followed by another additive or just a multitive. The second case is only tried if the first does not match. The third rule says that a multitive is either a digit followed by the character '*' followed by another multitive or just a digit. The fourth rule says that a digit is a character in the range 0-9. The <code>:</code> followed by a name binds the result of a match to a variable. The expressions to the right of <code>-&gt;</code> are semantic actions. They specify what should happen on a match. They can refer to variables. In this grammar they say that whenever an additive is matched, call the host language function <code>add</code> with the left and right side, and whenever a multitive is matched, call the host language function <code>mul</code> with the left and right side, and whenever a digit is matched, call the host language function <code>int</code> with the digit character. The host language function <code>int</code> converts a digit character to an integer and the <code>add</code> and <code>mul</code> functions perform addition and multiplication.</p>
<p>This grammar describes how to recognize an arithmetic expression in a sequence of characters. Precedence is encoded by the order of the rules. An additive is <code>x1 + x2 + x3 + ..</code> where the xes are multitives. Therefore multiplication is performed before addition. It gives meaning to the expression by calling host language functions when parts are matched.</p>
<p>When the calculator grammar is fed to the RLMeta compiler, a program is output that is an interpreter for arithmetic expressions.</p>
<p><img src="image2.png" /></p>
<!-- image text -->
<center>
Overview of calculator compilation.
</center>
<p>More specifically, this program is a Python class that implements interpretation of arithmetic expressions. The class depends on a support library and also on the host language functions that were called from the grammar (<code>add</code>, <code>mul</code>, and <code>int</code>). Host language refers to the language that grammars are compiled to. In this case Python. The pieces must be assembled to form an executable program. Here is a template for the final Python file that implements a read-eval-print loop (REPL) for arithmetic expressions:</p>
<pre><code>1.  calculator
2.  compile.sh
3.  [python file template]{.cp}</code></pre>
<pre><code>from operator import add, mul

$support_py

$calculator_py

if __name__ == &quot;__main__&quot;:
    calculator = Calculator()
    while True:
        line = raw_input(&quot;&gt; &quot;)
        result = calculator.run(&quot;expression&quot;, line)
        print(result)</code></pre>
<p>First the host language functions are imported (<code>int</code> is always available). Then the support library and the compiled calculator grammar snippets are inserted. Finally the main method which is the REPL is implemented. Compiled grammars are used by instantiating them and calling their <code>run</code> method with the name of the rule and the input object. This template is rendered with a Bash script:</p>
<pre><code>1.  calculator
2.  compile.sh</code></pre>
<pre><code>#!/bin/bash

set -e

cd &quot;$(dirname &quot;$0&quot;)&quot;

support_py=$(python ../rlmeta/rlmeta.py --support)
calculator_py=$(python ../rlmeta/rlmeta.py &lt; calculator.rlmeta)

cat &lt;&lt;EOF
&lt;&lt;python file template&gt;&gt;
EOF</code></pre>
<p>First the <code>set -e</code> directive ensures that the script exits as soon as there is an error. Then the directory is changed to the one where the compile script lives. Then the output of two calls to the RLMeta compiler (<code>rlmeta.py</code>) are captured in two variables. The RLMeta compiler reads a grammar from stdin and writes a Python class to stdout. If the <code>--support</code> flag is given, it writes the support library to stdout instead. The <code>command &lt; file</code> syntax redirects the contents of the file to the command's stdin. Finally the Python file template is rendered and written to stdout using a <a href="https://en.wikipedia.org/wiki/Here_document#Unix_shells">here document</a> which has access to the previously captured variables.</p>
<p>Example usage on the command line:</p>
<pre class="text"><code>$ python &lt;(./calculator/compile.sh)
&gt; 1+2*3
7</code></pre>
<p>The compile script writes a Python file to stdout. The <code>&lt;(command)</code> syntax is <a href="https://en.wikipedia.org/wiki/Process_substitution">process substitution</a> and turns the output of the command into a temporary file which can then be run with Python.</p>
<p>In this example, the input stream to the calculator becomes a list of characters:</p>
<pre class="text"><code>[&#39;1&#39;, &#39;+&#39;, &#39;2&#39;, &#39;*&#39;, &#39;3&#39;]</code></pre>
<p>When the calculator matches the expression, the following host language functions will be called:</p>
<pre class="text"><code>add(int(&#39;1&#39;), mul(int(&#39;2&#39;), int(&#39;3&#39;)))</code></pre>
<h2 id="e10d1de6624255a4406572fef4b413compiling-expressions">[]{#61e10d1de6624255a4406572fef4b413}Compiling expressions</h2>
<p>The previous example relied on host language functions to perform addition and multiplication. The meaning of an expression was defined in terms of the meaning of Python functions. To understand what an expression means, you need to understand how Python implements those functions. The next example compiles an expression down to a kind of assembly language that eliminates the need for Python.</p>
<p>For this compilation, two grammars are written: a parser and a code generator. The parser looks similar to the calculator grammar but instead of evaluating the expression, it creates an abstract syntax tree (AST) describing the expression:</p>
<pre><code>1.  expression
2.  parser.rlmeta</code></pre>
<pre><code>Parser {
  expression =
    | additive
  additive =
    | multitive:x &#39;+&#39; additive:y -&gt; [&quot;add&quot; x y]
    | multitive
  multitive =
    | digit:x &#39;*&#39; multitive:y    -&gt; [&quot;mul&quot; x y]
    | digit
  digit =
    | &#39;0&#39;-&#39;9&#39;:x                  -&gt; [&quot;digit&quot; x]
}</code></pre>
<p>The bracket notation in the semantic actions creates lists. Nodes in the AST are represented as lists where the first item is a string denoting the type of node.</p>
<p>The code generator takes as input an AST from the parser and generates assembly language code for an imaginary stack machine:</p>
<pre><code>1.  expression
2.  codegenerator.rlmeta</code></pre>
<pre><code>CodeGenerator {
  ast =
    | [&quot;add&quot; ast:x ast:y] -&gt; { x y &quot;add&quot;     &quot;\n&quot; }
    | [&quot;mul&quot; ast:x ast:y] -&gt; { x y &quot;mul&quot;     &quot;\n&quot; }
    | [&quot;digit&quot; .:x]       -&gt; {     &quot;push &quot; x &quot;\n&quot; }
}</code></pre>
<p>This grammar has only one rule: <code>ast</code>. It says that an AST is either a list that starts with the string 'add', or a list that starts with the string 'mul', or a list that starts with the string 'digit'. The add and mul cases recursively match AST nodes as their left and right side whereas the digit matches anything (<code>.</code>) which is the digit stored in the AST node. The semantic actions in this grammar generate string output which is denoted by the curly braces. When a digit AST node is matched, the string 'push [digit]\n' is generated. It instructs the stack machine to push the given digit to the stack. For add and mul, instructions for the operands are first output followed by an 'add\n' or 'mul\n' instruction. They instruct the stack machine to pop two numbers off the stack, add or multiply them, and push the result.</p>
<p>This grammar describes how to recognize and AST in a sequence of objects. It gives meaning to the AST by generating assembly language code when AST nodes are matched.</p>
<p>When the expression grammars are fed to the RLMeta compiler, programs are output whose combination is a compiler for arithmetic expressions.</p>
<p><img src="image3.png" /></p>
<!-- image text -->
<center>
Overview of expression compilation.
</center>
<p>Here is a template for the final Python file that implements a REPL for arithmetic expression compilation:</p>
<pre><code>1.  expression
2.  compile.sh
3.  [python file template]{.cp}</code></pre>
<pre><code>import sys

$support_py

$parser_py

$codegenerator_py

if __name__ == &quot;__main__&quot;:
    parser = Parser()
    codegenerator = CodeGenerator()
    while True:
        line = raw_input(&quot;&gt; &quot;)
        ast = parser.run(&quot;expression&quot;, line)
        assembly = codegenerator.run(&quot;ast&quot;, ast)
        sys.stdout.write(assembly)</code></pre>
<p>First the <code>sys</code> module is imported because the main method needs it. Then the support library, compiled parser grammar, and compiled code generator grammar snippets are inserted. Finally the main method which is the REPL is implemented. The output of the parser is fed to the code generator and its output is finally written to stdout. This template is rendered with a Bash script:</p>
<pre><code>1.  expression
2.  compile.sh</code></pre>
<pre><code>#!/bin/bash

set -e

cd &quot;$(dirname &quot;$0&quot;)&quot;

support_py=$(python ../rlmeta/rlmeta.py --support)
parser_py=$(python ../rlmeta/rlmeta.py &lt; parser.rlmeta)
codegenerator_py=$(python ../rlmeta/rlmeta.py &lt; codegenerator.rlmeta)

cat &lt;&lt;EOF
&lt;&lt;python file template&gt;&gt;
EOF</code></pre>
<p>First the <code>set -e</code> directive ensures that the script exits as soon as there is an error. Then the directory is changed to the one where the compile script lives. Then the output of three calls to the RLMeta compiler are captured in three variables. Finally the Python file template is rendered and written to stdout.</p>
<p>Example usage on the command line:</p>
<pre class="text"><code>$ python &lt;(./expression/compile.sh)
&gt; 1+2*3
push 1
push 2
push 3
mul
add
&gt; 1*2+3
push 1
push 2
mul
push 3
add</code></pre>
<p>In the first example, the input stream to the parser becomes a list of characters (same as for the calculator):</p>
<pre class="text"><code>[&#39;1&#39;, &#39;+&#39;, &#39;2&#39;, &#39;*&#39;, &#39;3&#39;]</code></pre>
<p>The input stream to the code generator becomes a list with a single object which is a list (the root AST node):</p>
<pre class="text"><code>[
    [
        &#39;add&#39;,
        [&#39;digit&#39;, &#39;1&#39;],
        [
            &#39;mul&#39;,
            [&#39;digit&#39;, &#39;2&#39;],
            [&#39;digit&#39;, &#39;3&#39;]
        ]
    ]
]</code></pre>
<p>The generated assembly language code is much closer to CPU instructions than the Python-based interpreter. A grammar could be written to convert these assembly instructions to assembly instructions of a real CPU. But I will not do that here. The point is that the meaning of an expression can be described by a series of transformations that eventually output machine instructions.</p>
<h2 id="rlmeta-implementation"><span id="f5f122c94d3d4fa0b3a7e64a7fa0a724"></span>RLMeta implementation</h2>
<p>So far I've just given informal descriptions of how RLMeta works. To fully understand how arithmetic expressions are evaluated and compiled, you need to understand how RLMeta is implemented.</p>
<p>The RLMeta compiler translates a grammar to a Python class. This translation is implemented in RLMeta itself. A grammar is, like an expression, translated in two steps: the parser translates grammar syntax to an AST and the code generator translates the AST to a Python class. The generated Python class depends on a support library.</p>
<p><img src="image4.png" /></p>
<!-- image text -->
<center>
RLMeta compiler internals illustrated.
</center>
<p>The RLMeta compiler thus comprises three pieces: the parser, the code generator, and the support library.</p>
<h3 id="e01a8bdd22d48f2a7e8533d552bc264parser">[]{#1e01a8bdd22d48f2a7e8533d552bc264}Parser</h3>
<p>This section defines the parser:</p>
<pre><code>1.  rlmeta
2.  parser.rlmeta</code></pre>
<pre><code>Parser {
  &lt;&lt;rules&gt;&gt;
}</code></pre>
<h4 id="grammar"><span id="a757df1ad1764cc996d9d3e0a0ce4d25"></span>Grammar</h4>
<p>The top level syntactic element is a grammar. A grammar has a <a href="#19acecc9fbc44023a69cea9eadbe734d"><em>name</em></a> followed by <a href="#e1799ddc14ce4a7f83c8f390f9bf8720"><em>rules</em></a> enclosed in curly braces. When this is matched, a <code>Grammar</code> AST node is created containing the name of the grammar and the rule AST nodes:</p>
<pre><code>1.  rlmeta
2.  parser.rlmeta
3.  [rules]{.cp}</code></pre>
<pre><code>grammar =
  | name:x space &#39;{&#39; rule*:ys space &#39;}&#39; -&gt; [&quot;Grammar&quot; x ~ys]</code></pre>
<p>Throughout the parser, <a href="#d729731e037a4a5aafa6da77d2b8bdb1"><em>space</em></a> is ignored. As a rule of thumb, it is inserted before matching a character sequence (and not before matching other rules).</p>
<p>The <code>*</code> operator after <code>rule</code> means match the preceding expression zero or more times. The result is a list.</p>
<p>The <code>~</code> operator in the semantic action means splice the list in-line into the enclosing list. The <code>Grammar</code> AST node thus has the name as element one, the first rule AST node as element two, the second rule AST node as element three, and so on.</p>
<h4 id="rule"><span id="e1799ddc14ce4a7f83c8f390f9bf8720"></span>Rule</h4>
<p>A rule has a <a href="#19acecc9fbc44023a69cea9eadbe734d"><em>name</em></a> followed by an equal sign followed by a <a href="#c2a43ebb9a7d477f8dd7126f94bd33de"><em>choice</em></a>. When this is matched, a <code>Rule</code> AST node is created containing the name and the choice AST node:</p>
<pre><code>1.  rlmeta
2.  parser.rlmeta
3.  [rules]{.cp}</code></pre>
<pre><code>rule =
  | name:x space &#39;=&#39; choice:y -&gt; [&quot;Rule&quot; x y]</code></pre>
<h4 id="choice"><span id="c2a43ebb9a7d477f8dd7126f94bd33de"></span>Choice</h4>
<p>A choice has <a href="#08818eb200d0482f8feb9104e1ae2ea7"><em>sequences</em></a> separated by vertical bars. Optionally the first sequence can start with a vertical bar to allow all sequence lines to look the same. When this is matched, an <code>Or</code> AST node is created containing the sequence AST nodes:</p>
<pre><code>1.  rlmeta
2.  parser.rlmeta
3.  [rules]{.cp}</code></pre>
<pre><code>choice =
  | (space &#39;|&#39;)?
    sequence:x (space &#39;|&#39; sequence)*:xs -&gt; [&quot;Or&quot; x ~xs]</code></pre>
<p>The <code>?</code> operator means match the preceding expression zero or one time.</p>
<p>The result of <code>xs</code> is a list of sequences since the expression inside parenthesis returns the last match (which is a sequence).</p>
<h4 id="eb200d0482f8feb9104e1ae2ea7sequence">[]{#08818eb200d0482f8feb9104e1ae2ea7}Sequence</h4>
<p>A sequence has one or more <a href="#5fca8ddb3f88457bbe5217fa1ebf4383"><em>expressions</em></a>. When this is matched, a <code>Scope</code> AST node is created containing an <code>And</code> AST node containing the expression AST nodes:</p>
<pre><code>1.  rlmeta
2.  parser.rlmeta
3.  [rules]{.cp}</code></pre>
<pre><code>sequence =
  | expr:x expr*:xs -&gt; [&quot;Scope&quot; [&quot;And&quot; x ~xs]]</code></pre>
<h4 id="fca8ddb3f88457bbe5217fa1ebf4383expression">[]{#5fca8ddb3f88457bbe5217fa1ebf4383}Expression</h4>
<p>An expression is one of the following sequences:</p>
<pre><code>1.  rlmeta
2.  parser.rlmeta
3.  [rules]{.cp}</code></pre>
<pre><code>expr =
  | expr1:x space &#39;:&#39; name:y -&gt; [&quot;Bind&quot; y x]
  | expr1</code></pre>
<p>The first sequence is an <a href="#cdeac4c7bcb84261a3d194c1183c9dd7"><em>expression of level 1</em></a> followed by a colon followed by a <a href="#19acecc9fbc44023a69cea9eadbe734d"><em>name</em></a>. When this is matched, a <code>Bind</code> AST node is created containing the name and the expression AST node.</p>
<p>The second sequence is an <a href="#cdeac4c7bcb84261a3d194c1183c9dd7"><em>expression of level 1</em></a>.</p>
<h4 id="expression-of-level-1"><span id="cdeac4c7bcb84261a3d194c1183c9dd7"></span>Expression of level 1</h4>
<p>An expression of level 1 is one of the following sequences:</p>
<pre><code>1.  rlmeta
2.  parser.rlmeta
3.  [rules]{.cp}</code></pre>
<pre><code>expr1 =
  | expr2:x space &#39;*&#39; -&gt; [&quot;Star&quot; x]
  | expr2:x space &#39;?&#39; -&gt; [&quot;Or&quot; x [&quot;And&quot;]]
  | space &#39;!&#39; expr2:x -&gt; [&quot;Not&quot; x]
  | expr2</code></pre>
<p>The first sequence is an <a href="#4e76262e4c9841db8c0b79401ac7a8ff"><em>expression of level 2</em></a> followed by an asterisk. When this is matched, a <code>Star</code> AST node is created containing the expression AST node.</p>
<p>The second sequence is an <a href="#4e76262e4c9841db8c0b79401ac7a8ff"><em>expression of level 2</em></a> followed by a question mark. When this is matched, an <code>Or</code> AST node is created containing the expression AST node and an empty <code>And</code> AST node. There is no dedicated AST node for the <code>?</code> operator, but it is equivalent to matching the expression or zero expressions and'ed.</p>
<p>The third sequence is an exclamation mark followed by an <a href="#4e76262e4c9841db8c0b79401ac7a8ff"><em>expression of level 2</em></a>. When this is matched, a <code>Not</code> AST node is created containing the expression AST node.</p>
<p>The fourth sequence is an <a href="#4e76262e4c9841db8c0b79401ac7a8ff"><em>expression of level 2</em></a>.</p>
<h4 id="e76262e4c9841db8c0b79401ac7a8ffexpression-of-level-2">[]{#4e76262e4c9841db8c0b79401ac7a8ff}Expression of level 2</h4>
<p>An expression of level 2 is one of the following sequences:</p>
<pre><code>1.  rlmeta
2.  parser.rlmeta
3.  [rules]{.cp}</code></pre>
<pre><code>expr2 =
  | space &#39;-&gt;&#39; hostExpr:x        -&gt; [&quot;SemanticAction&quot; x]
  | name:x !(space &#39;=&#39;)          -&gt; [&quot;MatchRule&quot; x]
  | space char:x &#39;-&#39; char:y      -&gt; [&quot;MatchRange&quot; x y]
  | space string:x               -&gt; [&quot;MatchString&quot; x]
  | space charseq:x              -&gt; [&quot;MatchCharseq&quot; x]
  | space &#39;.&#39;                    -&gt; [&quot;MatchAny&quot;]
  | space &#39;(&#39; choice:x space &#39;)&#39; -&gt; x
  | space &#39;[&#39; expr*:xs space &#39;]&#39; -&gt; [&quot;MatchList&quot; [&quot;And&quot; ~xs]]</code></pre>
<p>The first sequence is the characters '-&gt;' followed by a <a href="#768d143c206146ca8efba292c6e9169b"><em>host expression</em></a>. When this is matched, a <code>SemanticAction</code> AST node is created containing the expression AST node.</p>
<p>The second sequence is a <a href="#19acecc9fbc44023a69cea9eadbe734d"><em>name</em></a> that is not followed by an equal sign (otherwise it would also match the start of a rule). When this is matched, a <code>MatchRule</code> AST node is created containing the name.</p>
<p>The third sequence is a <a href="#2057abb618bf4209950acd87fa49da5d"><em>character</em></a> followed by a dash followed by another character. When this is matched, a <code>MatchRange</code> AST node is created containing the two characters.</p>
<p>The fourth sequence is a <a href="#2057abb618bf4209950acd87fa49da5d"><em>string</em></a>. When this is matched, a <code>MatchString</code> AST node is created containing the string.</p>
<p>The fifth sequence is a <a href="#2057abb618bf4209950acd87fa49da5d"><em>character sequence</em></a>. When this is matched, a <code>MatchCharseq</code> AST node is created containing the character sequence.</p>
<p>The sixth sequence is a dot. When this is matched, a <code>MatchAny</code> AST node is created.</p>
<p>The seventh sequence is an open parenthesis followed by a <a href="#c2a43ebb9a7d477f8dd7126f94bd33de"><em>choice</em></a> followed by a closing parenthesis. When this is matched, the choice AST node is returned.</p>
<p>The eighth sequence is an open bracket followed by <a href="#5fca8ddb3f88457bbe5217fa1ebf4383"><em>expressions</em></a> followed by a closing bracket. When this is matched, a <code>MatchList</code> AST node is created containing an <code>And</code> AST node containing the expressions.</p>
<h4 id="d143c206146ca8efba292c6e9169bhost-expression">[]{#768d143c206146ca8efba292c6e9169b}Host expression</h4>
<p>A host expression is one of the following sequences:</p>
<pre><code>1.  rlmeta
2.  parser.rlmeta
3.  [rules]{.cp}</code></pre>
<pre><code>hostExpr =
  | space string:x                           -&gt; [&quot;String&quot; x]
  | space &#39;[&#39; hostExprListItem*:xs space &#39;]&#39; -&gt; [&quot;List&quot; ~xs]
  | space &#39;{&#39; buildExpr*:xs space &#39;}&#39;        -&gt; [&quot;Builder&quot; ~xs]
  | name:x space &#39;(&#39; hostExpr*:ys space &#39;)&#39;  -&gt; [&quot;FnCall&quot; x ~ys]
  | name:x                                   -&gt; [&quot;VarLookup&quot; x]</code></pre>
<p>The first sequence is a <a href="#2057abb618bf4209950acd87fa49da5d"><em>string</em></a>. When this is matched, a <code>String</code> AST node is created containing the string.</p>
<p>The second sequence is an open bracket followed by host expression list items followed by a closing bracket. When this is matched, a <code>List</code> AST node is created containing the list item AST nodes.</p>
<p>A list item is either a host expression preceded by the <code>~</code> operator, in which case a <code>ListItemSplice</code> AST node is created containing the expression, or a host expression:</p>
<pre><code>1.  rlmeta
2.  parser.rlmeta
3.  [rules]{.cp}</code></pre>
<pre><code>hostExprListItem =
  | space &#39;~&#39; hostExpr:x -&gt; [&quot;ListItemSplice&quot; x]
  | hostExpr</code></pre>
<p>The third sequence is an open curly brace followed by build expressions followed by a closing curly brace. When this is matched, a <code>Builder</code> AST node is created containing the expression AST nodes.</p>
<p>A build expression is either a greater than character, in which case an <code>IndentBuilder</code> AST node is created, or a less than character, in which case a <code>DedentBuilder</code> AST node is created, or a host expression.</p>
<pre><code>1.  rlmeta
2.  parser.rlmeta
3.  [rules]{.cp}</code></pre>
<pre><code>buildExpr =
  | space &#39;&gt;&#39; -&gt; [&quot;IndentBuilder&quot;]
  | space &#39;&lt;&#39; -&gt; [&quot;DedentBuilder&quot;]
  | hostExpr</code></pre>
<p>The fourth sequence is a <a href="#19acecc9fbc44023a69cea9eadbe734d"><em>name</em></a> followed by an open parenthesis followed by host expressions followed by a closing parenthesis. When this is matched, a <code>FnCall</code> AST node is created containing the name and expression AST nodes.</p>
<p>The fifth sequence is a <a href="#19acecc9fbc44023a69cea9eadbe734d"><em>name</em></a>. When this is matched, a <code>VarLookup</code> AST node is created containing the name.</p>
<h4 id="abb618bf4209950acd87fa49da5dcharacter-related">[]{#2057abb618bf4209950acd87fa49da5d}Character related</h4>
<p>Character related rules capture strings, character sequences, and single characters. Inside all of them a few escape codes are possible. When this is matched, the characters inside the delimiters are joined together to create the string:</p>
<pre><code>1.  rlmeta
2.  parser.rlmeta
3.  [rules]{.cp}</code></pre>
<pre><code>string    = &#39;&quot;&#39;  (!&#39;&quot;&#39;  innerChar)*:xs &#39;&quot;&#39;  -&gt; join(xs)
charseq   = &#39;\&#39;&#39; (!&#39;\&#39;&#39; innerChar)*:xs &#39;\&#39;&#39; -&gt; join(xs)
char      = &#39;\&#39;&#39;  !&#39;\&#39;&#39; innerChar  :x  &#39;\&#39;&#39; -&gt; x
innerChar = &#39;\\&#39; escape | .
escape    = &#39;\\&#39; -&gt; &quot;\\&quot; | &#39;\&#39;&#39; -&gt; &quot;&#39;&quot;
          | &#39;&quot;&#39;  -&gt; &quot;\&quot;&quot; | &#39;n&#39;  -&gt; &quot;\n&quot;</code></pre>
<h4 id="acecc9fbc44023a69cea9eadbe734dname">[]{#19acecc9fbc44023a69cea9eadbe734d}Name</h4>
<p>A name has at least one alphabetic character followed by any number of alphanumeric characters. When this is matched, the individual characters are joined together to create a string:</p>
<pre><code>1.  rlmeta
2.  parser.rlmeta
3.  [rules]{.cp}</code></pre>
<pre><code>name      = space nameStart:x nameChar*:xs -&gt; join([x ~xs])
nameStart = &#39;a&#39;-&#39;z&#39; | &#39;A&#39;-&#39;Z&#39;
nameChar  = &#39;a&#39;-&#39;z&#39; | &#39;A&#39;-&#39;Z&#39; | &#39;0&#39;-&#39;9&#39;</code></pre>
<h4 id="space"><span id="d729731e037a4a5aafa6da77d2b8bdb1"></span>Space</h4>
<p>A space is any number of space characters or newlines:</p>
<pre><code>1.  rlmeta
2.  parser.rlmeta
3.  [rules]{.cp}</code></pre>
<pre><code>space = (&#39; &#39; | &#39;\n&#39;)*</code></pre>
<h3 id="code-generator"><span id="c3f29fa523f341a487ebc07209c471f9"></span>Code generator</h3>
<p>This section defines the code generator and the support library:</p>
<pre><code>1.  rlmeta
2.  codegenerator.rlmeta</code></pre>
<pre><code>CodeGenerator {
  &lt;&lt;rules&gt;&gt;
}</code></pre>
<pre><code>1.  rlmeta
2.  support.py</code></pre>
<pre><code>&lt;&lt;classes&gt;&gt;</code></pre>
<h4 id="note-on-target-language"><span id="b225bd1638614a808495e33a63797beb"></span>Note on target language</h4>
<p>The choice of Python as the target language for code generation is an implementation detail. A different target language could easily be used. Say for example that you would like to use RLMeta in a web browser. In that case JavaScript must be used as the target language. RLMeta could be ported to JavaScript by modifying the code generator and the support library.</p>
<h4 id="ad3d1044db18591fe09cdf1caeeparsing-algorithm">[]{#69841ad3d1044db18591fe09cdf1caee}Parsing algorithm</h4>
<p>The parsing algorithm that RLMeta implements is based on <a href="https://en.wikipedia.org/wiki/Parsing_expression_grammar">parsing expression grammars</a> (PEG), but is extended to match arbitrary objects, not just characters. Another way to describe the parsing algorithm is that it is a <a href="https://en.wikipedia.org/wiki/Recursive_descent_parser">recursive descent parser</a> with backtracking an <a href="https://en.wikipedia.org/wiki/Memoization">memoization</a>. Details of the algorithm is shown in the remainder of this section.</p>
<h4 id="d8a472a5c844a729b866f2c2c64794bstructure-of-code-generator">[]{#0d8a472a5c844a729b866f2c2c64794b}Structure of code generator</h4>
<p>The code generator has two main rules: <code>ast</code> and <code>astFnBody</code>:</p>
<pre><code>1.  rlmeta
2.  codegenerator.rlmeta
3.  [rules]{.cp}</code></pre>
<pre><code>ast =
  &lt;&lt;ast&gt;&gt;
  | astFnBody:x -&gt; { &quot;(lambda:\n&quot; &gt; x &lt; &quot;\n)&quot; }
astFnBody =
  &lt;&lt;astFnBody&gt;&gt;</code></pre>
<p>Sometimes generated code for an AST node should be wrapped in a lambda. Those AST nodes are added to the <code>astFnBody</code> rule. The <code>astFnBody</code> rule is not strictly needed, but without it, many rules would have to wrap its output in a lambda.</p>
<p>The greater than and less than characters in the string output expression cause an indent and a dedent like this:</p>
<pre class="text"><code>(lambda:
    x
)</code></pre>
<h4 id="grammar-1"><span id="ed6931f4eeca4d43aaee1e9f5485a295"></span>Grammar</h4>
<p>When a <code>Grammar</code> AST node is matched, a Python class inheriting <code>_Grammar</code> is generated:</p>
<pre><code>1.  rlmeta
2.  codegenerator.rlmeta
3.  [rules]{.cp}
4.  [ast]{.cp}</code></pre>
<pre><code>| [&quot;Grammar&quot; .:x ast*:ys] -&gt; { &quot;class &quot; x &quot;(_Grammar):\n&quot; &gt; ys &lt; }</code></pre>
<p>The name of the class is the same as the name of the grammar and the child AST nodes are assumed to generate methods in the class.</p>
<p>The <code>_Grammar</code> class is defined in the support library:</p>
<pre><code>1.  rlmeta
2.  support.py
3.  [classes]{.cp}</code></pre>
<pre><code>class _Grammar(object):

    &lt;&lt;_Grammar&gt;&gt;</code></pre>
<p>Names of support classes start with underscore to not collide with generated grammar names (which can not contain underscores).</p>
<h4 id="c542ba5b0104273805b227aeab84c04rule">[]{#3c542ba5b0104273805b227aeab84c04}Rule</h4>
<p>When a <code>Rule</code> AST node is matched, a Python method with a name prefixed with <code>_rule_</code> is generated:</p>
<pre><code>1.  rlmeta
2.  codegenerator.rlmeta
3.  [rules]{.cp}
4.  [ast]{.cp}</code></pre>
<pre><code>| [&quot;Rule&quot; .:x ast:y] -&gt; { &quot;\ndef _rule_&quot; x &quot;(self):\n&quot; &gt; &quot;return &quot; y &quot;()\n&quot; &lt; }</code></pre>
<p>The method name ends with the same name as the rule. The child AST node is assumed to generate a matcher. A matcher is a function that tries to match objects from the input stream and return a semantic action if it succeeds or raise an exception if it fails. That function is called from the generated method and the semantic action is returned.</p>
<h4 id="bc029c47949b2ad97ce78ea32cor">[]{#696631bc029c47949b2ad97ce78ea32c}Or</h4>
<p>When an <code>Or</code> AST node is matched, a matcher that calls the built-in <code>_or</code> method is generated:</p>
<pre><code>1.  rlmeta
2.  codegenerator.rlmeta
3.  [rules]{.cp}
4.  [astFnBody]{.cp}</code></pre>
<pre><code>| [&quot;Or&quot; astItems:x] -&gt; { &quot;self._or([&quot; x &quot;])&quot; }</code></pre>
<p>Rules to generate a list of items:</p>
<pre><code>1.  rlmeta
2.  codegenerator.rlmeta
3.  [rules]{.cp}</code></pre>
<pre><code>astItems = astItem*:xs -&gt; { &quot;\n&quot; &gt; xs &lt; }
astItem  = ast:x       -&gt; { x &quot;,\n&quot;     }</code></pre>
<p>The generated string is wrapped in a lambda because the code is added to the <code>astFnBody</code> rule and will thus look like this:</p>
<pre class="text"><code>(lambda:
    self._or([
        matcher1,
        matcher2,
        ...
    ])
)</code></pre>
<p>The <code>_or</code> method expects a list of matchers which are tried in sequence:</p>
<pre><code>1.  rlmeta
2.  support.py
3.  [classes]{.cp}
4.  [\_Grammar]{.cp}</code></pre>
<pre><code>def _or(self, matchers):
    original_stream = self._stream
    for matcher in matchers:
        try:
            return matcher()
        except _MatchError:
            self._stream = original_stream
    original_stream.fail(&quot;no choice matched&quot;)</code></pre>
<p>The result of the first succeeding matcher is returned. The input stream is stored in <code>_stream</code>. Streams are immutable, so resetting the stream upon failure is just a matter of saving and restoring <code>_stream</code>. <code>_MatchError</code> is the name of the exception that is raised when a match fails. Streams have a <code>fail</code> method that generates that exception and adds context to it that is useful for error reporting.</p>
<h4 id="bda56d342bc9d1f2c62e632a72dscope">[]{#86438bda56d342bc9d1f2c62e632a72d}Scope</h4>
<p>When a <code>Scope</code> AST node is matched, a matcher that creates a new scope is generated:</p>
<pre><code>1.  rlmeta
2.  codegenerator.rlmeta
3.  [rules]{.cp}
4.  [astFnBody]{.cp}</code></pre>
<pre><code>| [&quot;Scope&quot; ast:x] -&gt; { &quot;(lambda _vars:\n&quot; &gt; x &lt; &quot;()\n)(_Vars())&quot; }</code></pre>
<p>A scope is a set of variables that do not interfere with variables in other scopes. The name <code>_vars</code> is used to refer to variables in the current scope. The child AST node is assumed to generate a matcher which is called to return a semantic action. The generated string will thus look like this:</p>
<pre class="text"><code>(lambda:
    (lambda _vars:
        matcher()
    )(_Vars())
)</code></pre>
<p>The <code>_Vars</code> class is a subclass of a Python dictionary:</p>
<pre><code>1.  rlmeta
2.  support.py
3.  [classes]{.cp}</code></pre>
<pre><code>class _Vars(dict):

    &lt;&lt;_Vars&gt;&gt;</code></pre>
<h4 id="e675a013c45e3aee8b6c068e226dfand">[]{#487e675a013c45e3aee8b6c068e226df}And</h4>
<p>When an <code>And</code> AST node is matched, a matcher that calls the built-in <code>_and</code> method is generated:</p>
<pre><code>1.  rlmeta
2.  codegenerator.rlmeta
3.  [rules]{.cp}
4.  [astFnBody]{.cp}</code></pre>
<pre><code>| [&quot;And&quot; astItems:x] -&gt; { &quot;self._and([&quot; x &quot;])&quot; }</code></pre>
<p>The <code>_and</code> method expects a list of matchers which are called in sequence:</p>
<pre><code>1.  rlmeta
2.  support.py
3.  [classes]{.cp}
4.  [\_Grammar]{.cp}</code></pre>
<pre><code>def _and(self, matchers):
    result = None
    for matcher in matchers:
        result = matcher()
    return result</code></pre>
<p>The result of the last matcher is returned.</p>
<h4 id="ca572367401bb6c4561f273b8c85bind">[]{#4309ca572367401bb6c4561f273b8c85}Bind</h4>
<p>When a <code>Bind</code> AST node is matched, a matcher that binds the name to a value in the current scope is generated:</p>
<pre><code>1.  rlmeta
2.  codegenerator.rlmeta
3.  [rules]{.cp}
4.  [astFnBody]{.cp}</code></pre>
<pre><code>| [&quot;Bind&quot; .:x ast:y] -&gt; { &quot;_vars.bind(&quot; repr(x) &quot;, &quot; y &quot;())&quot; }</code></pre>
<p>The child AST node is assumed to generate a matcher which is called to make the value a semantic action.</p>
<p>The <code>bind</code> method stores and returns a value with the given name:</p>
<pre><code>1.  rlmeta
2.  support.py
3.  [classes]{.cp}
4.  [\_Vars]{.cp}</code></pre>
<pre><code>def bind(self, name, value):
    self[name] = value
    return value</code></pre>
<h4 id="f0754be514ae88e0f581f3ab58c59star">[]{#244f0754be514ae88e0f581f3ab58c59}Star</h4>
<p>When a <code>Star</code> AST node is matched, a matcher that calls the built-in <code>_star</code> method is generated:</p>
<pre><code>1.  rlmeta
2.  codegenerator.rlmeta
3.  [rules]{.cp}
4.  [astFnBody]{.cp}</code></pre>
<pre><code>| [&quot;Star&quot; ast:x] -&gt; { &quot;self._star(&quot; x &quot;)&quot; }</code></pre>
<p>The <code>_star</code> method expects a matcher and calls it for as long as it succeeds:</p>
<pre><code>1.  rlmeta
2.  support.py
3.  [classes]{.cp}
4.  [\_Grammar]{.cp}</code></pre>
<pre><code>def _star(self, matcher):
    result = []
    while True:
        original_stream = self._stream
        try:
            result.append(matcher())
        except _MatchError:
            self._stream = original_stream
            return _SemanticAction(lambda: [x.eval() for x in result])</code></pre>
<p>The return value is a semantic action. When evaluated, it returns a list of all match results evaluated.</p>
<p>A semantic action is a wrapper for a function:</p>
<pre><code>1.  rlmeta
2.  support.py
3.  [classes]{.cp}</code></pre>
<pre><code>class _SemanticAction(object):

    def __init__(self, fn):
        self.fn = fn

    def eval(self):
        return self.fn()</code></pre>
<p>Its <code>eval</code> method calls the function. The reason for wrapping semantic actions in functions is to prevent them from being evaluated before a parse is complete. If a parse fails, no semantic actions are evaluated.</p>
<h4 id="d3b166c62d43e38d2a781fb9f06b6dnot">[]{#44d3b166c62d43e38d2a781fb9f06b6d}Not</h4>
<p>When a <code>Not</code> AST node is matched, a matcher that calls the built-in <code>_not</code> method is generated:</p>
<pre><code>1.  rlmeta
2.  codegenerator.rlmeta
3.  [rules]{.cp}
4.  [astFnBody]{.cp}</code></pre>
<pre><code>| [&quot;Not&quot; ast:x] -&gt; { &quot;self._not(&quot; x &quot;)&quot; }</code></pre>
<p>The <code>_not</code> method expects a matcher and succeeds if that matcher fails:</p>
<pre><code>1.  rlmeta
2.  support.py
3.  [classes]{.cp}
4.  [\_Grammar]{.cp}</code></pre>
<pre><code>def _not(self, matcher):
    original_stream = self._stream
    try:
        matcher()
    except _MatchError:
        return _SemanticAction(lambda: None)
    else:
        original_stream.fail(&quot;match found&quot;)
    finally:
        self._stream = original_stream</code></pre>
<p>It never consumes any input. The original stream is always reset.</p>
<h4 id="ffd21784561bd8594c98fcd050asemantic-action">[]{#07530ffd21784561bd8594c98fcd050a}Semantic action</h4>
<p>When a <code>SemanticAction</code> AST node is matched, a matcher that creates a <code>_SemanticAction</code> is generated:</p>
<pre><code>1.  rlmeta
2.  codegenerator.rlmeta
3.  [rules]{.cp}
4.  [astFnBody]{.cp}</code></pre>
<pre><code>| [&quot;SemanticAction&quot; ast:x] -&gt; { &quot;_SemanticAction(lambda: &quot; x &quot;)&quot; }</code></pre>
<p>The child AST node is assumed to generate a Python expression that will be returned when the semantic action is evaluated.</p>
<h4 id="match-rule"><span id="c10aabed8057404e97ef8cd6ac1b113d"></span>Match rule</h4>
<p>When a <code>MatchRule</code> AST node is matched, a matcher that calls the built-in <code>_match_rule</code> is generated:</p>
<pre><code>1.  rlmeta
2.  codegenerator.rlmeta
3.  [rules]{.cp}
4.  [astFnBody]{.cp}</code></pre>
<pre><code>| [&quot;MatchRule&quot; .:x] -&gt; { &quot;self._match_rule(&quot; repr(x) &quot;)&quot;}</code></pre>
<p>The <code>_match_rule</code> method expects the name of the rule to call:</p>
<pre><code>1.  rlmeta
2.  support.py
3.  [classes]{.cp}
4.  [\_Grammar]{.cp}</code></pre>
<pre><code>def _match_rule(self, rule_name):
    key = (rule_name, self._stream.position())
    if key in self._memo:
        result, _, self._stream = self._memo[key]
    else:
        start = self._stream
        result = getattr(self, &quot;_rule_{}&quot;.format(rule_name))()
        end = self._stream
        self._memo[key] = (result, start, end)
    return result</code></pre>
<p>If the given rule has been matched at the current position before, the memoized result is returned and the input stream is changed to where the previous match ended. If there has been no previous match, the rule is matched by calling the method. The result of the match is stored in the memoization table for later retrieval.</p>
<h4 id="ba5893bb7094ece96e853f869df9456match-range">[]{#3ba5893bb7094ece96e853f869df9456}Match range</h4>
<p>When a <code>MatchRange</code> AST node is matched, a matcher that calls the built-in <code>_match_range</code> is generated:</p>
<pre><code>1.  rlmeta
2.  codegenerator.rlmeta
3.  [rules]{.cp}
4.  [astFnBody]{.cp}</code></pre>
<pre><code>| [&quot;MatchRange&quot; .:x .:y] -&gt; { &quot;self._match_range(&quot; repr(x) &quot;, &quot; repr(y) &quot;)&quot; }</code></pre>
<p>The <code>_match_range</code> method expects two objects defining a range to match:</p>
<pre><code>1.  rlmeta
2.  support.py
3.  [classes]{.cp}
4.  [\_Grammar]{.cp}</code></pre>
<pre><code>def _match_range(self, start, end):
    original_stream = self._stream
    next_objext, self._stream = self._stream.next()
    if next_objext &gt;= start and next_objext &lt;= end:
        return _SemanticAction(lambda: next_objext)
    else:
        original_stream.fail(
            &quot;expected range {!r}-{!r} but found {!r}&quot;.format(start, end, next_objext)
        )</code></pre>
<p>If the next object from the input stream is in that range, it succeeds, otherwise it fails.</p>
<h4 id="cc15d944579825b52559b1ee469match-string">[]{#82022cc15d944579825b52559b1ee469}Match string</h4>
<p>When a <code>MatchString</code> AST node is matched, a matcher that calls the built-in <code>_match_string</code> is generated:</p>
<pre><code>1.  rlmeta
2.  codegenerator.rlmeta
3.  [rules]{.cp}
4.  [astFnBody]{.cp}</code></pre>
<pre><code>| [&quot;MatchString&quot; .:x] -&gt; { &quot;self._match_string(&quot; repr(x) &quot;)&quot; }</code></pre>
<p>The <code>_match_string</code> method expects the string to match:</p>
<pre><code>1.  rlmeta
2.  support.py
3.  [classes]{.cp}
4.  [\_Grammar]{.cp}</code></pre>
<pre><code>def _match_string(self, string):
    original_stream = self._stream
    next_object, self._stream = self._stream.next()
    if next_object == string:
        return _SemanticAction(lambda: string)
    else:
        original_stream.fail(
            &quot;expected {!r} but found {!r}&quot;.format(string, next_object)
        )</code></pre>
<p>If the next object from the input stream is that string, it succeeds, otherwise it fails.</p>
<h4 id="eff70b8911e4b4e9bd520a7d25624e7match-character-sequence">[]{#3eff70b8911e4b4e9bd520a7d25624e7}Match character sequence</h4>
<p>When a <code>MatchCharseq</code> AST node is matched, a matcher that calls the built-in <code>_match_charseq</code> is generated:</p>
<pre><code>1.  rlmeta
2.  codegenerator.rlmeta
3.  [rules]{.cp}
4.  [astFnBody]{.cp}</code></pre>
<pre><code>| [&quot;MatchCharseq&quot; .:x] -&gt; { &quot;self._match_charseq(&quot; repr(x) &quot;)&quot; }</code></pre>
<p>The <code>_match_charseq</code> method expects a string with characters to match:</p>
<pre><code>1.  rlmeta
2.  support.py
3.  [classes]{.cp}
4.  [\_Grammar]{.cp}</code></pre>
<pre><code>def _match_charseq(self, charseq):
    for char in charseq:
        original_stream = self._stream
        next_object, self._stream = self._stream.next()
        if next_object != char:
            original_stream.fail(
                &quot;expected {!r} but found {!r}&quot;.format(char, next_object)
            )
    return _SemanticAction(lambda: charseq)</code></pre>
<p>If the next objects from the input stream are those characters, it succeeds, otherwise it fails.</p>
<h4 id="edd25f746a94b8392834343dce57370match-any">[]{#5edd25f746a94b8392834343dce57370}Match any</h4>
<p>When a <code>MatchAny</code> AST node is matched, the built-in <code>_match_any</code> is generated:</p>
<pre><code>1.  rlmeta
2.  codegenerator.rlmeta
3.  [rules]{.cp}
4.  [ast]{.cp}</code></pre>
<pre><code>| [&quot;MatchAny&quot;] -&gt; { &quot;self._match_any&quot; }</code></pre>
<p>The <code>_match_any</code> method expects no arguments and always matches the next object from the input stream:</p>
<pre><code>1.  rlmeta
2.  support.py
3.  [classes]{.cp}
4.  [\_Grammar]{.cp}</code></pre>
<pre><code>def _match_any(self):
    next_object, self._stream = self._stream.next()
    return _SemanticAction(lambda: next_object)</code></pre>
<p>It only fails if there are no more objects.</p>
<h4 id="match-list"><span id="c3b58d2d7b024fa4a0e5ff0bcf06d154"></span>Match list</h4>
<p>When a <code>MatchList</code> AST node is matched, a matcher that calls the built-in <code>_match_list</code> is generated:</p>
<pre><code>1.  rlmeta
2.  codegenerator.rlmeta
3.  [rules]{.cp}
4.  [astFnBody]{.cp}</code></pre>
<pre><code>| [&quot;MatchList&quot; ast:x] -&gt; { &quot;self._match_list(&quot; x &quot;)&quot; }</code></pre>
<p>The <code>_match_list</code> method expects a matcher that should match the contents of the list:</p>
<pre><code>1.  rlmeta
2.  support.py
3.  [classes]{.cp}
4.  [\_Grammar]{.cp}</code></pre>
<pre><code>def _match_list(self, matcher):
    original_stream = self._stream
    next_object, next_stream = self._stream.next()
    if isinstance(next_object, list):
        self._stream = self._stream.nested(next_object)
        matcher()
        if self._stream.is_at_end():
            self._stream = next_stream
            return _SemanticAction(lambda: next_object)
    original_stream.fail(&quot;list match failed&quot;)</code></pre>
<p>If the next object is a list, a new stream is created with the <code>nested</code> call that contains all child objects. It is set to be the input stream, and the matcher is then called. The matcher must match all child objects, or the match fails.</p>
<h4 id="e4e0ee643ac95210d7aa17ae7c6string">[]{#74804e4e0ee643ac95210d7aa17ae7c6}String</h4>
<p>When a <code>String</code> AST node is matched, a Python string is generated:</p>
<pre><code>1.  rlmeta
2.  codegenerator.rlmeta
3.  [rules]{.cp}
4.  [ast]{.cp}</code></pre>
<pre><code>| [&quot;String&quot; .:x] -&gt; { repr(x) }</code></pre>
<h4 id="d7a70d44fe4470967acd15d51ad56alist">[]{#03d7a70d44fe4470967acd15d51ad56a}List</h4>
<p>When a <code>List</code> AST node is matched, a Python list is generated:</p>
<pre><code>1.  rlmeta
2.  codegenerator.rlmeta
3.  [rules]{.cp}
4.  [ast]{.cp}</code></pre>
<pre><code>| [&quot;List&quot; astList:x] -&gt; { x }</code></pre>
<pre><code>1.  rlmeta
2.  codegenerator.rlmeta
3.  [rules]{.cp}</code></pre>
<pre><code>astList = astListItem*:xs    -&gt; { &quot;(&quot; xs &quot;[])&quot; }
astListItem =
  | [&quot;ListItemSplice&quot; ast:x] -&gt; {     x  &quot;+&quot;   }
  | ast:x                    -&gt; { &quot;[&quot; x &quot;]+&quot;   }</code></pre>
<p>The Python list is generated by concatenating sub-lists. If an item should be spliced, it is assumed to be a list already and is not wrapped in brackets.</p>
<h4 id="dffacb2ca4911908584d77f30b21fbuilder">[]{#166dffacb2ca4911908584d77f30b21f}Builder</h4>
<p>When a <code>Builder</code> AST node is matched, a <code>_Builder</code> is generated:</p>
<pre><code>1.  rlmeta
2.  codegenerator.rlmeta
3.  [rules]{.cp}
4.  [ast]{.cp}</code></pre>
<pre><code>| [&quot;Builder&quot; astItems:x] -&gt; { &quot;_Builder.create([&quot; x &quot;])&quot; }</code></pre>
<p>The child AST nodes are assumed to generate Python expressions.</p>
<p>When an <code>IndentBuilder</code> AST node is matched, an <code>_IndentBuilder</code> is generated:</p>
<pre><code>1.  rlmeta
2.  codegenerator.rlmeta
3.  [rules]{.cp}
4.  [ast]{.cp}</code></pre>
<pre><code>| [&quot;IndentBuilder&quot;] -&gt; { &quot;_IndentBuilder()&quot; }</code></pre>
<p>When a <code>DedentBuilder</code> AST node is matched, a <code>_DedentBuilder</code> is generated:</p>
<pre><code>1.  rlmeta
2.  codegenerator.rlmeta
3.  [rules]{.cp}
4.  [ast]{.cp}</code></pre>
<pre><code>| [&quot;DedentBuilder&quot;] -&gt; { &quot;_DedentBuilder()&quot; }</code></pre>
<p>All builders inherit from <code>_Builder</code>:</p>
<pre><code>1.  rlmeta
2.  support.py
3.  [classes]{.cp}</code></pre>
<pre><code>class _Builder(object):

    &lt;&lt;_Builder&gt;&gt;</code></pre>
<p>A builder can build a string with the <code>build_string</code> method:</p>
<pre><code>1.  rlmeta
2.  support.py
3.  [classes]{.cp}
4.  [\_Builder]{.cp}</code></pre>
<pre><code>def build_string(self):
    output = _Output()
    self.write(output)
    return output.value</code></pre>
<p>All builders must implement the <code>write</code> method that is passed an instance of <code>_Output</code>. The <code>_Output</code> class has functionality to build a string with appropriate indentation:</p>
<pre><code>1.  rlmeta
2.  support.py
3.  [classes]{.cp}</code></pre>
<pre><code>class _Output(object):

    def __init__(self):
        self.value = &quot;&quot;
        self.indentation = 0

    def write(self, value):
        for ch in value:
            if self.value and ch != &quot;\n&quot; and self.value[-1] == &quot;\n&quot;:
                self.value += &quot;    &quot;*self.indentation
            self.value += ch</code></pre>
<p>The <code>create</code> method of a builder creates an instance of a builder depending on the type of object passed in:</p>
<pre><code>1.  rlmeta
2.  support.py
3.  [classes]{.cp}
4.  [\_Builder]{.cp}</code></pre>
<pre><code>@classmethod
def create(self, item):
    if isinstance(item, _Builder):
        return item
    elif isinstance(item, list):
        return _ListBuilder([_Builder.create(x) for x in item])
    else:
        return _AtomBuilder(item)</code></pre>
<p>A <code>_ListBuilder</code> calls the <code>write</code> method on all child builders:</p>
<pre><code>1.  rlmeta
2.  support.py
3.  [classes]{.cp}</code></pre>
<pre><code>class _ListBuilder(_Builder):

    def __init__(self, builders):
        self.builders = builders

    def write(self, output):
        for builder in self.builders:
            builder.write(output)</code></pre>
<p>An <code>_AtomBuilder</code> converts its object to a string and writes it to the output:</p>
<pre><code>1.  rlmeta
2.  support.py
3.  [classes]{.cp}</code></pre>
<pre><code>class _AtomBuilder(_Builder):

    def __init__(self, atom):
        self.atom = atom

    def write(self, output):
        output.write(str(self.atom))</code></pre>
<p>An <code>_IndentBuilder</code> changes the indentation of the output:</p>
<pre><code>1.  rlmeta
2.  support.py
3.  [classes]{.cp}</code></pre>
<pre><code>class _IndentBuilder(_Builder):

    def write(self, output):
        output.indentation += 1</code></pre>
<p>A <code>_DedentBuilder</code> changes the indentation of the output:</p>
<pre><code>1.  rlmeta
2.  support.py
3.  [classes]{.cp}</code></pre>
<pre><code>class _DedentBuilder(_Builder):

    def write(self, output):
        output.indentation -= 1</code></pre>
<h4 id="function-call"><span id="f5372dab8e084ca386297eb9575052e8"></span>Function call</h4>
<p>When a <code>FnCall</code> AST node is matched, a Python function call is generated:</p>
<pre><code>1.  rlmeta
2.  codegenerator.rlmeta
3.  [rules]{.cp}
4.  [ast]{.cp}</code></pre>
<pre><code>| [&quot;FnCall&quot; .:x astItems:y] -&gt; { x &quot;(&quot; y &quot;)&quot; }</code></pre>
<p>The child AST nodes are assumed to generate Python expressions.</p>
<h4 id="variable-lookup"><span id="d9f73bdeb5c447dbaf5b8fe0bf3b67ba"></span>Variable lookup</h4>
<p>When a <code>VarLookup</code> AST node is matched, a Python expression that looks up the variable and evaluates it is generated:</p>
<pre><code>1.  rlmeta
2.  codegenerator.rlmeta
3.  [rules]{.cp}
4.  [ast]{.cp}</code></pre>
<pre><code>| [&quot;VarLookup&quot; .:x] -&gt; { &quot;_vars.lookup(&quot; repr(x) &quot;).eval()&quot; }</code></pre>
<p>The <code>lookup</code> method returns the stored value:</p>
<pre><code>1.  rlmeta
2.  support.py
3.  [classes]{.cp}
4.  [\_Vars]{.cp}</code></pre>
<pre><code>def lookup(self, name):
    return self[name]</code></pre>
<p>Every time a variable is referenced, the <code>eval</code> method is called. Consider this grammar:</p>
<pre class="text"><code>AGrammar {
  foo = bar:x -&gt; { x x }
  bar = .     -&gt; a_side_effect()
}</code></pre>
<p>If evaluating <code>x</code> has a side effect, it will be executed twice. The <code>eval</code> method of <code>_SemanticAction</code> could be modified so that the function is only called once if needed.</p>
<h4 id="d20868fa4c08ac289e463725f18efinal-support-methods">[]{#4397d20868fa4c08ac289e463725f18e}Final support methods</h4>
<p>Grammars in Python have a single entry point, <code>run</code>, which expects the name of the rule to match and the input object:</p>
<pre><code>1.  rlmeta
2.  support.py
3.  [classes]{.cp}
4.  [\_Grammar]{.cp}</code></pre>
<pre><code>def run(self, rule_name, input_object):
    self._memo = _Memo()
    self._stream = _Stream.from_object(self._memo, input_object)
    result = self._match_rule(rule_name).eval()
    if isinstance(result, _Builder):
        return result.build_string()
    else:
        return result</code></pre>
<p>It initializes the memoization table and the input stream, matches the rule, and returns the evaluated result. If the result is a builder, the string that the builder builds is returned.</p>
<p>The memoization table is a subclass of a Python dictionary:</p>
<pre><code>1.  rlmeta
2.  support.py
3.  [classes]{.cp}</code></pre>
<pre><code>class _Memo(dict):

    def __init__(self):
        dict.__init__(self)
        self._latest_stream = _ObjectStream(self, [], position=-1)
        self._latest_message = &quot;&quot;

    def describe(self):
        items = []
        for (rule_name, _), (_, start, end) in self.items():
            if end &gt; start:
                items.append((rule_name, start, end))
        items.sort(key=lambda item: (item[2].position(), item[1].position()))
        message = []
        for item in items:
            message.append(&quot;matched {: &lt;20} {} -&gt; {}\n&quot;.format(*item))
        message.append(&quot;\n&quot;)
        message.append(&quot;ERROR: {}: {}\n&quot;.format(
            self._latest_stream,
            self._latest_message
        ))
        return &quot;&quot;.join(message)

    def fail(self, stream, message):
        if stream.position() &gt;= self._latest_stream.position():
            self._latest_stream = stream
            self._latest_message = message
        raise _MatchError(self)</code></pre>
<p>Its <code>describe</code> method returns a string that describes what has been matched so far and what the latest error message was. It is used for error reporting. It keeps track of match failures via the <code>fail</code> method which is always called to raise a <code>_MatchError</code>.</p>
<p>A <code>_MatchError</code> is a Python exception that also has a reference to a memoization table so that the <code>describe</code> method can be exposed:</p>
<pre><code>1.  rlmeta
2.  support.py
3.  [classes]{.cp}</code></pre>
<pre><code>class _MatchError(Exception):

    def __init__(self, memo):
        Exception.__init__(self)
        self._memo = memo

    def describe(self):
        return self._memo.describe()</code></pre>
<p>A <code>_Stream</code> is an immutable object that has a list of objects:</p>
<pre><code>1.  rlmeta
2.  support.py
3.  [classes]{.cp}</code></pre>
<pre><code>class _Stream(object):

    @classmethod
    def from_object(cls, memo, input_object):
        if isinstance(input_object, basestring):
            return _CharStream(memo, list(input_object))
        else:
            return _ObjectStream(memo, [input_object])

    def __init__(self, memo, objects):
        self._memo = memo
        self._objects = objects

    def fail(self, message):
        self._memo.fail(self, message)

    def next(self):
        if self.is_at_end():
            self.fail(&quot;not eof&quot;)
        next_object = self._objects[0]
        return (
            next_object,
            self._advance(next_object, self._objects[1:]),
        )

    def is_at_end(self):
        return len(self._objects) == 0</code></pre>
<p>Its <code>next</code> method returns a tuple with the next object and the next stream. There are two kinds of streams: character streams and object streams. They are subclasses of <code>_Stream</code> and implement the <code>position</code> and <code>_advance</code> methods. The appropriate stream is chosen in the <code>from_object</code> method.</p>
<p>A character steam stores the position as a line + column:</p>
<pre><code>1.  rlmeta
2.  support.py
3.  [classes]{.cp}</code></pre>
<pre><code>class _CharStream(_Stream):

    def __init__(self, memo, objects, line=1, column=1):
        _Stream.__init__(self, memo, objects)
        self._line = line
        self._column = column

    def position(self):
        return (self._line, self._column)

    def _advance(self, next_object, objects):
        if next_object == &quot;\n&quot;:
            return _CharStream(self._memo, objects, self._line+1, 1)
        else:
            return _CharStream(self._memo, objects, self._line, self._column+1)

    def __str__(self):
        return &quot;L{:03d}:C{:03d}&quot;.format(self._line, self._column)</code></pre>
<p>An object stream stores the position as a tuple of indices:</p>
<pre><code>1.  rlmeta
2.  support.py
3.  [classes]{.cp}</code></pre>
<pre><code>class _ObjectStream(_Stream):

    def __init__(self, memo, objects, parent=(), position=0):
        _Stream.__init__(self, memo, objects)
        self._parent = parent
        self._position = position

    def position(self):
        return self._parent + (self._position,)

    def nested(self, input_object):
        return _ObjectStream(self._memo, input_object, self._parent+(self._position,))

    def _advance(self, next_object, objects):
        return _ObjectStream(self._memo, objects, self._parent, self._position+1)

    def __str__(self):
        return &quot;[{}]&quot;.format(&quot;, &quot;.join(str(x) for x in self.position()))</code></pre>
<p>The <code>nested</code> method will only be called on object streams since character streams do not nest.</p>
<h3 id="c78e9d9104c4bddbdd1dfe6314506c9putting-it-together">[]{#2c78e9d9104c4bddbdd1dfe6314506c9}Putting it together</h3>
<p>Here is a template for the final Python file that implements the RLMeta compiler:</p>
<pre><code>1.  rlmeta
2.  compile.sh
3.  [python file template]{.cp}</code></pre>
<pre><code>import sys

SUPPORT = $support_py_string

$support_py

$parser_py

$codegenerator_py

join = &quot;&quot;.join

def compile_grammar(grammar):
    parser = Parser()
    code_generator = CodeGenerator()
    return code_generator.run(&quot;ast&quot;, parser.run(&quot;grammar&quot;, grammar))

if __name__ == &quot;__main__&quot;:
    if &quot;--support&quot; in sys.argv:
        sys.stdout.write(SUPPORT)
    else:
        try:
            sys.stdout.write(compile_grammar(sys.stdin.read()))
        except _MatchError as e:
            sys.stderr.write(e.describe())
            sys.exit(1)</code></pre>
<p>First the <code>sys</code> module is imported because the main method needs it. Then the support library snippet is stored in a variable so that it can be output when the <code>--support</code> flag is given. Then the support library, compiled parser grammar, and compiled code generator grammar snippets are inserted. Then the host language function <code>join</code> is defined. Then a function to compile a grammar is defined. Finally the main method that reads a grammar from stdin and writes a Python class to stdout is implemented. If an error occurs, it is written to stderr using the exception's <code>describe</code> method. This template is rendered with a Bash script:</p>
<pre><code>1.  rlmeta
2.  compile.sh</code></pre>
<pre><code>#!/bin/bash

set -e

rlmeta_compiler=&quot;$(pwd)/$1&quot;

cd &quot;$(dirname &quot;$0&quot;)&quot;

to_python_string() {
    python -c &#39;import sys; sys.stdout.write(repr(sys.stdin.read()))&#39;
}

support_py=$(cat support.py)
support_py_string=$(to_python_string &lt; support.py)
parser_py=$(python &quot;$rlmeta_compiler&quot; &lt; parser.rlmeta)
codegenerator_py=$(python &quot;$rlmeta_compiler&quot; &lt; codegenerator.rlmeta)

cat &lt;&lt;EOF
&lt;&lt;python file template&gt;&gt;
EOF</code></pre>
<p>First the <code>set -e</code> directive ensures that the script exits as soon as there is an error. Then a variable containing the path to the RLMeta compiler is defined. The path must be given to the compile script as the first argument. Then the directory is changed to the one where the compile script lives. Then a function is defined that turns its stdin into a Python string with correct quoting. Then the support library is captured in a variable. Then the output of passing the support library to <code>to_python_string</code> is captured in a variable. Then the output of two calls to the RLMeta compiler are captured in two variables. Finally the Python file template is rendered and written to stdout.</p>
<p>If the compile script is run with the current RLMeta compiler (<code>rlmeta/rlmeta.py</code>), a new Python file is output that is exactly the same as the <code>rlmeta/rlmeta.py</code> file. It can be seen by diffing the two files:</p>
<pre class="text"><code>$ diff &lt;(./rlmeta/compile.sh rlmeta/rlmeta.py) rlmeta/rlmeta.py &amp;&amp; echo EQUAL
EQUAL</code></pre>
<p>The <code>rlmeta.py</code> file never needs to be changed manually. The next version can always be produced using the previous version. Sometimes the next version must be produced in steps and intermediate compilers must be created. That is why the path to the compiler must be given to the compile script. (More on modifying RLMeta in the <a href="/writing/modifying-rlmeta/index.html">next article</a>.) If you want to see what the <code>rlmeta.py</code> file looks like, it is <a href="https://github.com/rickardlindberg/rickardlindberg.me/blob/master/writing/rlmeta/rlmeta/rlmeta.py">here</a>.</p>
<h3 id="b147a2f574ea09d76d9c7371bdf18bootstrapping">[]{#313b147a2f574ea09d76d9c7371bdf18}Bootstrapping</h3>
<p>In the previous section, a version of the RLMeta compiler was needed to compile the RLMeta compiler:</p>
<pre class="text"><code>parser_py=$(python &quot;$rlmeta_compiler&quot; &lt; parser.rlmeta)
codegenerator_py=$(python &quot;$rlmeta_compiler&quot; &lt; codegenerator.rlmeta)</code></pre>
<p>But how can the RLMeta compiler be run before it exists? How was the first version of <code>rlmeta.py</code> created? This is a bootstrapping problem. In this case I solved it by translating the parser and the code generator to Python code manually according the rules specified in the grammars. I did manually what the compiler would do.</p>
<p>I started translating the parser that looks like this:</p>
<pre class="text"><code>Parser {
  ...
}</code></pre>
<p>This is matched by the <code>grammar</code> rule in the parser and turned into a <code>Grammar</code> AST node:</p>
<pre class="text"><code>grammar =
  | name:x space &#39;{&#39; rule*:ys space &#39;}&#39; -&gt; [&quot;Grammar&quot; x ~ys]</code></pre>
<p>The <code>Grammar</code> AST node is then turned into a Python class definition by the code generator:</p>
<pre class="text"><code>| [&quot;Grammar&quot; .:x ast*:ys] -&gt; { &quot;class &quot; x &quot;(_Grammar):\n&quot; &gt; ys &lt; }</code></pre>
<p>The parser is thus turned into the following Python code:</p>
<pre class="text"><code>class Parser(_Grammar):
    ...</code></pre>
<p>I then went on to translate the rules in the parser. The first rule is <code>grammar</code>:</p>
<pre class="text"><code>grammar =
  | name:x space &#39;{&#39; rule*:ys space &#39;}&#39; -&gt; [&quot;Grammar&quot; x ~ys]</code></pre>
<p>It is matched by the <code>rule</code> rule in the parser and turned into a <code>Rule</code> AST node:</p>
<pre class="text"><code>rule =
  | name:x space &#39;=&#39; choice:y -&gt; [&quot;Rule&quot; x y]</code></pre>
<p>The <code>Rule</code> AST node is then turned into a Python method definition by the code generator:</p>
<pre class="text"><code>| [&quot;Rule&quot; .:x ast:y] -&gt; { &quot;\ndef _rule_&quot; x &quot;(self):\n&quot; &gt; &quot;return &quot; y &quot;()\n&quot; &lt; }</code></pre>
<p>The <code>grammar</code> rule is thus turned into the following Python code:</p>
<pre class="text"><code>def _rule_grammar(self):
    return ...()</code></pre>
<p>The body of the <code>grammar</code> rule is matched by the <code>choice</code> rule in the parser and turned into an <code>Or</code> AST node:</p>
<pre class="text"><code>choice =
  | (space &#39;|&#39;)?
    sequence:x (space &#39;|&#39; sequence)*:xs -&gt; [&quot;Or&quot; x ~xs]</code></pre>
<p>The <code>Or</code> AST node is then turned into a Python lambda expression by the code generator:</p>
<pre class="text"><code>| [&quot;Or&quot; astItems:x] -&gt; { &quot;self._or([&quot; x &quot;])&quot; }</code></pre>
<p>The body of the <code>grammar</code> rule is thus turned into the following Python code:</p>
<pre class="text"><code>(lambda:
    self._or([...])
)</code></pre>
<p>I continued this process until all dots had been expanded. Then I did the same for all remaining rules. Finally I repeated the process for the code generator. Once I had the manually translated versions of <code>parser.py</code> and <code>codegenerator.py</code>, I could temporarily replace</p>
<pre class="text"><code>parser_py=$(python &quot;$rlmeta_compiler&quot; &lt; parser.rlmeta)
codegenerator_py=$(python &quot;$rlmeta_compiler&quot; &lt; codegenerator.rlmeta)</code></pre>
<p>with</p>
<pre class="text"><code>parser_py=$(cat parser.py)
codegenerator_py=$(cat codegenerator.py)</code></pre>
<p>to create the initial version of <code>rlmeta.py</code>.</p>
<p>With the initial version of <code>rlmeta.py</code> I could run the compile script to generate the second version of <code>rlmeta.py</code>. The second version did not match the first version exactly. The complete diff can be seen in the commit <a href="https://github.com/rickardlindberg/rickardlindberg.me/commit/134c3a360160a2b978cd742a935df1c3a85de546#diff-7687f8856e0607ca8e0247b6cd77cf7b">Get rid of bootstrapped compiler</a>. Mostly I had used a different character for strings and forgotten some commas that were not strictly necessary. Once the second version replaced the first, the compile script reproduced <code>rlmeta.py</code> exactly. At this point the manually translated versions could be discarded. The RLMeta compiler was bootstrapped. This was a tremendously rewarding experience.</p>
<p>Did the first version work on the first run? No. In the translation process I noticed incorrect behavior in the grammars that I had to fix. And some manual translations were done incorrectly. But all fixes were relatively minor. Before the translation I had also carefully debugged the grammars in my head to decrease the risk of them having bugs.</p>
<p>To avoid making mistakes in the manual translation process, I created snippets for the Vim text editor for each AST node. So when I encountered a <code>Rule</code> AST node, I could type "rule", hit tab, and the following snippet would be inserted placing the cursor where the rule name should be inserted:</p>
<pre class="text"><code>def _rule_${1:name}(self):
    return ${2:matcher}()</code></pre>
<p>I could then type the name ("grammar" for example), hit tab, write the name of the next AST node, and hit tab. If the next AST node was <code>Or</code> for example, the following snipped would be inserted, placing the cursor inside the list:</p>
<pre class="text"><code>(lambda:
    self._or([
        ${1:matchers}
    ])
)</code></pre>
<p>The Vim snippets saved me a lot of typing and made manual translation feasible. Getting all commas and parenthesis right would have been difficult otherwise.</p>
<h2 id="f558623cfce441fb3e61033299d1419implementing-programming-languages">[]{#5f558623cfce441fb3e61033299d1419}Implementing programming languages</h2>
<p>When I read <a href="https://mitpress.mit.edu/sites/default/files/sicp/full-text/book/book.html">Structure and Interpretation of Computer Programs</a> I remember thinking that it described what programming was all about. The following quote from <a href="https://mitpress.mit.edu/sites/default/files/sicp/full-text/book/book-Z-H-25.html#%_chap_4">chapter 4</a> I think summarizes it:</p>
<blockquote>
<p>However, as we confront increasingly complex problems, we will find that Lisp, or indeed any fixed programming language, is not sufficient for our needs. We must constantly turn to new languages in order to express our ideas more effectively. Establishing new languages is a powerful strategy for controlling complexity in engineering design; we can often enhance our ability to deal with a complex problem by adopting a new language that enables us to describe (and hence to think about) the problem in a different way, using primitives, means of combination, and means of abstraction that are particularly well suited to the problem at hand.</p>
</blockquote>
<p>In this article I set out to explain how a metalanguage could be used to give meaning to arithmetic expressions. But RLMeta is more powerful than that. It can be used to implement itself and also many other programming languages because matching and transforming is at the heart of programming language implementation. Its small implementation, just over 400 lines of code, also makes it feasible to understand and modify:</p>
<pre class="text"><code> 51 parser.rlmeta
 33 codegenerator.rlmeta
278 support.py
 45 compile.sh
407 total</code></pre>
<p>I hope this article inspires you to experiment with implementing programming languages so that you can solve complex problems elegantly.</p>
<h2 id="c6af1a11ed440d2bf31a497032c9c0bresources">[]{#4c6af1a11ed440d2bf31a497032c9c0b}Resources</h2>
<p>I was helped by the following resources when implementing RLMeta:</p>
<ul>
<li><a href="http://www.hcs64.com/files/pd1-3-schorre.pdf">META II paper</a></li>
<li><a href="http://www.vpri.org/pdf/tr2008003_experimenting.pdf">OMeta thesis</a></li>
<li><a href="http://www.bayfronttechnologies.com/mc_tutorial.html">Tutorial: Metacompilers Part 1</a></li>
<li><a href="https://www.youtube.com/watch?v=L1rwVBLHGiU">META II: A Syntax-Oriented Compiler Writing Language - Papers We Love Singapore</a></li>
</ul>
<h2 id="bb1e8ccbd4d55b89b391c08452c33code-listings-for-rlmeta">[]{#388bb1e8ccbd4d55b89b391c08452c33}Code listings for RLMeta</h2>
<h3 id="parser.rlmeta"><span id="a56c54f42c00473091d7c8295ff4e0f1"></span>parser.rlmeta</h3>
<pre class="text"><code>Parser {
  grammar =
    | name:x space &#39;{&#39; rule*:ys space &#39;}&#39;      -&gt; [&quot;Grammar&quot; x ~ys]
  rule =
    | name:x space &#39;=&#39; choice:y                -&gt; [&quot;Rule&quot; x y]
  choice =
    | (space &#39;|&#39;)?
      sequence:x (space &#39;|&#39; sequence)*:xs      -&gt; [&quot;Or&quot; x ~xs]
  sequence =
    | expr:x expr*:xs                          -&gt; [&quot;Scope&quot; [&quot;And&quot; x ~xs]]
  expr =
    | expr1:x space &#39;:&#39; name:y                 -&gt; [&quot;Bind&quot; y x]
    | expr1
  expr1 =
    | expr2:x space &#39;*&#39;                        -&gt; [&quot;Star&quot; x]
    | expr2:x space &#39;?&#39;                        -&gt; [&quot;Or&quot; x [&quot;And&quot;]]
    | space &#39;!&#39; expr2:x                        -&gt; [&quot;Not&quot; x]
    | expr2
  expr2 =
    | space &#39;-&gt;&#39; hostExpr:x                    -&gt; [&quot;SemanticAction&quot; x]
    | name:x !(space &#39;=&#39;)                      -&gt; [&quot;MatchRule&quot; x]
    | space char:x &#39;-&#39; char:y                  -&gt; [&quot;MatchRange&quot; x y]
    | space string:x                           -&gt; [&quot;MatchString&quot; x]
    | space charseq:x                          -&gt; [&quot;MatchCharseq&quot; x]
    | space &#39;.&#39;                                -&gt; [&quot;MatchAny&quot;]
    | space &#39;(&#39; choice:x space &#39;)&#39;             -&gt; x
    | space &#39;[&#39; expr*:xs space &#39;]&#39;             -&gt; [&quot;MatchList&quot; [&quot;And&quot; ~xs]]
  hostExpr =
    | space string:x                           -&gt; [&quot;String&quot; x]
    | space &#39;[&#39; hostExprListItem*:xs space &#39;]&#39; -&gt; [&quot;List&quot; ~xs]
    | space &#39;{&#39; buildExpr*:xs space &#39;}&#39;        -&gt; [&quot;Builder&quot; ~xs]
    | name:x space &#39;(&#39; hostExpr*:ys space &#39;)&#39;  -&gt; [&quot;FnCall&quot; x ~ys]
    | name:x                                   -&gt; [&quot;VarLookup&quot; x]
  hostExprListItem =
    | space &#39;~&#39; hostExpr:x                     -&gt; [&quot;ListItemSplice&quot; x]
    | hostExpr
  buildExpr =
    | space &#39;&gt;&#39;                                -&gt; [&quot;IndentBuilder&quot;]
    | space &#39;&lt;&#39;                                -&gt; [&quot;DedentBuilder&quot;]
    | hostExpr
  string    = &#39;&quot;&#39;  (!&#39;&quot;&#39;  innerChar)*:xs &#39;&quot;&#39;   -&gt; join(xs)
  charseq   = &#39;\&#39;&#39; (!&#39;\&#39;&#39; innerChar)*:xs &#39;\&#39;&#39;  -&gt; join(xs)
  char      = &#39;\&#39;&#39;  !&#39;\&#39;&#39; innerChar  :x  &#39;\&#39;&#39;  -&gt; x
  innerChar = &#39;\\&#39; escape | .
  escape    = &#39;\\&#39; -&gt; &quot;\\&quot; | &#39;\&#39;&#39; -&gt; &quot;&#39;&quot;
            | &#39;&quot;&#39;  -&gt; &quot;\&quot;&quot; | &#39;n&#39;  -&gt; &quot;\n&quot;
  name      = space nameStart:x nameChar*:xs   -&gt; join([x ~xs])
  nameStart = &#39;a&#39;-&#39;z&#39; | &#39;A&#39;-&#39;Z&#39;
  nameChar  = &#39;a&#39;-&#39;z&#39; | &#39;A&#39;-&#39;Z&#39; | &#39;0&#39;-&#39;9&#39;
  space     = (&#39; &#39; | &#39;\n&#39;)*
}</code></pre>
<h3 id="codegenerator.rlmeta"><span id="d9ea64bbdad3465897667ebec9d5ace1"></span>codegenerator.rlmeta</h3>
<pre class="text"><code>CodeGenerator {
  ast =
    | [&quot;Grammar&quot; .:x ast*:ys]   -&gt; { &quot;class &quot; x &quot;(_Grammar):\n&quot; &gt; ys &lt;                   }
    | [&quot;Rule&quot; .:x ast:y]        -&gt; { &quot;\ndef _rule_&quot; x &quot;(self):\n&quot; &gt; &quot;return &quot; y &quot;()\n&quot; &lt; }
    | [&quot;MatchAny&quot;]              -&gt; { &quot;self._match_any&quot;                                   }
    | [&quot;String&quot; .:x]            -&gt; { repr(x)                                             }
    | [&quot;List&quot; astList:x]        -&gt; { x                                                   }
    | [&quot;Builder&quot; astItems:x]    -&gt; { &quot;_Builder.create([&quot; x &quot;])&quot;                          }
    | [&quot;IndentBuilder&quot;]         -&gt; { &quot;_IndentBuilder()&quot;                                  }
    | [&quot;DedentBuilder&quot;]         -&gt; { &quot;_DedentBuilder()&quot;                                  }
    | [&quot;FnCall&quot; .:x astItems:y] -&gt; { x &quot;(&quot; y &quot;)&quot;                                         }
    | [&quot;VarLookup&quot; .:x]         -&gt; { &quot;_vars.lookup(&quot; repr(x) &quot;).eval()&quot;                  }
    | astFnBody:x               -&gt; { &quot;(lambda:\n&quot; &gt; x &lt; &quot;\n)&quot; }
  astFnBody =
    | [&quot;Or&quot; astItems:x]         -&gt; { &quot;self._or([&quot; x &quot;])&quot;                                 }
    | [&quot;Scope&quot; ast:x]           -&gt; { &quot;(lambda _vars:\n&quot; &gt; x &lt; &quot;()\n)(_Vars())&quot;           }
    | [&quot;And&quot; astItems:x]        -&gt; { &quot;self._and([&quot; x &quot;])&quot;                                }
    | [&quot;Bind&quot; .:x ast:y]        -&gt; { &quot;_vars.bind(&quot; repr(x) &quot;, &quot; y &quot;())&quot;                  }
    | [&quot;Star&quot; ast:x]            -&gt; { &quot;self._star(&quot; x &quot;)&quot;                                 }
    | [&quot;Not&quot; ast:x]             -&gt; { &quot;self._not(&quot; x &quot;)&quot;                                  }
    | [&quot;SemanticAction&quot; ast:x]  -&gt; { &quot;_SemanticAction(lambda: &quot; x &quot;)&quot;                    }
    | [&quot;MatchRule&quot; .:x]         -&gt; { &quot;self._match_rule(&quot; repr(x) &quot;)&quot;                     }
    | [&quot;MatchRange&quot; .:x .:y]    -&gt; { &quot;self._match_range(&quot; repr(x) &quot;, &quot; repr(y) &quot;)&quot;       }
    | [&quot;MatchString&quot; .:x]       -&gt; { &quot;self._match_string(&quot; repr(x) &quot;)&quot;                   }
    | [&quot;MatchCharseq&quot; .:x]      -&gt; { &quot;self._match_charseq(&quot; repr(x) &quot;)&quot;                  }
    | [&quot;MatchList&quot; ast:x]       -&gt; { &quot;self._match_list(&quot; x &quot;)&quot;                           }
  astItems = astItem*:xs        -&gt; { &quot;\n&quot; &gt; xs &lt;                                         }
  astItem  = ast:x              -&gt; { x &quot;,\n&quot;                                             }
  astList  = astListItem*:xs    -&gt; { &quot;(&quot; xs &quot;[])&quot;                                        }
  astListItem =
    | [&quot;ListItemSplice&quot; ast:x]  -&gt; {     x  &quot;+&quot;                                          }
    | ast:x                     -&gt; { &quot;[&quot; x &quot;]+&quot;                                          }
}</code></pre>
<h3 id="e606587034a0a9c8e8b5c714e7ef8support.py">[]{#983e606587034a0a9c8e8b5c714e7ef8}support.py</h3>
<pre class="text"><code>class _Grammar(object):

    def _or(self, matchers):
        original_stream = self._stream
        for matcher in matchers:
            try:
                return matcher()
            except _MatchError:
                self._stream = original_stream
        original_stream.fail(&quot;no choice matched&quot;)

    def _and(self, matchers):
        result = None
        for matcher in matchers:
            result = matcher()
        return result

    def _star(self, matcher):
        result = []
        while True:
            original_stream = self._stream
            try:
                result.append(matcher())
            except _MatchError:
                self._stream = original_stream
                return _SemanticAction(lambda: [x.eval() for x in result])

    def _not(self, matcher):
        original_stream = self._stream
        try:
            matcher()
        except _MatchError:
            return _SemanticAction(lambda: None)
        else:
            original_stream.fail(&quot;match found&quot;)
        finally:
            self._stream = original_stream

    def _match_rule(self, rule_name):
        key = (rule_name, self._stream.position())
        if key in self._memo:
            result, _, self._stream = self._memo[key]
        else:
            start = self._stream
            result = getattr(self, &quot;_rule_{}&quot;.format(rule_name))()
            end = self._stream
            self._memo[key] = (result, start, end)
        return result

    def _match_range(self, start, end):
        original_stream = self._stream
        next_objext, self._stream = self._stream.next()
        if next_objext &gt;= start and next_objext &lt;= end:
            return _SemanticAction(lambda: next_objext)
        else:
            original_stream.fail(
                &quot;expected range {!r}-{!r} but found {!r}&quot;.format(start, end, next_objext)
            )

    def _match_string(self, string):
        original_stream = self._stream
        next_object, self._stream = self._stream.next()
        if next_object == string:
            return _SemanticAction(lambda: string)
        else:
            original_stream.fail(
                &quot;expected {!r} but found {!r}&quot;.format(string, next_object)
            )

    def _match_charseq(self, charseq):
        for char in charseq:
            original_stream = self._stream
            next_object, self._stream = self._stream.next()
            if next_object != char:
                original_stream.fail(
                    &quot;expected {!r} but found {!r}&quot;.format(char, next_object)
                )
        return _SemanticAction(lambda: charseq)

    def _match_any(self):
        next_object, self._stream = self._stream.next()
        return _SemanticAction(lambda: next_object)

    def _match_list(self, matcher):
        original_stream = self._stream
        next_object, next_stream = self._stream.next()
        if isinstance(next_object, list):
            self._stream = self._stream.nested(next_object)
            matcher()
            if self._stream.is_at_end():
                self._stream = next_stream
                return _SemanticAction(lambda: next_object)
        original_stream.fail(&quot;list match failed&quot;)

    def run(self, rule_name, input_object):
        self._memo = _Memo()
        self._stream = _Stream.from_object(self._memo, input_object)
        result = self._match_rule(rule_name).eval()
        if isinstance(result, _Builder):
            return result.build_string()
        else:
            return result

class _Vars(dict):

    def bind(self, name, value):
        self[name] = value
        return value

    def lookup(self, name):
        return self[name]

class _SemanticAction(object):

    def __init__(self, fn):
        self.fn = fn

    def eval(self):
        return self.fn()

class _Builder(object):

    def build_string(self):
        output = _Output()
        self.write(output)
        return output.value

    @classmethod
    def create(self, item):
        if isinstance(item, _Builder):
            return item
        elif isinstance(item, list):
            return _ListBuilder([_Builder.create(x) for x in item])
        else:
            return _AtomBuilder(item)

class _Output(object):

    def __init__(self):
        self.value = &quot;&quot;
        self.indentation = 0

    def write(self, value):
        for ch in value:
            if self.value and ch != &quot;\n&quot; and self.value[-1] == &quot;\n&quot;:
                self.value += &quot;    &quot;*self.indentation
            self.value += ch

class _ListBuilder(_Builder):

    def __init__(self, builders):
        self.builders = builders

    def write(self, output):
        for builder in self.builders:
            builder.write(output)

class _AtomBuilder(_Builder):

    def __init__(self, atom):
        self.atom = atom

    def write(self, output):
        output.write(str(self.atom))

class _IndentBuilder(_Builder):

    def write(self, output):
        output.indentation += 1

class _DedentBuilder(_Builder):

    def write(self, output):
        output.indentation -= 1

class _Memo(dict):

    def __init__(self):
        dict.__init__(self)
        self._latest_stream = _ObjectStream(self, [], position=-1)
        self._latest_message = &quot;&quot;

    def describe(self):
        items = []
        for (rule_name, _), (_, start, end) in self.items():
            if end &gt; start:
                items.append((rule_name, start, end))
        items.sort(key=lambda item: (item[2].position(), item[1].position()))
        message = []
        for item in items:
            message.append(&quot;matched {: &lt;20} {} -&gt; {}\n&quot;.format(*item))
        message.append(&quot;\n&quot;)
        message.append(&quot;ERROR: {}: {}\n&quot;.format(
            self._latest_stream,
            self._latest_message
        ))
        return &quot;&quot;.join(message)

    def fail(self, stream, message):
        if stream.position() &gt;= self._latest_stream.position():
            self._latest_stream = stream
            self._latest_message = message
        raise _MatchError(self)

class _MatchError(Exception):

    def __init__(self, memo):
        Exception.__init__(self)
        self._memo = memo

    def describe(self):
        return self._memo.describe()

class _Stream(object):

    @classmethod
    def from_object(cls, memo, input_object):
        if isinstance(input_object, basestring):
            return _CharStream(memo, list(input_object))
        else:
            return _ObjectStream(memo, [input_object])

    def __init__(self, memo, objects):
        self._memo = memo
        self._objects = objects

    def fail(self, message):
        self._memo.fail(self, message)

    def next(self):
        if self.is_at_end():
            self.fail(&quot;not eof&quot;)
        next_object = self._objects[0]
        return (
            next_object,
            self._advance(next_object, self._objects[1:]),
        )

    def is_at_end(self):
        return len(self._objects) == 0

class _CharStream(_Stream):

    def __init__(self, memo, objects, line=1, column=1):
        _Stream.__init__(self, memo, objects)
        self._line = line
        self._column = column

    def position(self):
        return (self._line, self._column)

    def _advance(self, next_object, objects):
        if next_object == &quot;\n&quot;:
            return _CharStream(self._memo, objects, self._line+1, 1)
        else:
            return _CharStream(self._memo, objects, self._line, self._column+1)

    def __str__(self):
        return &quot;L{:03d}:C{:03d}&quot;.format(self._line, self._column)

class _ObjectStream(_Stream):

    def __init__(self, memo, objects, parent=(), position=0):
        _Stream.__init__(self, memo, objects)
        self._parent = parent
        self._position = position

    def position(self):
        return self._parent + (self._position,)

    def nested(self, input_object):
        return _ObjectStream(self._memo, input_object, self._parent+(self._position,))

    def _advance(self, next_object, objects):
        return _ObjectStream(self._memo, objects, self._parent, self._position+1)

    def __str__(self):
        return &quot;[{}]&quot;.format(&quot;, &quot;.join(str(x) for x in self.position()))</code></pre>
<h3 id="d8f0ff47f4edcb201139df8cd9520compile.sh">[]{#193d8f0ff47f4edcb201139df8cd9520}compile.sh</h3>
<pre class="text"><code>#!/bin/bash

set -e

rlmeta_compiler=&quot;$(pwd)/$1&quot;

cd &quot;$(dirname &quot;$0&quot;)&quot;

to_python_string() {
    python -c &#39;import sys; sys.stdout.write(repr(sys.stdin.read()))&#39;
}

support_py=$(cat support.py)
support_py_string=$(to_python_string &lt; support.py)
parser_py=$(python &quot;$rlmeta_compiler&quot; &lt; parser.rlmeta)
codegenerator_py=$(python &quot;$rlmeta_compiler&quot; &lt; codegenerator.rlmeta)

cat &lt;&lt;EOF
import sys

SUPPORT = $support_py_string

$support_py

$parser_py

$codegenerator_py

join = &quot;&quot;.join

def compile_grammar(grammar):
    parser = Parser()
    code_generator = CodeGenerator()
    return code_generator.run(&quot;ast&quot;, parser.run(&quot;grammar&quot;, grammar))

if __name__ == &quot;__main__&quot;:
    if &quot;--support&quot; in sys.argv:
        sys.stdout.write(SUPPORT)
    else:
        try:
            sys.stdout.write(compile_grammar(sys.stdin.read()))
        except _MatchError as e:
            sys.stderr.write(e.describe())
            sys.exit(1)
EOF</code></pre>
]]></summary>
</entry>
<entry>
    <title>Evolution of recalling Bash history</title>
    <link href="http://rickardlindberg.me/writing/evolution-recalling-bash-history/" />
    <id>http://rickardlindberg.me/writing/evolution-recalling-bash-history/</id>
    <published>2017-05-19T00:00:00Z</published>
    <updated>2017-05-19T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1>Evolution of recalling Bash history</h1>

<p><em>Published on 19 May 2017.</em></p>

<p>This article is about how I’ve become more efficient at using Bash, the interactive UNIX shell.</p>
<p>When I work in Bash, I often want to execute a command again. In the beginning I re-typed the command and pressed enter. This worked fine for short commands, but became tedious for longer commands.</p>
<p>In some shells this is the only way to enter a new command. But Bash remembers the recently executed commands and provides ways to recall them.</p>
<h2 id="cycle-with-arrow-keys">Cycle with arrow keys</h2>
<p>The first way I learned to recall history was with the arrow keys. If I pressed <kbd>Up</kbd> the previous command was inserted at the prompt. I could continue for as long as I wanted. If I pressed <kbd>Down</kbd> the next command was inserted at the prompt:</p>
<pre><code>$ ls&lt;Enter&gt;
bin         ...

$ date&lt;Enter&gt;
Wed May 10 08:14:46 CEST 2017

$ &lt;Up&gt;

$ date&lt;Up&gt;

$ ls&lt;Down&gt;

$ date&lt;Enter&gt;
Wed May 10 08:14:59 CEST 2017</code></pre>
<p>This worked fine for commands that I had executed recently, but tedious for commands that I had executed long ago because I had to press <kbd>Up</kbd> many times. I ended up pressing and holding <kbd>Up</kbd> so that history scrolled by and when I saw my command, I released the key and pressed <kbd>Down</kbd> until it appeared again.</p>
<h2 id="cycle-with-ctrl-pctrl-n">Cycle with Ctrl-P/Ctrl-N</h2>
<p>Later I learned that <kbd>Ctrl-P</kbd> (previous) had the same function as <kbd>Up</kbd> and that <kbd>Ctrl-N</kbd> (next) had the same function as <kbd>Down</kbd>.</p>
<p>These shortcuts were more comfortable for me because I like to keep my fingers as close to the home row as possible.</p>
<h2 id="searching-with-ctrl-r">Searching with Ctrl-R</h2>
<p>Then I learned about Bash’s interactive history search command. If I pressed <kbd>Ctrl-R</kbd> the prompt changed to this:</p>
<pre><code>(reverse-i-search)`&#39;:</code></pre>
<p>This special prompt allowed me to type parts of a command that I had executed previously. Say I wanted to execute the last find command again. I typed “find” and the prompt changed to this:</p>
<pre><code>(reverse-i-search)`find&#39;: find -name &#39;*.py&#39; -a -type f</code></pre>
<p>The text I typed, “find”, was present before the colon. After the colon the last command that I had executed that contained the string “find” was displayed. In this case I did a search for Python files. If this was not the match I was looking for, I could hit <kbd>Ctrl-R</kbd> again and the part to the right of the colon would change to the next command in the history that contained the string “find”. Once I found the command I was looking for I had two options: I could hit <kbd>Tab</kbd> to insert the command at the prompt:</p>
<pre><code>$ find -name &#39;*.py&#39; -a -type f</code></pre>
<p>This way I could edit the command before I executed it. Or I could hit <kbd>Enter</kbd> to execute the command directly.</p>
<p>Now I was able to recall commands that I had executed long ago. I almost replaced all my usages of <kbd>Ctrl-P</kbd>/<kbd>Ctrl-N</kbd> with <kbd>Ctrl-R</kbd>. Except for the cases where I knew that the command I wanted to recall was only a few entries back.</p>
<h2 id="frustrations-with-ctrl-r">Frustrations with Ctrl-R</h2>
<p>The interactive search worked great for me when I knew what I was looking for. It did not work so great when I was more uncertain or when I mistyped the name of a command.</p>
<p>The interactive search works by having a pointer to en entry in the history. When I typed a command it would move that pointer to the next item in the history that matched. But if I mistyped, the search might still match something further back in history. But when I erased a few characters to correct my mistake, the search would continue from there. Say this was my history:</p>
<ol type="1">
<li><code>tac ~/.bash_history</code></li>
<li><code>echo frustration</code></li>
<li><code>echo with</code></li>
<li><code>echo bash</code></li>
</ol>
<p>I hit <kbd>Ctrl-R</kbd> to to begin searching for “bash”:</p>
<pre><code>(reverse-i-search)`&#39;:</code></pre>
<p>But I mistyped. Instead of “b” I typed “f”:</p>
<pre><code>(reverse-i-search)`f&#39;: echo frustration</code></pre>
<p>The search matched item 2. I erased the incorrectly typed character:</p>
<pre><code>(reverse-i-search)`&#39;: echo frustration</code></pre>
<p>The match remained. I typed bash correctly:</p>
<pre><code>(reverse-i-search)`bash&#39;: tac ~/.bash_history</code></pre>
<p>It now matched item 1 instead of item 4. The search continued from the previous match. I would have wanted the search to always show the most recent match from history. The easiest way I found to reset the search after a failure to find what I was looking for was to just execute a dummy command. Usually I selected <code>ls</code> because it was short to type and had no side effects.</p>
<h2 id="interactively-filtering-with-external-program">Interactively filtering with external program</h2>
<p>Then I was introduced to <a href="https://github.com/dvorka/hstr">hstr</a> by a colleague. It worked like a replacement for <kbd>Ctrl-R</kbd>. When I invoked it, it dropped into a text UI where my last history entries were shown. I could also type part of a command to narrow down the list. If I changed the search string, the narrowed down list changed accordingly. When I found a match I could similarly press <kbd>Tab</kbd> to insert the command at the prompt or press <kbd>Enter</kbd> to execute it immediately. It looked like this:</p>
<p><a href="https://github.com/dvorka/hstr"><img src="/writing/evolution-recalling-bash-history/hh-animated-01.gif" alt="Demo of hstr (from their website)" /></a></p>
<p>This solved my frustrations with Bash’s interactive search. For me, this was a far easier way to find items from my history. The fact that it showed the last commands also helped me. I could visually inspect them, and they would guide my search.</p>
<p>hstr was so good that I wanted to use a similar selection mechanism for other things, but hstr was only for Bash history. I ended up writing my own selection program: <a href="/projects/rlselect/index.html">rlselect</a>. Partly because I wanted such a program, but also because it seemed like a fun program to write. The core selection program is called <code>rlselect</code> and then there are multiple programs that use it to allow selecting specific things. <code>rlselect-history</code> is a replacement for <kbd>Ctrl-R</kbd>/hstr:</p>
<p><a href="/projects/rlselect/index.html"><img src="/writing/evolution-recalling-bash-history/rlselect_history_demo.gif" alt="Demo of rlselect" /></a></p>
<p>There are some differences between hstr and <code>rlselect-history</code>. I took only the parts I personally wanted from hstr and put them into <code>rlselect-history</code>.</p>
<p>If you want to improve your Bash usage, I suggest taking a look at <a href="https://github.com/dvorka/hstr">hstr</a> or <a href="/projects/rlselect/index.html">rlselect</a>.</p>
]]></summary>
</entry>
<entry>
    <title>Search and replace in Vim</title>
    <link href="http://rickardlindberg.me/writing/search-and-replace-in-vim/" />
    <id>http://rickardlindberg.me/writing/search-and-replace-in-vim/</id>
    <published>2015-03-28T00:00:00Z</published>
    <updated>2015-03-28T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1>Search and replace in Vim</h1>

<p><em>Published on 28 March 2015.</em></p>

<p><em>24 September 2017: Fixed broken link to “Vim: Find and replace text across files.”</em></p>
<p>In this article I explain how I do search and replace in Vim.</p>
<p>As a programmer, I constantly rename variables, functions, and classes. The easier it is to rename something, the more likely I am to do it. I think renaming is probably one of the most important refactorings.</p>
<p>The advantage of being able to do it with Vim is that it is language independent. If I don’t have an IDE or a refactoring tool to help me, I can always use Vim.</p>
<p>At the heart of my workflow is the substitute command. I’ll show you how I use it to do renames in a single file and then show you how I have extended it to work across multiple files.</p>
<h2 id="in-a-single-file">In a single file</h2>
<p>When I want to rename something in a single file, I do the following:</p>
<ul>
<li>Place the cursor somewhere on the word I want to rename.</li>
<li>Hit <code>,rw</code> (rename word).</li>
<li>Customize the pre-entered substitute command if needed. Usually I just need to edit the replacement.</li>
<li>Hit enter.</li>
<li>Hit y/n to confirm each substitution.</li>
</ul>
<p>Now I will explain how I have built this workflow. Let me start with the mapping:</p>
<pre><code>map ,rw :call SubstituteInFile(expand(&quot;&lt;cword&gt;&quot;))&lt;CR&gt;</code></pre>
<p>The first thing that happens when I hit <code>,rw</code> is that <code>expand("&lt;cword&gt;")</code> is evaluated. It returns the word that is under the cursor. That word gets passed to <code>SubstituteInFile</code>:</p>
<pre><code>function! SubstituteInFile(text)
    execute GetSubstituteCommand(&quot;%&quot;, a:text)
endfunction</code></pre>
<p>It calls <code>GetSubstituteCommand</code> with the <code>%</code> range and the passed in text. The search command that is returned gets executed. Here is <code>GetSubstituteCommand</code>:</p>
<pre><code>function! GetSubstituteCommand(range, term)
  return a:range . &quot;s&quot; . input(&quot;:s&quot;, &quot;/\\&lt;&quot; . a:term . &quot;\\&gt;/&quot; . a:term . &quot;/gc\&lt;C-f&gt;F/F/l&quot;)
endfunction</code></pre>
<p>The call to <code>input</code> makes it possible for me to edit the substitute command before I proceed. The last bit in the input <code>\&lt;C-f&gt;F/F/l</code> drops me into the command-line window and moves the cursor to the first character of the replacement. That way I can quickly edit it. Say I make the following call: <code>GetSubstituteCommand("%", "getCategory")</code>. The command-line window shows the following with the cursor placed over <code>g</code> in the replacement:</p>
<pre><code>/\&lt;getCategory\&gt;/getCategory/gc</code></pre>
<p>Say I type <code>cwfetchCategory&lt;CR&gt;</code> (change word, type <code>fetchCategory</code>, hit enter). The return value is the following:</p>
<pre><code>%s/\&lt;getCategory\&gt;/fetchCategory/gc</code></pre>
<p>Running execute on that command is the equivalent of typing the following:</p>
<pre><code>:%s/\&lt;getCategory\&gt;/fetchCategory/gc</code></pre>
<p>Let me explain how this substitute command works:</p>
<ul>
<li><code>%</code> makes the substitute work in the whole file.</li>
<li>The brackets around <code>getCategory</code> (<code>\&lt;</code> and <code>\&gt;</code>) ensure that it only matches <code>getCategory</code> if it is not part of another word. For example, it matches <code>getCategory</code>, but not <code>getCategoryId</code> or <code>ungetCategory</code>. This is almost always what I want.</li>
<li><code>g</code> makes it replace all occurrences on a line. Not just the first.</li>
<li><code>c</code> makes me confirm each substitution. Textual search and replace is not 100% accurate, and therefore I like to manually confirm each substitution.</li>
</ul>
<p>So the Vim script I have written for renames in a single file is basically just to help me type the substitute command I use most often faster.</p>
<h2 id="across-multiple-files">Across multiple files</h2>
<p>The problem with renames is that they are not always local to a file. If I rename a function I also need to use the new name in all files where that function is called. My workflow involves both the grep command and the substitute command. It looks like this:</p>
<ul>
<li>Place the cursor somewhere on the word I want to rename.</li>
<li>Hit <code>,mrw</code> (multiple rename word).</li>
<li>Customize the pre-entered grep command if needed.</li>
<li>Hit enter.</li>
<li>Customize the pre-entered substitute command if needed. Usually I just need to edit the replacement.</li>
<li>Hit enter.</li>
<li>Hit y/n to confirm each substitution.</li>
</ul>
<p>Now I will explain how I have built this workflow. Let me start with the mapping:</p>
<pre><code>map ,mrw :call SubstituteInCodebase(expand(&quot;&lt;cword&gt;&quot;))&lt;CR&gt;</code></pre>
<p>When I hit <code>,mrw</code>, the word under the cursor is passed to <code>SubstituteInCodebase</code>:</p>
<pre><code>function! SubstituteInCodebase(text)
    let grepCommand = GetGrepCommand(a:text)
    let substituteCommand = GetSubstituteCommand(&quot;&quot;, a:text)
    execute grepCommand
    call QuickfixDo(substituteCommand . &quot; | update&quot;)
endfunction</code></pre>
<p>The first thing that happens here is that I build the grep command. It looks like this:</p>
<pre><code>function! GetGrepCommand(term)
  return &quot;grep &quot; . input(&quot;:grep &quot;, &quot;-w &#39;&quot; . a:term . &quot;&#39;\&lt;C-f&gt;F&#39;F&#39;l&quot;)
endfunction</code></pre>
<p>Similar to <code>GetSubstituteCommand</code> it drops me into command-line window so that I can customize the grep command. Say I make the following call: <code>GetGrepCommand("getCategory")</code>. The command-line window shows the following with the cursor placed over <code>g</code>:</p>
<pre><code>-w &#39;getCategory&#39;</code></pre>
<p>Say I just hit enter here. The return value is then the following:</p>
<pre><code>grep -w &#39;getCategory&#39;</code></pre>
<p>Running execute on that command is the equivalent of typing the following:</p>
<pre><code>:grep -w &#39;getCategory&#39;</code></pre>
<p>I use <a href="http://beyondgrep.com/">ack</a> as my grep program. In my <code>.vimrc</code> I have this:</p>
<pre><code>set grepprg=ack</code></pre>
<p>The <code>-w</code> flag is the equivalent of Vim’s <code>\&lt;</code> and <code>\&gt;</code>.</p>
<p>Typical customizations that I do:</p>
<ul>
<li>Add <code>--python</code> or equivalent to only search in Python files.</li>
<li>Add a directory to only do the search in certain directories.</li>
</ul>
<p>After the grep command is created, the search command is created in the same way as before. But notice the lack of the <code>%</code> range. That is because now I only want the substitute command to operate on a single line, and not the whole file. After both commands have been created, the grep command is executed.</p>
<p>Now the quickfix list is populated with the search results and I can step through it and do the substitution on each matched line. That is what <code>QuickfixDo</code> is for: It will run an arbitrary command on each line in the quickfix list. In this case I pass the substitute command (without the <code>%</code> range) plus the update command. That ensures that I save the file if the substitution did any changes before I move on to the next match. <code>QuickfixDo</code> looks like this:</p>
<pre><code>function! QuickfixDo(command)
    let itemCount = len(getqflist())
    let itemNr = 1
    while itemNr &lt;= itemCount
        exe &quot;cc &quot; . itemNr
        exe a:command
        let itemNr = itemNr + 1
    endwhile
endfunction</code></pre>
<p>The workflow for renames across multiple files contains only an extra grep step compared to the single file workflow. The defaults ensure that the matches found by the grep command are also found by the substitute command.</p>
<h2 id="further-reading">Further reading</h2>
<p>The latest version of my search and replace configuration can be found at <a href="https://github.com/rickardlindberg/dotfiles/blob/master/.vim/vimrc_search_replace.vim">vimrc_search_replace.vim</a>.</p>
<p>Other articles on the subject of search and replace in Vim that I found interesting:</p>
<ul>
<li><p><a href="http://vimcasts.org/episodes/project-wide-find-and-replace/">Vimcasts - Project-wide find and replace</a></p></li>
<li><p><a href="https://web.archive.org/web/20150928211530/http://www.ibrahim-ahmed.com/2008/01/find-and-replace-in-multiple-files-in.html">Ibrahim Ahmed - Vim: Find and replace text across files</a></p></li>
<li><p><a href="http://www.thegeekstuff.com/2009/04/vi-vim-editor-search-and-replace-examples/">The Geek Stuff - Vi and Vim Editor: 12 Powerful Find and Replace Examples</a></p></li>
</ul>
]]></summary>
</entry>
<entry>
    <title>Related things are not kept together</title>
    <link href="http://rickardlindberg.me/writing/reflections-on-programming/2013-02-24-related-things-are-not-kept-together/" />
    <id>http://rickardlindberg.me/writing/reflections-on-programming/2013-02-24-related-things-are-not-kept-together/</id>
    <published>2013-02-24T00:00:00Z</published>
    <updated>2013-02-24T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1>Related things are not kept together</h1>

<p><em>Published on 24 February 2013.</em></p>

<p>I think the organization of our code bases make them hard to understand because related things are not kept together. Let me explain what I mean by that.</p>
<h2 id="a-typical-code-base">A typical code base</h2>
<p>A typical code base is organized something like this:</p>
<pre><code>- doc/
- src/
- test/
- README</code></pre>
<p>If we want to understand how a particular part of the code works, it is helpful to find the related documentation in the doc folder and the related tests in the test folder. The problem is that all information related to a particular thing is not kept together. We have to look for it in different places in the file system.</p>
<p>This separation makes it harder to understand and modify code.</p>
<p>Also, how can we know if corresponding documentation and tests exist? We have to scan all documentation and all tests to find out if something is related. And we have to do this every time. If all related things were kept together, we wouldn’t have to do this.</p>
<p>A less obvious thing that is spread out over the code base is the declarations of things and the usage of them. When we read a declaration of a function for example, we don’t immediately know where it is used. Having that information right next to the declaration would help understand in which contexts it is used.</p>
<h2 id="cause-file-system-is-limiting">Cause: file system is limiting</h2>
<p>I believe the biggest reason why we spread related things in our code bases is that we use the file system for organization. The file system is not very flexible. We have files and folders in a strict hierarchy, and that’s about it. It makes it hard to keep related things together.</p>
<p>Contrast this with a wiki where every page can link to any other page and we can create different table of contents by creating a new page and linking to the relevant pages. We can create different views of our data. A wiki is more suitable for organizing information than the file system.</p>
<p>Let’s look at how the file system makes it hard to keep related things together.</p>
<h3 id="tests-and-implementation">Tests and implementation</h3>
<p>Why don’t we write tests next to the implementation?</p>
<p>Sometimes we do: In Python, there is a module called <a href="http://docs.python.org/3.3/library/doctest.html">doctest</a> that allows us to embed test code in comments right next to functions. It looks like this:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true"></a><span class="kw">def</span> factorial(n):</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true"></a>    <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true"></a><span class="co">    &gt;&gt;&gt; [factorial(n) for n in range(6)]</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true"></a><span class="co">    [1, 1, 2, 6, 24, 120]</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true"></a><span class="co">    &quot;&quot;&quot;</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true"></a>    result <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true"></a>    factor <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true"></a>    <span class="cf">while</span> factor <span class="op">&lt;=</span> n:</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true"></a>        result <span class="op">*=</span> factor</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true"></a>        factor <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true"></a>    <span class="cf">return</span> result</span></code></pre></div>
<p>But most of the time, we don’t write our tests like this. Why?</p>
<p>Some tests are not suitable as doctests: They might involve multiple functions so it is not obvious under which function to place them for example.</p>
<p>But I believe the biggest reason why we don’t mix test code and source code is that we don’t want to mix different things at the same level in the same source file. In the example above, it is pretty obvious that the test belongs to the factorial function because of the indentation, but consider this example:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true"></a><span class="kw">def</span> implementation(...):</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true"></a>    ...</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true"></a><span class="kw">def</span> test_implementation(...):</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true"></a>    ...</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true"></a></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true"></a><span class="kw">def</span> another_implementation(...):</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true"></a>    ...</span></code></pre></div>
<p>In this example, the invisible organization is this:</p>
<pre><code>unit 1
    implementation
    test_implementation
unit 2
    another_implementation</code></pre>
<p>We don’t immediately see which parts of the file are related. We can only guess this organization from the formatting of the text and the naming. But guessing is the best we can do.</p>
<p>Unless we put a single unit of code in a file, the source file will have different things mixed together at the same level. We never know when the tests for one function ends and the implementation for the next begins.</p>
<p>One solution to this problem is to put section comments in our files:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true"></a><span class="co"># Unit 1</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true"></a></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true"></a><span class="kw">def</span> implementation(...):</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true"></a>    ...</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true"></a></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true"></a><span class="kw">def</span> test_implementation(...):</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true"></a>    ...</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true"></a></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true"></a><span class="co"># Unit 2</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true"></a></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true"></a><span class="kw">def</span> another_implementation(...):</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true"></a>    ...</span></code></pre></div>
<p>It might make it easier to know where a section begins and ends, but when scrolling through the file, it is still just a wall of text with no obvious structure. It is not an ideal way to show organization.</p>
<h3 id="documentation-and-implementation">Documentation and implementation</h3>
<p>Why don’t we write documentation next to the implementation?</p>
<p>Sometimes we do: Tools like <a href="http://www.stack.nl/~dimitri/doxygen/">Doxygen</a> allow us to write comments next to functions and then have API documentation automatically generated.</p>
<p>But it has the same problem as test code next to the implementation: it makes the file harder to read because there are many mixed things and there is no way to show the organization.</p>
<p>Also, some documentation may pertain to many aspect of the code, so putting it on a single function or file would not be optimal for understanding.</p>
<h3 id="declaration-and-usage">Declaration and usage</h3>
<p>Why don’t we put usage next to declarations?</p>
<p>When using files to organize our code, this is simply impossible. Imagine all calls to a function being right next to where they are defined. It might work for a few functions, but certainly not for all. The file system is just not flexible enough to support this kind of organization.</p>
<p>Some IDEs allow us to show that information with the click of a button. But we still have to make a search. The code is not organized like that. The disadvantages of a search is that it might show us irrelevant results. A search can only give us the line where a declaration is used, but it might be the context around that line that helps us understand how it works. If we can put that piece of surrounding code (not just the call to the function) next to the declaration, we wouldn’t have to guess what surrounding code is important.</p>
<h2 id="why-file-system">Why file system?</h2>
<p>If the file system is such a bad tool for organizing, why do we use it? Probably because tools (compilers, document generators) expect the source code to be organized in a file system.</p>
<p>And the file system works for that purpose. We can organize our information so that tools can understand it. But it is less good for organizing information so that humans can understand it.</p>
<h2 id="how-it-should-be">How it should be</h2>
<p>Let users organize their code, tests, and documentation in whichever way they find most usable. Then, and only then, figure out how to turn that organization into something which tools (compilers, documentation generators) can use.</p>
<p>(The last step is only necessary if tools don’t directly support the organization we want.)</p>
<h2 id="way-forward">Way forward</h2>
<p>I believe tools will depend on file system organization for a long time. So if we want to benefit from a better organization today, we must take this into consideration.</p>
<p>Next, I will show how <a href="http://leoeditor.com/">Leo</a> can solve the problems discussed in this post. Leo is a tool that allows us organize our data in a flexible way yet make sure it is written to the file system where it needs to be.</p>
<h2 id="leo">Leo</h2>
<p>At a first glance, Leo looks like an outliner.</p>
<p>Here I’ve replicated parts of the file structure of <a href="https://github.com/kajgo/photobox">an Android project</a> inside Leo:</p>
<figure>
<img src="/writing/reflections-on-programming/2013-02-24-related-things-are-not-kept-together/leo-photobox-file-structure.png" title="Replicated file structure in Leo." alt="" /><figcaption>Replicated file structure in Leo.</figcaption>
</figure>
<p>Every node that starts with shadow tells Leo that it is stored in an external file. When we modify it in Leo, it will be modified on disk as well. The outline mirrors the structure of the file system. So the file <code>IntroActivity.java</code> is located in the folder <code>photobox/src/com/photobox/app/</code>.</p>
<p>So far, this doesn’t add much value. It looks exactly like the file system. Let’s see how Leo allows us to improve our organization.</p>
<p>Inside each file, we can create nodes to explicitly show the structure of our source file (the poor alternative to this is section comments):</p>
<figure>
<img src="/writing/reflections-on-programming/2013-02-24-related-things-are-not-kept-together/leo-photobox-class-structure.png" title="Show structure inside files." alt="" /><figcaption>Show structure inside files.</figcaption>
</figure>
<p>In this example, each method in the class is put in its own node. If we want, we can group related methods together under a name:</p>
<figure>
<img src="/writing/reflections-on-programming/2013-02-24-related-things-are-not-kept-together/leo-photobox-class-structure-grouping.png" title="Create more structure inside files." alt="" /><figcaption>Create more structure inside files.</figcaption>
</figure>
<p>This is a bit better, but we still don’t have related things together. We can solve that by using clones in Leo. Clones allow us to show one node in multiple places in the outline.</p>
<p>Let’s say we want to gather all information about photo collections in one place. First we create a node called “Photo collection”, then we clone the “class PhotoCollection” and “class PhotoCollectionTest” nodes and put them as children to “Photo collection” :</p>
<figure>
<img src="/writing/reflections-on-programming/2013-02-24-related-things-are-not-kept-together/leo-photobox-clones.png" title="Using clones to create different views." alt="" /><figcaption>Using clones to create different views.</figcaption>
</figure>
<p>When we change a cloned node, all places where that clone appears in the outline are changed. So if we want to work with photo collections, we never have to touch the “Files” tree. We can spend all time in “Photo collection” because all things related to that area is visible there as well.</p>
<p>Another example of clones shows how things related to the intro screen in the app have been kept together under a node:</p>
<figure>
<img src="/writing/reflections-on-programming/2013-02-24-related-things-are-not-kept-together/leo-photobox-another-view.png" title="Using clones to create different views." alt="" /><figcaption>Using clones to create different views.</figcaption>
</figure>
<h2 id="summary">Summary</h2>
<p>I hope that I’ve convinced you that using only the file system to organize our code bases makes them hard to understand. It makes them hard to understand because related things are not kept together, and the structure is not clearly visible. I also hope that I’ve given you some ideas how we can improve the situation.</p>
]]></summary>
</entry>

</feed>
